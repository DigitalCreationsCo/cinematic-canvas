diff --git a/.vscode/launch.json b/.vscode/launch.json
index 359f2c4..50395ef 100644
--- a/.vscode/launch.json
+++ b/.vscode/launch.json
@@ -94,18 +94,15 @@
                 "<node_internals>/**"
             ],
             "sourceMaps": true,
+            "console": "integratedTerminal",
+            "restart": true,
+            "autoAttachChildProcesses": true,
             "outFiles": [
-                "${workspaceFolder}/src/worker/**/*.js",
-                "${workspaceFolder}/src/pipeline/**/*.js",
-                "${workspaceFolder}/src/workflow/**/*.js",
-                "${workspaceFolder}/audio/**/*.js",
-                "${workspaceFolder}/src/shared/**/*.js",
+                "${workspaceFolder}/src/**/*.js",
                 "!**/node_modules/**"
             ],
             "resolveSourceMapLocations": [
-                "${workspaceFolder}/src/worker/**",
-                "${workspaceFolder}/src/pipeline/**",
-                "${workspaceFolder}/src/workflow/**",
+                "${workspaceFolder}/src/**",
                 "!**/node_modules/**"
             ]
         },
@@ -120,16 +117,15 @@
                 "<node_internals>/**"
             ],
             "sourceMaps": true,
+            "console": "integratedTerminal",
+            "restart": true,
+            "autoAttachChildProcesses": true,
             "outFiles": [
-                "${workspaceFolder}/src/pipeline/**/*.js",
-                "${workspaceFolder}/src/workflow/**/*.js",
-                "${workspaceFolder}/audio/**/*.js",
-                "${workspaceFolder}/src/shared/**/*.js",
+                "${workspaceFolder}/src/**/*.js",
                 "!**/node_modules/**"
             ],
             "resolveSourceMapLocations": [
-                "${workspaceFolder}/src/pipeline/**",
-                "${workspaceFolder}/src/workflow/**",
+                "${workspaceFolder}/src/**",
                 "!**/node_modules/**"
             ]
         },
@@ -143,6 +139,18 @@
             "skipFiles": [
                 "<node_internals>/**"
             ],
+            "sourceMaps": true,
+            "console": "integratedTerminal",
+            "restart": true,
+            "autoAttachChildProcesses": true,
+            "outFiles": [
+                "${workspaceFolder}/src/**/*.js",
+                "!**/node_modules/**"
+            ],
+            "resolveSourceMapLocations": [
+                "${workspaceFolder}/src/**",
+                "!**/node_modules/**"
+            ]
         },
         {
             "name": "Debug Server (Hot Reload)",
@@ -158,9 +166,20 @@
             "envFile": "${workspaceFolder}/.env",
             "console": "integratedTerminal",
             "skipFiles": [
-                "<node_internals>/**"
+                "<node_internals>/**",
             ],
-            "sourceMaps": true
+            "sourceMaps": true,
+            "restart": true,
+            "autoAttachChildProcesses": true,
+            "outFiles": [
+                "${workspaceFolder}/**/*.js",
+                "!**/node_modules/**"
+            ],
+            "resolveSourceMapLocations": [
+                "${workspaceFolder}/src/**",
+                "!**/node_modules/**"
+            ],
+            "smartStep": true,
         },
         {
             "name": "Debug Worker (Hot Reload)",
@@ -176,9 +195,20 @@
             "envFile": "${workspaceFolder}/.env",
             "console": "integratedTerminal",
             "skipFiles": [
-                "<node_internals>/**"
+                "<node_internals>/**",
+            ],
+            "sourceMaps": true,
+            "restart": true,
+            "autoAttachChildProcesses": true,
+            "outFiles": [
+                "${workspaceFolder}/**/*.js",
+                "!**/node_modules/**"
+            ],
+            "resolveSourceMapLocations": [
+                "${workspaceFolder}/src/**",
+                "!**/node_modules/**"
             ],
-            "sourceMaps": true
+            "smartStep": true,
         },
         {
             "name": "Debug Pipeline (Hot Reload)",
@@ -196,7 +226,18 @@
             "skipFiles": [
                 "<node_internals>/**"
             ],
-            "sourceMaps": true
+            "sourceMaps": true,
+            "restart": true,
+            "autoAttachChildProcesses": true,
+            "outFiles": [
+                "${workspaceFolder}/**/*.js",
+                "!**/node_modules/**"
+            ],
+            "resolveSourceMapLocations": [
+                "${workspaceFolder}/src/**",
+                "!**/node_modules/**"
+            ],
+            "smartStep": true,
         },
         {
             "name": "Debug Client",
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
new file mode 100644
index 0000000..03cb952
--- /dev/null
+++ b/CONTRIBUTING.md
@@ -0,0 +1,18 @@
+## ðŸž Debugging & Concurrency
+
+This application is architected for **Massively Concurrent** operations. It utilizes distributed locking and strict timeout policies to maintain database health in production. However, these safety mechanisms can interfere with local debugging (breakpoints).
+
+### How to Debug Safely
+If you need to use breakpoints or step-through debugging, you **must** disable the strict circuit breakers and timeouts.
+
+1.  Open your `.env` file.
+2.  Set the following flag:
+    ```bash
+    DISABLE_DB_CIRCUIT_BREAKER=true
+    ```
+3.  Restart your development server.
+
+**What this does:**
+* Sets database connection timeouts to `Infinity`.
+* Disables the application-side Circuit Breaker pattern.
+* Prevents `Circuit breaker open: Too many authentication errors` when resuming from a breakpoint.
\ No newline at end of file
diff --git a/docs/architecture/README.md b/docs/architecture/README.md
index 175bf7f..d58052c 100644
--- a/docs/architecture/README.md
+++ b/docs/architecture/README.md
@@ -15,4 +15,27 @@ This section documents the technical design and implementation details of the Ci
 *   **Event-Driven**: All communication between Control Plane and Execution Plane happens via Pub/Sub.
 *   **State-Authoritative**: PostgreSQL is the single source of truth; no hidden in-memory state.
 *   **Role-Based Generation**: Prompts are composed from specialized "expert" roles rather than monolithic instructions.
-*   **Human-in-the-Loop**: Failures trigger interruptible states where humans can intervene (via `retryLlmCall`).
\ No newline at end of file
+*   **Human-in-the-Loop**: Failures trigger interruptible states where humans can intervene (via `retryLlmCall`).
+
+## ðŸ”’ Concurrency Control & Data Integrity
+
+To support high throughput without database deadlocks, we implement a two-layer concurrency strategy.
+
+### 1. Distributed Coordination: Advisory Locks
+We do **not** use `SELECT ... FOR UPDATE` (Row Locking) for job coordination. Row locks cause bloating in Postgres and can lead to aggressive vacuuming requirements.
+
+Instead, we use **Postgres Transaction-Level Advisory Locks** (`pg_try_advisory_xact_lock`).
+* **Mechanism:** We hash the UUID of the job to a 64-bit integer key.
+* **Behavior:** Workers attempt to claim this memory-only lock. If `false` is returned, the worker immediately skips the job (fast-fail).
+* **Scope:** Locks are automatically released when the transaction commits or rolls back, preventing "zombie locks" if a worker crashes.
+
+### 2. Data Integrity: Optimistic Locking (Versioning)
+To prevent "Lost Updates" (where Worker A overwrites Worker B's results), all entities utilize **Optimistic Concurrency Control**.
+
+* **Schema:** The `jobs` table includes a strictly monotonic `version` integer.
+* **Mutation Strategy:** ```sql
+    UPDATE jobs 
+    SET state = 'COMPLETED', version = version + 1 
+    WHERE id = $1 AND version = $read_version
+    ```
+* **Safety:** If `version` does not match the version read at the start of the transaction, the update affects 0 rows and throws an `OptimisticLockError`.
\ No newline at end of file
diff --git a/docs/architecture/transient_workflow_state.md b/docs/architecture/transient_workflow_state.md
index 24728e5..419667b 100644
--- a/docs/architecture/transient_workflow_state.md
+++ b/docs/architecture/transient_workflow_state.md
@@ -276,7 +276,7 @@ import { projects, scenes, jobs } from "./schema";
 import { 
   RegenerateSceneCommand, 
   UpdateSceneAssetCommand 
-} from "./shared/types/pubsub.types";
+} from "./shared/types/pipeline.types";
 import { DbSceneSchema } from "./zod-db";
 import { eq, and } from "drizzle-orm";
 
diff --git a/package-lock.json b/package-lock.json
index df86e6e..9569acd 100644
--- a/package-lock.json
+++ b/package-lock.json
@@ -72,6 +72,8 @@
         "passport": "^0.7.0",
         "passport-local": "^1.0.0",
         "pg": "^8.16.3",
+        "pino": "^10.1.1",
+        "pino-pretty": "^13.1.3",
         "react": "^18.3.1",
         "react-day-picker": "^8.10.1",
         "react-dom": "^18.3.1",
@@ -2523,6 +2525,12 @@
         "node": ">=14"
       }
     },
+    "node_modules/@pinojs/redact": {
+      "version": "0.4.0",
+      "resolved": "https://registry.npmjs.org/@pinojs/redact/-/redact-0.4.0.tgz",
+      "integrity": "sha512-k2ENnmBugE/rzQfEcdWHcCY+/FM3VLzH9cYEsbdsoqrvzAKRhUZeRNhAZvB8OitQJ1TBed3yqWtdjzS6wJKBwg==",
+      "license": "MIT"
+    },
     "node_modules/@pkgjs/parseargs": {
       "version": "0.11.0",
       "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
@@ -6126,6 +6134,15 @@
       "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==",
       "license": "MIT"
     },
+    "node_modules/atomic-sleep": {
+      "version": "1.0.0",
+      "resolved": "https://registry.npmjs.org/atomic-sleep/-/atomic-sleep-1.0.0.tgz",
+      "integrity": "sha512-kNOjDqAh7px0XWNI+4QbzoiR/nTkHAWNud2uvnJquD1/x5a7EQZMJT0AczqK0Qn67oY/TTQ1LbUKajZpp3I9tQ==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=8.0.0"
+      }
+    },
     "node_modules/autoprefixer": {
       "version": "10.4.23",
       "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.23.tgz",
@@ -6871,6 +6888,12 @@
       "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
       "license": "MIT"
     },
+    "node_modules/colorette": {
+      "version": "2.0.20",
+      "resolved": "https://registry.npmjs.org/colorette/-/colorette-2.0.20.tgz",
+      "integrity": "sha512-IfEDxwoWIjkeXL1eXcDiow4UbKjhLdq6/EuSVR9GMN7KVH3r9gQ83e73hsz1Nd1T3ijd5xv1wcWRYO+D6kCI2w==",
+      "license": "MIT"
+    },
     "node_modules/combined-stream": {
       "version": "1.0.8",
       "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
@@ -7353,6 +7376,15 @@
         "url": "https://github.com/sponsors/kossnocorp"
       }
     },
+    "node_modules/dateformat": {
+      "version": "4.6.3",
+      "resolved": "https://registry.npmjs.org/dateformat/-/dateformat-4.6.3.tgz",
+      "integrity": "sha512-2P0p0pFGzHS5EMnhdxQi7aJN+iMheud0UhG4dlE1DLAlvL8JHjJJTX/CSm4JXwV0Ka5nGk3zC5mcb5bUQUxxMA==",
+      "license": "MIT",
+      "engines": {
+        "node": "*"
+      }
+    },
     "node_modules/debug": {
       "version": "4.4.3",
       "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.3.tgz",
@@ -8353,6 +8385,12 @@
       ],
       "license": "MIT"
     },
+    "node_modules/fast-copy": {
+      "version": "4.0.2",
+      "resolved": "https://registry.npmjs.org/fast-copy/-/fast-copy-4.0.2.tgz",
+      "integrity": "sha512-ybA6PDXIXOXivLJK/z9e+Otk7ve13I4ckBvGO5I2RRmBU1gMHLVDJYEuJYhGwez7YNlYji2M2DvVU+a9mSFDlw==",
+      "license": "MIT"
+    },
     "node_modules/fast-equals": {
       "version": "5.4.0",
       "resolved": "https://registry.npmjs.org/fast-equals/-/fast-equals-5.4.0.tgz",
@@ -8390,6 +8428,12 @@
         "node": ">= 6"
       }
     },
+    "node_modules/fast-safe-stringify": {
+      "version": "2.1.1",
+      "resolved": "https://registry.npmjs.org/fast-safe-stringify/-/fast-safe-stringify-2.1.1.tgz",
+      "integrity": "sha512-W+KJc2dmILlPplD/H4K9l9LcAHAfPtP6BY84uVLXQ6Evcz9Lcg33Y2z1IVblT6xdY54PXYVHEv+0Wpq8Io6zkA==",
+      "license": "MIT"
+    },
     "node_modules/fast-xml-parser": {
       "version": "4.5.3",
       "resolved": "https://registry.npmjs.org/fast-xml-parser/-/fast-xml-parser-4.5.3.tgz",
@@ -9312,6 +9356,12 @@
         "node": ">=10.0.0"
       }
     },
+    "node_modules/help-me": {
+      "version": "5.0.0",
+      "resolved": "https://registry.npmjs.org/help-me/-/help-me-5.0.0.tgz",
+      "integrity": "sha512-7xgomUX6ADmcYzFik0HzAxh/73YlKR9bmFzf51CZwR+b6YtzU2m0u49hQCqV6SvlqIqsaxovfwdvbnsw3b/zpg==",
+      "license": "MIT"
+    },
     "node_modules/highlight.js": {
       "version": "10.7.3",
       "resolved": "https://registry.npmjs.org/highlight.js/-/highlight.js-10.7.3.tgz",
@@ -9978,6 +10028,15 @@
         "jiti": "lib/jiti-cli.mjs"
       }
     },
+    "node_modules/joycon": {
+      "version": "3.1.1",
+      "resolved": "https://registry.npmjs.org/joycon/-/joycon-3.1.1.tgz",
+      "integrity": "sha512-34wB/Y7MW7bzjKRjUKTa46I2Z7eV62Rkhva+KkopW7Qvv/OSWBqvkSY7vusOPrNuZcUG3tApvdVgNB8POj3SPw==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=10"
+      }
+    },
     "node_modules/js-tiktoken": {
       "version": "1.0.21",
       "resolved": "https://registry.npmjs.org/js-tiktoken/-/js-tiktoken-1.0.21.tgz",
@@ -13716,6 +13775,15 @@
       ],
       "license": "MIT"
     },
+    "node_modules/on-exit-leak-free": {
+      "version": "2.1.2",
+      "resolved": "https://registry.npmjs.org/on-exit-leak-free/-/on-exit-leak-free-2.1.2.tgz",
+      "integrity": "sha512-0eJJY6hXLGf1udHwfNftBqH+g73EU4B504nZeKpz1sYRKafAghwxEJunB2O7rDZkL4PGfsMVnTXZ2EjibbqcsA==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=14.0.0"
+      }
+    },
     "node_modules/on-finished": {
       "version": "2.4.1",
       "resolved": "https://registry.npmjs.org/on-finished/-/on-finished-2.4.1.tgz",
@@ -14259,6 +14327,79 @@
         "node": ">=0.10.0"
       }
     },
+    "node_modules/pino": {
+      "version": "10.1.1",
+      "resolved": "https://registry.npmjs.org/pino/-/pino-10.1.1.tgz",
+      "integrity": "sha512-3qqVfpJtRQUCAOs4rTOEwLH6mwJJ/CSAlbis8fKOiMzTtXh0HN/VLsn3UWVTJ7U8DsWmxeNon2IpGb+wORXH4g==",
+      "license": "MIT",
+      "dependencies": {
+        "@pinojs/redact": "^0.4.0",
+        "atomic-sleep": "^1.0.0",
+        "on-exit-leak-free": "^2.1.0",
+        "pino-abstract-transport": "^3.0.0",
+        "pino-std-serializers": "^7.0.0",
+        "process-warning": "^5.0.0",
+        "quick-format-unescaped": "^4.0.3",
+        "real-require": "^0.2.0",
+        "safe-stable-stringify": "^2.3.1",
+        "sonic-boom": "^4.0.1",
+        "thread-stream": "^4.0.0"
+      },
+      "bin": {
+        "pino": "bin.js"
+      }
+    },
+    "node_modules/pino-abstract-transport": {
+      "version": "3.0.0",
+      "resolved": "https://registry.npmjs.org/pino-abstract-transport/-/pino-abstract-transport-3.0.0.tgz",
+      "integrity": "sha512-wlfUczU+n7Hy/Ha5j9a/gZNy7We5+cXp8YL+X+PG8S0KXxw7n/JXA3c46Y0zQznIJ83URJiwy7Lh56WLokNuxg==",
+      "license": "MIT",
+      "dependencies": {
+        "split2": "^4.0.0"
+      }
+    },
+    "node_modules/pino-pretty": {
+      "version": "13.1.3",
+      "resolved": "https://registry.npmjs.org/pino-pretty/-/pino-pretty-13.1.3.tgz",
+      "integrity": "sha512-ttXRkkOz6WWC95KeY9+xxWL6AtImwbyMHrL1mSwqwW9u+vLp/WIElvHvCSDg0xO/Dzrggz1zv3rN5ovTRVowKg==",
+      "license": "MIT",
+      "dependencies": {
+        "colorette": "^2.0.7",
+        "dateformat": "^4.6.3",
+        "fast-copy": "^4.0.0",
+        "fast-safe-stringify": "^2.1.1",
+        "help-me": "^5.0.0",
+        "joycon": "^3.1.1",
+        "minimist": "^1.2.6",
+        "on-exit-leak-free": "^2.1.0",
+        "pino-abstract-transport": "^3.0.0",
+        "pump": "^3.0.0",
+        "secure-json-parse": "^4.0.0",
+        "sonic-boom": "^4.0.1",
+        "strip-json-comments": "^5.0.2"
+      },
+      "bin": {
+        "pino-pretty": "bin.js"
+      }
+    },
+    "node_modules/pino-pretty/node_modules/strip-json-comments": {
+      "version": "5.0.3",
+      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-5.0.3.tgz",
+      "integrity": "sha512-1tB5mhVo7U+ETBKNf92xT4hrQa3pm0MZ0PQvuDnWgAAGHDsfp4lPSpiS6psrSiet87wyGPh9ft6wmhOMQ0hDiw==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=14.16"
+      },
+      "funding": {
+        "url": "https://github.com/sponsors/sindresorhus"
+      }
+    },
+    "node_modules/pino-std-serializers": {
+      "version": "7.1.0",
+      "resolved": "https://registry.npmjs.org/pino-std-serializers/-/pino-std-serializers-7.1.0.tgz",
+      "integrity": "sha512-BndPH67/JxGExRgiX1dX0w1FvZck5Wa4aal9198SrRhZjH3GxKQUKIBnYJTdj2HDN3UQAS06HlfcSbQj2OHmaw==",
+      "license": "MIT"
+    },
     "node_modules/pirates": {
       "version": "4.0.7",
       "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.7.tgz",
@@ -14526,6 +14667,22 @@
       "integrity": "sha512-3ouUOpQhtgrbOa17J7+uxOTpITYWaGP7/AhoR3+A+/1e9skrzelGi/dXzEYyvbxubEF6Wn2ypscTKiKJFFn1ag==",
       "license": "MIT"
     },
+    "node_modules/process-warning": {
+      "version": "5.0.0",
+      "resolved": "https://registry.npmjs.org/process-warning/-/process-warning-5.0.0.tgz",
+      "integrity": "sha512-a39t9ApHNx2L4+HBnQKqxxHNs1r7KF+Intd8Q/g1bUh6q0WIp9voPXJ/x0j+ZL45KF1pJd9+q2jLIRMfvEshkA==",
+      "funding": [
+        {
+          "type": "github",
+          "url": "https://github.com/sponsors/fastify"
+        },
+        {
+          "type": "opencollective",
+          "url": "https://opencollective.com/fastify"
+        }
+      ],
+      "license": "MIT"
+    },
     "node_modules/prop-types": {
       "version": "15.8.1",
       "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
@@ -14604,6 +14761,16 @@
       "integrity": "sha512-b/YwNhb8lk1Zz2+bXXpS/LK9OisiZZ1SNsSLxN1x2OXVEhW2Ckr/7mWE5vrC1ZTiJlD9g19jWszTmJsB+oEpFQ==",
       "license": "ISC"
     },
+    "node_modules/pump": {
+      "version": "3.0.3",
+      "resolved": "https://registry.npmjs.org/pump/-/pump-3.0.3.tgz",
+      "integrity": "sha512-todwxLMY7/heScKmntwQG8CXVkWUOdYxIvY2s0VWAAMh/nd8SoYiRaKjlr7+iCs984f2P8zvrfWcDDYVb73NfA==",
+      "license": "MIT",
+      "dependencies": {
+        "end-of-stream": "^1.1.0",
+        "once": "^1.3.1"
+      }
+    },
     "node_modules/qs": {
       "version": "6.14.1",
       "resolved": "https://registry.npmjs.org/qs/-/qs-6.14.1.tgz",
@@ -14639,6 +14806,12 @@
       ],
       "license": "MIT"
     },
+    "node_modules/quick-format-unescaped": {
+      "version": "4.0.4",
+      "resolved": "https://registry.npmjs.org/quick-format-unescaped/-/quick-format-unescaped-4.0.4.tgz",
+      "integrity": "sha512-tYC1Q1hgyRuHgloV/YXs2w15unPVh8qfu/qCTfhTYamaw7fyhumKa2yGpdSo87vY32rIclj+4fWYQXUMs9EHvg==",
+      "license": "MIT"
+    },
     "node_modules/random-bytes": {
       "version": "1.0.0",
       "resolved": "https://registry.npmjs.org/random-bytes/-/random-bytes-1.0.0.tgz",
@@ -14978,6 +15151,15 @@
         "node": ">=8.10.0"
       }
     },
+    "node_modules/real-require": {
+      "version": "0.2.0",
+      "resolved": "https://registry.npmjs.org/real-require/-/real-require-0.2.0.tgz",
+      "integrity": "sha512-57frrGM/OCTLqLOAh0mhVA9VBMHd+9U7Zb2THMGdBUoZVOtGbJzjxsYGDJ3A9AYYCP4hn6y1TVbaOfzWtm5GFg==",
+      "license": "MIT",
+      "engines": {
+        "node": ">= 12.13.0"
+      }
+    },
     "node_modules/recharts": {
       "version": "2.15.4",
       "resolved": "https://registry.npmjs.org/recharts/-/recharts-2.15.4.tgz",
@@ -15217,6 +15399,15 @@
       ],
       "license": "MIT"
     },
+    "node_modules/safe-stable-stringify": {
+      "version": "2.5.0",
+      "resolved": "https://registry.npmjs.org/safe-stable-stringify/-/safe-stable-stringify-2.5.0.tgz",
+      "integrity": "sha512-b3rppTKm9T+PsVCBEOUR46GWI7fdOs00VKZ1+9c1EWDaDMvjQc6tUwuFyIprgGgTcWoVHSKrU8H31ZHA2e0RHA==",
+      "license": "MIT",
+      "engines": {
+        "node": ">=10"
+      }
+    },
     "node_modules/safer-buffer": {
       "version": "2.1.2",
       "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
@@ -15232,6 +15423,22 @@
         "loose-envify": "^1.1.0"
       }
     },
+    "node_modules/secure-json-parse": {
+      "version": "4.1.0",
+      "resolved": "https://registry.npmjs.org/secure-json-parse/-/secure-json-parse-4.1.0.tgz",
+      "integrity": "sha512-l4KnYfEyqYJxDwlNVyRfO2E4NTHfMKAWdUuA8J0yve2Dz/E/PdBepY03RvyJpssIpRFwJoCD55wA+mEDs6ByWA==",
+      "funding": [
+        {
+          "type": "github",
+          "url": "https://github.com/sponsors/fastify"
+        },
+        {
+          "type": "opencollective",
+          "url": "https://opencollective.com/fastify"
+        }
+      ],
+      "license": "BSD-3-Clause"
+    },
     "node_modules/semantic-release": {
       "version": "24.2.7",
       "resolved": "https://registry.npmjs.org/semantic-release/-/semantic-release-24.2.7.tgz",
@@ -15751,6 +15958,15 @@
         "node": ">=8"
       }
     },
+    "node_modules/sonic-boom": {
+      "version": "4.2.0",
+      "resolved": "https://registry.npmjs.org/sonic-boom/-/sonic-boom-4.2.0.tgz",
+      "integrity": "sha512-INb7TM37/mAcsGmc9hyyI6+QR3rR1zVRu36B0NeGXKnOOLiZOfER5SA+N7X7k3yUYRzLWafduTDvJAfDswwEww==",
+      "license": "MIT",
+      "dependencies": {
+        "atomic-sleep": "^1.0.0"
+      }
+    },
     "node_modules/source-map": {
       "version": "0.6.1",
       "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
@@ -16393,6 +16609,18 @@
         "node": ">=0.8"
       }
     },
+    "node_modules/thread-stream": {
+      "version": "4.0.0",
+      "resolved": "https://registry.npmjs.org/thread-stream/-/thread-stream-4.0.0.tgz",
+      "integrity": "sha512-4iMVL6HAINXWf1ZKZjIPcz5wYaOdPhtO8ATvZ+Xqp3BTdaqtAwQkNmKORqcIo5YkQqGXq5cwfswDwMqqQNrpJA==",
+      "license": "MIT",
+      "dependencies": {
+        "real-require": "^0.2.0"
+      },
+      "engines": {
+        "node": ">=20"
+      }
+    },
     "node_modules/through2": {
       "version": "2.0.5",
       "resolved": "https://registry.npmjs.org/through2/-/through2-2.0.5.tgz",
diff --git a/package.json b/package.json
index 9393206..a77db9b 100644
--- a/package.json
+++ b/package.json
@@ -85,6 +85,8 @@
     "passport": "^0.7.0",
     "passport-local": "^1.0.0",
     "pg": "^8.16.3",
+    "pino": "^10.1.1",
+    "pino-pretty": "^13.1.3",
     "react": "^18.3.1",
     "react-day-picker": "^8.10.1",
     "react-dom": "^18.3.1",
@@ -117,6 +119,7 @@
     "@types/express": "4.17.21",
     "@types/express-session": "^1.18.0",
     "@types/fluent-ffmpeg": "^2.1.28",
+    "@types/jest": "^29.5.12",
     "@types/lodash.merge": "^4.6.9",
     "@types/multer": "^1.4.11",
     "@types/node": "22.18.0",
@@ -125,7 +128,6 @@
     "@types/react": "^18.3.11",
     "@types/react-dom": "^18.3.1",
     "@vitejs/plugin-react": "^4.7.0",
-    "@types/jest": "^29.5.12",
     "@vitest/coverage-v8": "^4.0.14",
     "autoprefixer": "^10.4.20",
     "drizzle-kit": "^0.31.4",
diff --git a/src/client/src/components/AssetHistoryPicker.tsx b/src/client/src/components/AssetHistoryPicker.tsx
index b44dc74..11e0785 100644
--- a/src/client/src/components/AssetHistoryPicker.tsx
+++ b/src/client/src/components/AssetHistoryPicker.tsx
@@ -6,7 +6,7 @@ import { useEffect, useState } from "react";
 import { getSceneAssets } from "@/lib/api";
 import { Skeleton } from "@/components/ui/skeleton";
 import { Clock, Play } from "lucide-react";
-import { AssetKey, AssetVersion } from "@shared/types/pipeline.types";
+import { AssetKey, AssetVersion } from "@shared/types/workflow.types";
 
 
 
diff --git a/src/client/src/components/CharacterCard.tsx b/src/client/src/components/CharacterCard.tsx
index 4129775..9a32dc4 100644
--- a/src/client/src/components/CharacterCard.tsx
+++ b/src/client/src/components/CharacterCard.tsx
@@ -2,7 +2,7 @@ import { Card, CardContent } from "@/components/ui/card";
 import { Users, User as UserIcon } from "lucide-react";
 import { Badge } from "@/components/ui/badge";
 import { Tooltip, TooltipContent, TooltipTrigger } from "@/components/ui/tooltip";
-import type { Character } from "@shared/types/pipeline.types";
+import type { Character } from "@shared/types/workflow.types";
 import { Skeleton } from "@/components/ui/skeleton";
 import { memo } from "react";
 import { getAllBestFromAssets } from "@shared/utils/utils";
diff --git a/src/client/src/components/LocationCard.tsx b/src/client/src/components/LocationCard.tsx
index bec7715..1268a07 100644
--- a/src/client/src/components/LocationCard.tsx
+++ b/src/client/src/components/LocationCard.tsx
@@ -2,7 +2,7 @@ import { Card, CardContent } from "@/components/ui/card";
 import { Badge } from "@/components/ui/badge";
 import { MapPin, Sun, Cloud } from "lucide-react";
 import { Tooltip, TooltipContent, TooltipTrigger } from "@/components/ui/tooltip";
-import type { Location } from "@shared/types/pipeline.types";
+import type { Location } from "@shared/types/workflow.types";
 import { Skeleton } from "@/components/ui/skeleton"; // Import Skeleton
 import { memo } from "react";
 import { getAllBestFromAssets } from "@shared/utils/utils";
diff --git a/src/client/src/components/PipelineHeader.tsx b/src/client/src/components/PipelineHeader.tsx
index 5ffa442..56c319e 100644
--- a/src/client/src/components/PipelineHeader.tsx
+++ b/src/client/src/components/PipelineHeader.tsx
@@ -3,7 +3,7 @@ import { Play, Pause, RotateCcw, Moon, Sun, Square } from "lucide-react";
 import StatusBadge from "./StatusBadge";
 import ConnectionStatus from "./ConnectionStatus";
 import { useStore } from "@/lib/store";
-import { Scene } from "@shared/types/pipeline.types";
+import { Scene } from "@shared/types/workflow.types";
 import { useCallback } from "react";
 
 interface PipelineHeaderProps {
diff --git a/src/client/src/components/PlaybackControls.tsx b/src/client/src/components/PlaybackControls.tsx
index 5156158..3cb637b 100644
--- a/src/client/src/components/PlaybackControls.tsx
+++ b/src/client/src/components/PlaybackControls.tsx
@@ -17,7 +17,7 @@ import {
   Volume1,
 } from "lucide-react";
 import { cn } from "@/lib/utils";
-import type { Scene } from "@shared/types/pipeline.types";
+import type { Scene } from "@shared/types/workflow.types";
 import { Skeleton } from "@/components/ui/skeleton";
 
 interface PlaybackControlsProps {
diff --git a/src/client/src/components/ProjectSelectionModal.tsx b/src/client/src/components/ProjectSelectionModal.tsx
index bdf8ecb..438d888 100644
--- a/src/client/src/components/ProjectSelectionModal.tsx
+++ b/src/client/src/components/ProjectSelectionModal.tsx
@@ -9,7 +9,7 @@ import { Textarea } from "@/components/ui/textarea";
 import { uploadAudio, startPipeline } from "@/lib/api";
 import { Loader2 } from "lucide-react";
 import { useStore } from '@/lib/store';
-import { Project } from '@shared/types/pipeline.types';
+import { Project } from '@shared/types/workflow.types';
 
 interface ProjectSelectionModalProps {
   isOpen: boolean;
diff --git a/src/client/src/components/QualityEvaluationPanel.tsx b/src/client/src/components/QualityEvaluationPanel.tsx
index 17c4ab3..6029429 100644
--- a/src/client/src/components/QualityEvaluationPanel.tsx
+++ b/src/client/src/components/QualityEvaluationPanel.tsx
@@ -3,7 +3,7 @@ import { Collapsible, CollapsibleContent, CollapsibleTrigger } from "@/component
 import { Badge } from "@/components/ui/badge";
 import { ChevronDown, AlertTriangle, AlertCircle, Info } from "lucide-react";
 import { useState } from "react";
-import type { QualityEvaluationResult, QualityIssue } from "@shared/types/pipeline.types";
+import type { QualityEvaluationResult, QualityIssue } from "@shared/types/workflow.types";
 import QualityScoreBar from "./QualityScoreBar";
 import StatusBadge from "./StatusBadge";
 
diff --git a/src/client/src/components/QualityScoreBar.tsx b/src/client/src/components/QualityScoreBar.tsx
index 63544c3..02a8ec1 100644
--- a/src/client/src/components/QualityScoreBar.tsx
+++ b/src/client/src/components/QualityScoreBar.tsx
@@ -1,5 +1,5 @@
 import { cn } from "@/lib/utils";
-import type { QualityScore } from "@shared/types/pipeline.types";
+import type { QualityScore } from "@shared/types/workflow.types";
 import StatusBadge from "./StatusBadge";
 
 interface QualityScoreBarProps {
diff --git a/src/client/src/components/RegenerateFrameDialog.tsx b/src/client/src/components/RegenerateFrameDialog.tsx
index 73995bf..1ea721d 100644
--- a/src/client/src/components/RegenerateFrameDialog.tsx
+++ b/src/client/src/components/RegenerateFrameDialog.tsx
@@ -8,7 +8,7 @@ import {
 import { Button } from "@/components/ui/button";
 import { Textarea } from "@/components/ui/textarea";
 import { useEffect, useState } from "react";
-import { AssetKey, AssetVersion, Scene } from "@shared/types/pipeline.types";
+import { AssetKey, AssetVersion, Scene } from "@shared/types/workflow.types";
 import { getAllBestFromAssets } from "@shared/utils/utils";
 
 interface RegenerateFrameDialogProps {
diff --git a/src/client/src/components/RegenerateSceneDialog.tsx b/src/client/src/components/RegenerateSceneDialog.tsx
index e8a2cff..d98b123 100644
--- a/src/client/src/components/RegenerateSceneDialog.tsx
+++ b/src/client/src/components/RegenerateSceneDialog.tsx
@@ -8,7 +8,7 @@ import {
 import { Button } from "@/components/ui/button";
 import { Textarea } from "@/components/ui/textarea";
 import { useEffect, useState } from "react";
-import { Scene } from "@shared/types/pipeline.types";
+import { Scene } from "@shared/types/workflow.types";
 import { getAllBestFromAssets } from "@shared/utils/utils";
 
 interface RegenerateSceneDialogProps {
diff --git a/src/client/src/components/SceneDetailPanel.tsx b/src/client/src/components/SceneDetailPanel.tsx
index 91b2157..2b966ea 100644
--- a/src/client/src/components/SceneDetailPanel.tsx
+++ b/src/client/src/components/SceneDetailPanel.tsx
@@ -5,7 +5,7 @@ import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
 import { ScrollArea } from "@/components/ui/scroll-area";
 import { Play, Pause, RefreshCw, Camera, Sun, Music, Users, MapPin, FileText } from "lucide-react";
 import { useRef, useState, useEffect, useCallback, RefObject, memo, useMemo } from "react";
-import type { Scene, AssetStatus, Character, Location, QualityEvaluationResult, AssetVersion, AssetRegistry, AssetKey, AssetHistory } from "@shared/types/pipeline.types";
+import type { Scene, AssetStatus, Character, Location, QualityEvaluationResult, AssetVersion, AssetRegistry, AssetKey, AssetHistory } from "@shared/types/workflow.types";
 import StatusBadge from "./StatusBadge";
 import QualityEvaluationPanel from "./QualityEvaluationPanel";
 import FramePreview from "./FramePreview";
diff --git a/src/client/src/components/Timeline.tsx b/src/client/src/components/Timeline.tsx
index 6d24374..ada8ca3 100644
--- a/src/client/src/components/Timeline.tsx
+++ b/src/client/src/components/Timeline.tsx
@@ -2,7 +2,7 @@ import { Badge } from "@/components/ui/badge";
 import { ScrollArea, ScrollBar } from "@/components/ui/scroll-area";
 import { Tooltip, TooltipContent, TooltipTrigger } from "@/components/ui/tooltip";
 import { cn } from "@/lib/utils";
-import type { Scene, AssetStatus } from "@shared/types/pipeline.types";
+import type { Scene, AssetStatus } from "@shared/types/workflow.types";
 import { Skeleton } from "@/components/ui/skeleton";
 import { useEffect, useRef, memo } from "react";
 import { getAllBestFromAssets } from "@shared/utils/utils";
diff --git a/src/client/src/components/ui/button.tsx b/src/client/src/components/ui/button.tsx
index 409cfbf..fc9f00a 100644
--- a/src/client/src/components/ui/button.tsx
+++ b/src/client/src/components/ui/button.tsx
@@ -29,7 +29,7 @@ const buttonVariants = cva(
         default: "min-h-9 px-4 py-2",
         sm: "min-h-8 rounded-md px-3 text-xs",
         lg: "min-h-10 rounded-md px-8",
-        icon: "h-9 w-9",
+        icon: "h-9 w-9 rounded-full",
       },
     },
     defaultVariants: {
diff --git a/src/client/src/hooks/use-media-preloader.ts b/src/client/src/hooks/use-media-preloader.ts
index 3dbdc66..323a4bf 100644
--- a/src/client/src/hooks/use-media-preloader.ts
+++ b/src/client/src/hooks/use-media-preloader.ts
@@ -1,5 +1,5 @@
 import { useEffect, useRef } from 'react';
-import type { Scene } from '@shared/types/pipeline.types';
+import type { Scene } from '@shared/types/workflow.types';
 import { getAllBestFromAssets } from '@shared/utils/utils';
 
 export function useMediaPreloader(scenes: Scene[], currentSceneId?: string) {
diff --git a/src/client/src/hooks/use-pipeline-events.ts b/src/client/src/hooks/use-pipeline-events.ts
index 8cb3e1c..2b9b3e9 100644
--- a/src/client/src/hooks/use-pipeline-events.ts
+++ b/src/client/src/hooks/use-pipeline-events.ts
@@ -1,8 +1,9 @@
 import { useEffect } from "react";
 import { useStore } from "../lib/store";
-import { PipelineEvent } from "@shared/types/pubsub.types";
-import { Project, Scene } from "@shared/types/pipeline.types";
+import { PipelineEvent } from "@shared/types/pipeline.types";
+import { Project, Scene } from "@shared/types/workflow.types";
 import { requestFullState } from "../lib/api";
+import { v7 as uuidv7 } from "uuid";
 
 interface UsePipelineEventsProps {
   projectId: string | null;
@@ -134,7 +135,7 @@ export function usePipelineEvents({ projectId }: UsePipelineEventsProps) {
               parsedEvent.payload.message.includes("âœ“") ||
               parsedEvent.payload.message.includes("âœ—")) {
               addMessage({
-                id: crypto.randomUUID(),
+                id: uuidv7(),
                 type: level,
                 message: parsedEvent.payload.message,
                 timestamp: new Date(parsedEvent.timestamp),
@@ -153,7 +154,7 @@ export function usePipelineEvents({ projectId }: UsePipelineEventsProps) {
             setProjectStatus("error");
             setIsLoading(false);
             addMessage({
-              id: crypto.randomUUID(),
+              id: uuidv7(),
               type: "error",
               message: `Workflow failed: ${parsedEvent.payload.error}`,
               timestamp: new Date(parsedEvent.timestamp)
@@ -169,7 +170,7 @@ export function usePipelineEvents({ projectId }: UsePipelineEventsProps) {
             });
             setProjectStatus("paused");
             addMessage({
-              id: crypto.randomUUID(),
+              id: uuidv7(),
               type: "warning",
               message: `Paused. Intervention required: ${parsedEvent.payload.error}`,
               timestamp: new Date(parsedEvent.timestamp)
diff --git a/src/client/src/pages/Dashboard.tsx b/src/client/src/pages/Dashboard.tsx
index db960d1..78dc32d 100644
--- a/src/client/src/pages/Dashboard.tsx
+++ b/src/client/src/pages/Dashboard.tsx
@@ -25,7 +25,7 @@ import type {
   Character,
   Location,
   AssetStatus,
-} from "@shared/types/pipeline.types";
+} from "@shared/types/workflow.types";
 import { getAllBestFromAssets } from "@shared/utils/utils";
 import PipelineHeader from "@/components/PipelineHeader";
 import SceneCard from "@/components/SceneCard";
diff --git a/src/pipeline/handlers/handleJobCompletion.ts b/src/pipeline/handlers/handleJobCompletion.ts
index a576e83..8d97dbf 100644
--- a/src/pipeline/handlers/handleJobCompletion.ts
+++ b/src/pipeline/handlers/handleJobCompletion.ts
@@ -1,4 +1,4 @@
-import { JobEvent } from "../../shared/types/job-types";
+import { JobEvent } from "../../shared/types/job.types";
 import { JobControlPlane } from "../services/job-control-plane";
 import { WorkflowOperator } from "../services/workflow-service";
 
diff --git a/src/pipeline/handlers/handleRegenerateFrameCommand.ts b/src/pipeline/handlers/handleRegenerateFrameCommand.ts
index 37b0b6d..e96616b 100644
--- a/src/pipeline/handlers/handleRegenerateFrameCommand.ts
+++ b/src/pipeline/handlers/handleRegenerateFrameCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 
 export async function handleRegenerateFrameCommand(
diff --git a/src/pipeline/handlers/handleRegenerateSceneCommand.ts b/src/pipeline/handlers/handleRegenerateSceneCommand.ts
index 1f8fd16..15df107 100644
--- a/src/pipeline/handlers/handleRegenerateSceneCommand.ts
+++ b/src/pipeline/handlers/handleRegenerateSceneCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 import { PipelineCommandHandler } from "../services/command-handler";
 
diff --git a/src/pipeline/handlers/handleRequestFullStateCommand.ts b/src/pipeline/handlers/handleRequestFullStateCommand.ts
index bb6e93a..7f8fab0 100644
--- a/src/pipeline/handlers/handleRequestFullStateCommand.ts
+++ b/src/pipeline/handlers/handleRequestFullStateCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 
 export async function handleRequestFullStateCommand(
diff --git a/src/pipeline/handlers/handleResolveInterventionCommand.ts b/src/pipeline/handlers/handleResolveInterventionCommand.ts
index 0c1c0de..abcb5de 100644
--- a/src/pipeline/handlers/handleResolveInterventionCommand.ts
+++ b/src/pipeline/handlers/handleResolveInterventionCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 
 export async function handleResolveInterventionCommand(
diff --git a/src/pipeline/handlers/handleResumePipelineCommand.ts b/src/pipeline/handlers/handleResumePipelineCommand.ts
index 2492b22..5a761bc 100644
--- a/src/pipeline/handlers/handleResumePipelineCommand.ts
+++ b/src/pipeline/handlers/handleResumePipelineCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 
 export async function handleResumePipelineCommand(
diff --git a/src/pipeline/handlers/handleStartPipelineCommand.ts b/src/pipeline/handlers/handleStartPipelineCommand.ts
index 7589046..92d020f 100644
--- a/src/pipeline/handlers/handleStartPipelineCommand.ts
+++ b/src/pipeline/handlers/handleStartPipelineCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 
 
diff --git a/src/pipeline/handlers/handleStopPipelineCommand.ts b/src/pipeline/handlers/handleStopPipelineCommand.ts
index b248b6e..2824e28 100644
--- a/src/pipeline/handlers/handleStopPipelineCommand.ts
+++ b/src/pipeline/handlers/handleStopPipelineCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 
 export async function handleStopPipelineCommand(
     command: Extract<PipelineCommand, { type: "STOP_PIPELINE"; }>,
diff --git a/src/pipeline/handlers/handleUpdateSceneAssetCommand.ts b/src/pipeline/handlers/handleUpdateSceneAssetCommand.ts
index 89e436d..061b171 100644
--- a/src/pipeline/handlers/handleUpdateSceneAssetCommand.ts
+++ b/src/pipeline/handlers/handleUpdateSceneAssetCommand.ts
@@ -1,4 +1,4 @@
-import { PipelineCommand } from "../../shared/types/pubsub.types";
+import { PipelineCommand } from "../../shared/types/pipeline.types";
 import { WorkflowOperator } from "../services/workflow-service";
 import { PipelineCommandHandler } from "../services/command-handler";
 
diff --git a/src/pipeline/helpers/assert-job.ts b/src/pipeline/helpers/assert-job.ts
index 011a9d7..d0f2feb 100644
--- a/src/pipeline/helpers/assert-job.ts
+++ b/src/pipeline/helpers/assert-job.ts
@@ -1,4 +1,4 @@
-import { JobState } from "../../shared/types/pubsub.types";
+import { JobState } from "../../shared/types/job.types";
 
 const transitions: Record<JobState, JobState[]> = {
     CREATED: [ "RUNNING", "CANCELLED" ],
diff --git a/src/pipeline/helpers/domain/character-mappers.ts b/src/pipeline/helpers/domain/character-mappers.ts
index 2d6de52..466fafe 100644
--- a/src/pipeline/helpers/domain/character-mappers.ts
+++ b/src/pipeline/helpers/domain/character-mappers.ts
@@ -1,7 +1,7 @@
 import { characters } from "../../../shared/schema";
 import {
     Character
-} from "../../../shared/types/pipeline.types";
+} from "../../../shared/types/workflow.types";
 import {
     CharacterEntity
 } from "../../../shared/zod-db";
diff --git a/src/pipeline/helpers/domain/location-mappers.ts b/src/pipeline/helpers/domain/location-mappers.ts
index 9975d09..f9d704c 100644
--- a/src/pipeline/helpers/domain/location-mappers.ts
+++ b/src/pipeline/helpers/domain/location-mappers.ts
@@ -1,7 +1,7 @@
 import { locations } from "../../../shared/schema";
 import {
     Location
-} from "../../../shared/types/pipeline.types";
+} from "../../../shared/types/workflow.types";
 import {
     LocationEntity
 } from "../../../shared/zod-db";
diff --git a/src/pipeline/helpers/domain/project-mappers.ts b/src/pipeline/helpers/domain/project-mappers.ts
index 4fff00e..b5fc628 100644
--- a/src/pipeline/helpers/domain/project-mappers.ts
+++ b/src/pipeline/helpers/domain/project-mappers.ts
@@ -2,7 +2,7 @@ import {
     Scene, Character, Location, Project, ProjectSchema, createDefaultMetrics,
     InitialProjectSchema,
     InitialProject,
-} from "../../../shared/types/pipeline.types";
+} from "../../../shared/types/workflow.types";
 import {
     ProjectEntity
 } from "../../../shared/zod-db";
diff --git a/src/pipeline/helpers/domain/scene-mappers.ts b/src/pipeline/helpers/domain/scene-mappers.ts
index f666f87..c031015 100644
--- a/src/pipeline/helpers/domain/scene-mappers.ts
+++ b/src/pipeline/helpers/domain/scene-mappers.ts
@@ -1,7 +1,7 @@
 import { scenes } from "../../../shared/schema";
 import {
     Scene,
-} from "../../../shared/types/pipeline.types";
+} from "../../../shared/types/workflow.types";
 import {
     SceneEntity
 } from "../../../shared/zod-db";
diff --git a/src/pipeline/helpers/format-loggers.ts b/src/pipeline/helpers/format-loggers.ts
deleted file mode 100644
index 491d900..0000000
--- a/src/pipeline/helpers/format-loggers.ts
+++ /dev/null
@@ -1,76 +0,0 @@
-// Only intercept console methods when projectId context exists AND filter out LLM response JSON
-function shouldPublishLog(message: any): boolean {
-    // Don't publish if message looks like LLM JSON response
-    if (typeof message === 'string') {
-        const trimmed = message.trim();
-        if (trimmed.startsWith('{') || trimmed.startsWith('[')) {
-            try {
-                JSON.parse(trimmed);
-                return false; // It's valid JSON, likely an LLM response
-            } catch {
-                // Not valid JSON, safe to publish
-            }
-        }
-    }
-    return true;
-}
-
-export function formatLoggers(store: { getStore: () => string | undefined; }, publishPipelineEvent: (event: any) => Promise<void>) {
-    const originalConsoleLog = console.log;
-    const originalConsoleWarn = console.warn;
-    const originalConsoleError = console.error;
-    
-    console.log = (message?: any, ...optionalParams: any[]) => {
-        originalConsoleLog(message, ...optionalParams);
-    
-        const projectId = store.getStore();
-        if (projectId && shouldPublishLog(message)) {
-            const formattedMessage = [ message, ...optionalParams ]
-                .map(arg => typeof arg === 'object' ? JSON.stringify(arg) : String(arg))
-                .join(' ');
-    
-            publishPipelineEvent({
-                type: "LOG",
-                projectId,
-                payload: { level: "info", message: formattedMessage },
-                timestamp: new Date().toISOString(),
-            }).catch(err => originalConsoleError("Failed to publish log event:", err));
-        }
-    };
-    
-    console.warn = (message?: any, ...optionalParams: any[]) => {
-        originalConsoleLog(message, ...optionalParams);
-    
-        const projectId = store.getStore();
-        if (projectId && shouldPublishLog(message)) {
-            const formattedMessage = [ message, ...optionalParams ]
-                .map(arg => typeof arg === 'object' ? JSON.stringify(arg) : String(arg))
-                .join(' ');
-    
-            publishPipelineEvent({
-                type: "LOG",
-                projectId,
-                payload: { level: "warning", message: formattedMessage },
-                timestamp: new Date().toISOString(),
-            }).catch(err => originalConsoleError("Failed to publish log event:", err));
-        }
-    };
-    
-    console.error = (message?: any, ...optionalParams: any[]) => {
-        originalConsoleLog(message, ...optionalParams);
-    
-        const projectId = store.getStore();
-        if (projectId && shouldPublishLog(message)) {
-            const formattedMessage = [ message, ...optionalParams ]
-                .map(arg => typeof arg === 'object' ? JSON.stringify(arg) : String(arg))
-                .join(' ');
-    
-            publishPipelineEvent({
-                type: "LOG",
-                projectId,
-                payload: { level: "error", message: formattedMessage },
-                timestamp: new Date().toISOString(),
-            }).catch(err => originalConsoleError("Failed to publish log event:", err));
-        }
-    };
-}
\ No newline at end of file
diff --git a/src/pipeline/helpers/interrupts.ts b/src/pipeline/helpers/interrupts.ts
index bc6d031..d58ef7b 100644
--- a/src/pipeline/helpers/interrupts.ts
+++ b/src/pipeline/helpers/interrupts.ts
@@ -1,6 +1,6 @@
 import { RunnableConfig } from "@langchain/core/runnables";
-import { LlmRetryInterruptValue, WorkflowState } from "../../shared/types/pipeline.types";
-import { PipelineEvent } from "../../shared/types/pubsub.types";
+import { LlmRetryInterruptValue, WorkflowState } from "../../shared/types/workflow.types";
+import { PipelineEvent } from "../../shared/types/pipeline.types";
 
 export type PipelineEventPublisher = (event: PipelineEvent) => Promise<void>;
 
@@ -22,7 +22,7 @@ export async function checkAndPublishInterruptFromSnapshot(
 
             // Ignore system interrupts (waiting for jobs)
             if (interruptValue.type !== 'llm_intervention' && interruptValue.type !== 'llm_retry_exhausted') {
-                console.log(` System interrupt detected (${(interruptValue as any).reason || 'unknown'}). Not publishing intervention event.`);
+                console.log(` System interrupt detected (${interruptValue.error || 'unknown'}). Not publishing intervention event.`);
                 return false;
             }
 
diff --git a/src/pipeline/helpers/stream-helper.ts b/src/pipeline/helpers/stream-helper.ts
index 68538ab..4e258f2 100644
--- a/src/pipeline/helpers/stream-helper.ts
+++ b/src/pipeline/helpers/stream-helper.ts
@@ -1,8 +1,8 @@
 // src/pipeline/helpers/stream-helper.ts
-import { WorkflowState } from "../../shared/types/pipeline.types";
+import { WorkflowState } from "../../shared/types/workflow.types";
 import { RunnableConfig } from "@langchain/core/runnables";
 import { checkAndPublishInterruptFromSnapshot, checkAndPublishInterruptFromStream } from "./interrupts";
-import { PipelineEvent } from "../../shared/types/pubsub.types";
+import { PipelineEvent } from "../../shared/types/pipeline.types";
 import { Command, CompiledStateGraph } from "@langchain/langgraph";
 
 
diff --git a/src/pipeline/index.ts b/src/pipeline/index.ts
index d0aca93..eb990c4 100644
--- a/src/pipeline/index.ts
+++ b/src/pipeline/index.ts
@@ -1,6 +1,6 @@
 // src/pipeline/index.ts
 import { PubSub } from "@google-cloud/pubsub";
-import { PipelineCommand, PipelineEvent } from "../shared/types/pubsub.types";
+import { PipelineCommand, PipelineEvent } from "../shared/types/pipeline.types";
 import {
     JOB_EVENTS_TOPIC_NAME,
     PIPELINE_EVENTS_TOPIC_NAME,
@@ -10,10 +10,9 @@ import {
     PIPELINE_COMMANDS_SUBSCRIPTION,
     WORKER_JOB_EVENTS_SUBSCRIPTION
 } from "../shared/constants";
-import { JobEvent } from "../shared/types/job-types";
+import { JobEvent } from "../shared/types/job.types";
 import { ApiError as StorageApiError } from "@google-cloud/storage";
 import { CheckpointerManager } from "../workflow/checkpointer-manager";
-import { AsyncLocalStorage } from "async_hooks";
 import { handleStartPipelineCommand } from './handlers/handleStartPipelineCommand';
 import { handleRequestFullStateCommand } from './handlers/handleRequestFullStateCommand';
 import { handleResumePipelineCommand } from './handlers/handleResumePipelineCommand';
@@ -22,7 +21,7 @@ import { handleRegenerateFrameCommand } from './handlers/handleRegenerateFrameCo
 import { handleUpdateSceneAssetCommand } from './handlers/handleUpdateSceneAssetCommand';
 import { handleResolveInterventionCommand } from './handlers/handleResolveInterventionCommand';
 import { handleStopPipelineCommand } from './handlers/handleStopPipelineCommand';
-import { formatLoggers } from "./helpers/format-loggers";
+import { formatLoggers, logContextStore, LogContext } from "../shared/format-loggers";
 import { WorkflowOperator } from "./services/workflow-service";
 import { DistributedLockManager } from "./services/lock-manager";
 import { v7 as uuidv7 } from 'uuid';
@@ -31,7 +30,7 @@ import { JobControlPlane } from "./services/job-control-plane";
 import { ProjectRepository } from "./project-repository";
 import { handleJobCompletion } from "./handlers/handleJobCompletion";
 
-const projectIdStore = new AsyncLocalStorage<string>();
+
 
 const gcpProjectId = process.env.GCP_PROJECT_ID;
 if (!gcpProjectId) throw Error("A GCP projectId was not provided");
@@ -76,19 +75,26 @@ export async function publishPipelineEvent(event: PipelineEvent) {
     await videoEventsTopicPublisher.publishMessage({ data: dataBuffer });
 }
 
+const logContext: LogContext = {
+    workerId,
+    correlationId: uuidv7(),
+    shouldPublishLog: false,
+};
+
 async function main() {
     console.log(`Starting pipeline service ${workerId}...`);
-
+    formatLoggers(
+        { getStore: logContextStore.getStore.bind(logContextStore) },
+        publishPipelineEvent
+    );
+    await logContextStore.run(logContext, async () => {
     try {
-        formatLoggers(projectIdStore, publishPipelineEvent);
-        checkpointerManager.getCheckpointer();
 
+        checkpointerManager.getCheckpointer();
         const jobControlPlane = new JobControlPlane(poolManager, publishJobEvent);
-
         const projectRepository = new ProjectRepository();
         const workflowOperator = new WorkflowOperator(checkpointerManager, jobControlPlane, publishPipelineEvent, projectRepository);
 
-
         // create job events topic, ensure pipeline event subscription exists
         console.log(`[Pipeline ${workerId}] Ensuring topic ${JOB_EVENTS_TOPIC_NAME} exists...`);
         const [ jobEventsTopic ] = await pubsub.topic(JOB_EVENTS_TOPIC_NAME).get({ autoCreate: true });
@@ -147,46 +153,53 @@ async function main() {
         }
 
         if (event && 'type' in event && event.type.startsWith('JOB_')) {
-            const { jobId } = event;
-            if (event.type === 'JOB_COMPLETED') {
-                await handleJobCompletion(jobId, workflowOperator, jobControlPlane);
-            }
 
-            if (event.type === 'JOB_FAILED') {
-                try {
-                    const job = await jobControlPlane.getJob(jobId);
-                    if (!job || job.state !== "FAILED") {
-                        console.warn(`[Pipeline.jobFailed] Job ${jobId} not found or not completed`);
+            await logContextStore.run({ ...logContext, jobId: event.jobId, shouldPublishLog: true }, async () => {
+                const { jobId } = event;
+                if (event.type === 'JOB_COMPLETED') {
+                    await handleJobCompletion(jobId, workflowOperator, jobControlPlane);
+                }
+
+                if (event.type === 'JOB_FAILED') {
+                    try {
+                        const job = await jobControlPlane.getJob(jobId);
+                        if (!job || job.state !== "FAILED") {
+                            console.warn(`[Pipeline.jobFailed] Job ${jobId} not found or not completed`);
+                            return;
+                        }
+
+                        const projectId = job.projectId;
+                        await publishPipelineEvent({
+                            type: "WORKFLOW_FAILED",
+                            projectId: projectId,
+                            payload: { error: job.error || `Job ${jobId} (${job.type}) failed` },
+                            timestamp: new Date().toISOString(),
+                        });
+                        console.warn(`[Pipeline] Job ${jobId} (${job.type}) failed.`);
                         return;
+                    } catch (err) {
+                        console.error("[Pipeline] Error handling job failure:", err);
                     }
-
-                    const projectId = job.projectId;
-                    await publishPipelineEvent({
-                        type: "WORKFLOW_FAILED",
-                        projectId: projectId,
-                        payload: { error: job.error || `Job ${jobId} (${job.type}) failed` },
-                        timestamp: new Date().toISOString(),
-                    });
-                    console.warn(`[Pipeline] Job ${jobId} (${job.type}) failed.`);
-                    return;
-                } catch (err) {
-                    console.error("[Pipeline] Error handling job failure:", err);
                 }
-            }
+
+            });
         }
         message.ack();
     });
 
 
-    cancellationSubscription.on("message", async (message) => {
-        try {
-            const payload = JSON.parse(message.data.toString());
-            if (payload.projectId) {
-                await workflowOperator.stopPipeline(payload.projectId);
+        cancellationSubscription.on("message", async (message) => {
+            try {
+                const payload = JSON.parse(message.data.toString());
+                if (payload.projectId) {
+                    await logContextStore.run({ ...logContext, projectId: payload.projectId, shouldPublishLog: true }, async () => {
+
+                        await workflowOperator.stopPipeline(payload.projectId);
+                    });
+                }
+            } catch (err) {
+                console.error("Error processing cancellation message:", err);
             }
-        } catch (err) {
-            console.error("Error processing cancellation message:", err);
-        }
         message.ack();
     });
 
@@ -206,12 +219,17 @@ async function main() {
             return;
         }
 
-        console.log(`[Pipeline Command] Received command: ${command.type} for projectId: ${command.projectId} (Msg ID: ${message.id}, Attempt: ${message.deliveryAttempt})`);
 
         message.ack();
-
         try {
-            await projectIdStore.run(command.projectId!, async () => {
+            await logContextStore.run({
+                ...logContext,
+                projectId: command.projectId,
+                commandId: command.commandId,
+                shouldPublishLog: true
+            }, async () => {
+
+                console.log(`[Pipeline Command] Received command: ${command.type} for projectId: ${command.projectId} (Msg ID: ${message.id}, Attempt: ${message.deliveryAttempt})`);
                 switch (command.type) {
                     case "START_PIPELINE":
                         await handleStartPipelineCommand(command, workflowOperator);
@@ -248,6 +266,7 @@ async function main() {
         }
     });
 
+
     process.on("SIGINT", async () => {
         console.log("Shutting down worker...");
         workerEventsSubscription.close();
@@ -278,6 +297,8 @@ async function main() {
         console.error(`[Pipeline ${workerId}] Service cannot start without PubSub. Shutting down...`);
         process.exit(1);
     }
+    });
+
 }
 
 main().catch(console.error);
diff --git a/src/pipeline/project-repository.ts b/src/pipeline/project-repository.ts
index 2efc696..9a9572d 100644
--- a/src/pipeline/project-repository.ts
+++ b/src/pipeline/project-repository.ts
@@ -4,7 +4,7 @@ import { eq, asc, inArray, sql, } from "drizzle-orm";
 import {
     Scene, Location, Project, InitialProject,
     Character,
-} from "../shared/types/pipeline.types";
+} from "../shared/types/workflow.types";
 import {
     DbProjectSchema, DbSceneSchema, DbCharacterSchema, DbLocationSchema, ProjectEntity,
 } from "../shared/zod-db";
@@ -18,8 +18,9 @@ export class ProjectRepository {
     async getProjects() {
         const records = await db.select({
             id: projects.id,
-            metadata: projects.metadata,
-        }).from(projects);
+            metadata: { title: sql`${projects.metadata}->>'title'`.as('title'), }
+        })
+            .from(projects);
         return records;
     }
 
diff --git a/src/pipeline/services/command-handler.ts b/src/pipeline/services/command-handler.ts
index d2aec1e..aab859b 100644
--- a/src/pipeline/services/command-handler.ts
+++ b/src/pipeline/services/command-handler.ts
@@ -3,7 +3,7 @@ import { projects, scenes, jobs } from "../../shared/schema";
 import { 
   RegenerateSceneCommand, 
   UpdateSceneAssetCommand 
-} from "../../shared/types/pubsub.types";
+} from "../../shared/types/pipeline.types";
 import { eq, sql } from "drizzle-orm";
 
 export const PipelineCommandHandler = {
diff --git a/src/pipeline/services/job-control-plane.ts b/src/pipeline/services/job-control-plane.ts
index 9ba9e0a..d2b2c40 100644
--- a/src/pipeline/services/job-control-plane.ts
+++ b/src/pipeline/services/job-control-plane.ts
@@ -1,4 +1,4 @@
-import { JobState, JobEvent, JobType, JobRecord } from "../../shared/types/job-types";
+import { JobState, JobEvent, JobType, JobRecord } from "../../shared/types/job.types";
 import { PoolManager } from "./pool-manager";
 import { v7 as uuidv7 } from "uuid";
 import { db } from "../../shared/db";
diff --git a/src/pipeline/services/workflow-service.ts b/src/pipeline/services/workflow-service.ts
index efea8a1..f1c43c8 100644
--- a/src/pipeline/services/workflow-service.ts
+++ b/src/pipeline/services/workflow-service.ts
@@ -1,5 +1,5 @@
-import { PipelineCommand, PipelineEvent } from "../../shared/types/pubsub.types";
-import { InitialProject, Project, WorkflowState, InitialProjectMetadata, InitialStoryboard } from "../../shared/types/pipeline.types";
+import { PipelineCommand, PipelineEvent } from "../../shared/types/pipeline.types";
+import { InitialProject, Project, WorkflowState, InitialProjectMetadata, InitialStoryboard } from "../../shared/types/workflow.types";
 import { CinematicVideoWorkflow } from "../../workflow/graph";
 import { CheckpointerManager } from "../../workflow/checkpointer-manager";
 import { RunnableConfig } from "@langchain/core/runnables";
@@ -117,7 +117,7 @@ export class WorkflowOperator {
             jobIds: {},
             currentSceneIndex: inserted.currentSceneIndex,
             errors: [],
-        };
+        }; 
         const compiled = await this.getCompiledGraph(projectId, this.getAbortController(projectId));
         await streamWithInterruptHandling(projectId, compiled, state, config, "startPipeline", this.publishEvent);
     }
@@ -138,6 +138,7 @@ export class WorkflowOperator {
             });
             return;
         }
+        // const command = new Command({ resume: updatedState });
         const compiledGraph = await this.getCompiledGraph(projectId, this.getAbortController(projectId));
         await streamWithInterruptHandling(projectId, compiledGraph, null, config, "resumePipeline", this.publishEvent);
     }
diff --git a/src/pipeline/tests/job-control-plane.test.ts b/src/pipeline/tests/job-control-plane.test.ts
index 12497f1..b3c0d80 100644
--- a/src/pipeline/tests/job-control-plane.test.ts
+++ b/src/pipeline/tests/job-control-plane.test.ts
@@ -1,7 +1,7 @@
 import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
 import { JobControlPlane } from '../services/job-control-plane';
 import { PoolManager } from '../services/pool-manager';
-import { JobEvent, JobRecord } from '../../shared/types/job-types';
+import { JobEvent, JobRecord } from '../../shared/types/job.types';
 
 // Mock PoolManager
 vi.mock('./pool-manager');
diff --git a/src/server/index.ts b/src/server/index.ts
index 6afc5c0..8d32fdd 100644
--- a/src/server/index.ts
+++ b/src/server/index.ts
@@ -4,8 +4,18 @@ import { serveStatic } from "./static";
 import { createServer } from "http";
 import { Storage } from "@google-cloud/storage";
 import * as dotenv from "dotenv";
+
+import { formatLoggers, logContextStore } from "@shared/format-loggers";
+import { contextMiddleware } from "./middle/context-handler";
+
+
+
 dotenv.config();
 
+formatLoggers(
+  { getStore: logContextStore.getStore.bind(logContextStore) },
+);
+
 const app = express();
 const httpServer = createServer(app);
 
@@ -13,7 +23,6 @@ const gcpProjectId = process.env.GCP_PROJECT_ID;
 const bucketName = process.env.GCP_BUCKET_NAME;
 
 if (!gcpProjectId) throw Error("A projectId was not provided");
-
 if (!bucketName) throw Error("A bucket name was not provided");
 
 const bucket = new Storage({ projectId: gcpProjectId }).bucket(bucketName);
@@ -24,47 +33,28 @@ declare module "http" {
   }
 }
 
-app.use(
-  express.json({
-    verify: (req, _res, buf) => {
-      req.rawBody = buf;
-    },
-  }),
-);
-
+app.use(express.json({
+  verify: (req, _res, buf) => {
+    req.rawBody = buf;
+  },
+}));
 app.use(express.urlencoded({ extended: false }));
 
-export function log(message: string, source = "express") {
-  const formattedTime = new Date().toLocaleTimeString("en-US", {
-    hour: "numeric",
-    minute: "2-digit",
-    second: "2-digit",
-    hour12: true,
-  });
-
-  console.log(`${formattedTime} [${source}] ${message}`);
-}
+app.use(contextMiddleware);
 
 app.use((req, res, next) => {
   const start = Date.now();
-  const path = req.path;
-  let responsePayloadJson: Record<string, any> | undefined = undefined;
 
   const originalResJson = res.json;
   res.json = function (bodyJson, ...args) {
-    responsePayloadJson = bodyJson;
-    return originalResJson.apply(res, [ bodyJson, ...args ]);
-  };
+    (res as any).locals.logBody = bodyJson;
+    return originalResJson.apply(res, [ bodyJson, ...args ]);  };
 
   res.on("finish", () => {
     const duration = Date.now() - start;
-    if (path.startsWith("/api")) {
-      let apiLogMessage = `${req.method} ${path} ${res.statusCode} in ${duration}ms`;
-      if (responsePayloadJson) {
-        apiLogMessage += ` :: ${JSON.stringify(responsePayloadJson)}`;
-      }
-
-      log(apiLogMessage);
+    if (req.path.startsWith("/api")) {      const body = (res as any).locals.logBody;
+      const bodyStr = body ? ` :: ${JSON.stringify(body)}` : "";
+      console.log(`${req.method} ${req.path} ${res.statusCode} in ${duration}ms${bodyStr}`);
     }
   });
 
@@ -79,8 +69,13 @@ app.use((req, res, next) => {
       const status = err.status || err.statusCode || 500;
       const message = err.message || "Internal Server Error";
 
+      console.error(`API Error: ${message}`, {
+        status,
+        stack: err.stack,
+        path: _req.path
+      });
+
       res.status(status).json({ message });
-      throw err;
     });
 
     if (process.env.NODE_ENV === "production") {
@@ -90,10 +85,6 @@ app.use((req, res, next) => {
       await setupVite(httpServer, app);
     }
 
-    // ALWAYS serve the app on the port specified in the environment variable PORT
-    // Other ports are firewalled. Default to 5000 if not specified.
-    // this serves both the API and the client.
-    // It is the only port that is not firewalled.
     const port = parseInt(process.env.PORT || "8000", 10);
     httpServer.listen(
       {
@@ -101,18 +92,18 @@ app.use((req, res, next) => {
         host: "0.0.0.0",
       },
       () => {
-        log(`serving on port ${port}`);
+        console.log(`serving on port ${port}`);
       },
     );
 
     if (import.meta.hot) {
       import.meta.hot.on("vite:beforeFullReload", () => {
-        log("Stopping server for reload...");
+        console.log("Stopping server for reload...");
         httpServer.close();
       });
 
       import.meta.hot.dispose(() => {
-        log("Disposing server...");
+        console.log("Disposing server...");
         httpServer.close();
       });
     }
diff --git a/src/server/middle/context-handler.ts b/src/server/middle/context-handler.ts
new file mode 100644
index 0000000..9a92e8e
--- /dev/null
+++ b/src/server/middle/context-handler.ts
@@ -0,0 +1,18 @@
+// src/middleware/context-handler.ts
+import { LogContext, logContextStore } from "../../shared/format-loggers";
+
+export function contextMiddleware(req: any, res: any, next: () => void) {
+    const context: LogContext = {
+        correlationId: req.headers[ "x-correlation-id" ],
+        projectId: req.headers[ "x-project-id" ],
+        workerId: `${process.env.HOSTNAME || 'express'}-${process.pid}`,
+        shouldPublishLog: false,
+        method: req.method,
+        url: req.path
+    };
+
+    logContextStore.run(context, () => {
+        // res.setHeader("X-Correlation-ID", context.correlationId);
+        next();
+    });
+}
\ No newline at end of file
diff --git a/src/server/routes.ts b/src/server/routes.ts
index f5ef6cb..85fe62d 100644
--- a/src/server/routes.ts
+++ b/src/server/routes.ts
@@ -7,7 +7,7 @@ import {
   PIPELINE_EVENTS_TOPIC_NAME,
   SERVER_PIPELINE_EVENTS_SUBSCRIPTION
 } from "../shared/constants";
-import { PipelineCommand, PipelineEvent } from "../shared/types/pubsub.types";
+import { PipelineCommand, PipelineEvent } from "../shared/types/pipeline.types";
 import { v7 as uuidv7 } from "uuid";
 import { Bucket } from "@google-cloud/storage";
 import multer from "multer";
diff --git a/src/server/tests/concurrency.test.ts b/src/server/tests/concurrency.test.ts
new file mode 100644
index 0000000..88e254f
--- /dev/null
+++ b/src/server/tests/concurrency.test.ts
@@ -0,0 +1,70 @@
+import { describe, it, expect, vi, beforeEach } from 'vitest';
+import { LogContext, logContextStore } from '../../shared/format-loggers';
+import { formatLoggers } from '../../shared/format-loggers';
+
+describe('Concurrency & Context Integrity', () => {
+    const mockPublish = vi.fn();
+
+    beforeEach(() => {
+        vi.clearAllMocks();
+        // Initialize the interceptor
+        formatLoggers(
+            { getStore: logContextStore.getStore.bind(logContextStore) },
+            mockPublish
+        );
+    });
+
+    it('should maintain strict context isolation under high concurrency', async () => {
+        const concurrentRequests = 100;
+
+        const runTask = async (id: number) => {
+            const context: LogContext = {
+                workerId: "test-worker",
+                jobId: `job-${id}`,
+                projectId: `project-${id}`,
+                correlationId: `corr-${id}`,
+                shouldPublishLog: true
+            };
+
+            return new Promise<void>((resolve) => {
+                logContextStore.run(context, async () => {
+                    // Simulate random async delay to force event loop interleaving
+                    await new Promise(r => setTimeout(r, Math.random() * 50));
+
+                    // Trigger the intercepted console.log
+                    console.log(`Executing task ${id}`);
+
+                    resolve();
+                });
+            });
+        };
+
+        // Execute 100 tasks in parallel
+        await Promise.all(Array.from({ length: concurrentRequests }).map((_, i) => runTask(i)));
+
+        // Verify results
+        expect(mockPublish).toHaveBeenCalledTimes(concurrentRequests);
+
+        // Verify that every single call had the correct matching IDs
+        mockPublish.mock.calls.forEach((call) => {
+            const event = call[ 0 ];
+            const idMatch = event.correlationId.match(/corr-(\d+)/);
+            const id = idMatch ? idMatch[ 1 ] : null;
+
+            // Ensure the correlationId matches the IDs in the payload
+            expect(event.projectId).toBe(`project-${id}`);
+            expect(event.payload.job_id).toBe(`job-${id}`);
+        });
+    });
+
+    it('should handle context loss gracefully (Fallback Mode)', () => {
+        const spy = vi.spyOn(console, 'log');
+
+        // Log called OUTSIDE of a logContextStore.run() block
+        console.log("Startup log with no context");
+
+        expect(spy).toHaveBeenCalled();
+        // Ensure we didn't attempt to publish an event without a project ID
+        expect(mockPublish).not.toHaveBeenCalled();
+    });
+});
\ No newline at end of file
diff --git a/src/shared/format-loggers.ts b/src/shared/format-loggers.ts
new file mode 100644
index 0000000..d79a4b3
--- /dev/null
+++ b/src/shared/format-loggers.ts
@@ -0,0 +1,68 @@
+import { logger, LogContext } from './logger';
+import { format } from 'util';
+import os from 'os';
+import { AsyncLocalStorage } from 'async_hooks';
+
+
+
+export { LogContext };
+export const logContextStore = new AsyncLocalStorage<LogContext>();
+
+// Helper to determine if a log is marked as internal-only
+const isInternalLog = (args: any[]) =>
+    args.some(arg => typeof arg === 'string' && arg.includes("LOG_INTERNAL_ONLY"));
+
+export function formatLoggers(
+    store: { getStore: () => LogContext | undefined; },
+    publishPipelineEvent?: (event: any) => Promise<void>
+) {
+    const handleIntercept = async (level: string, args: any[]) => {
+        const context = store.getStore();
+
+        // 1. Format the human-readable message string (handles %s, %d, etc.)
+        const message = format(...args);
+
+        // 2. Extract any objects from args to merge into the JSON structure
+        //    (This allows console.log("Event", { userId: 1 }) to structure 'userId')
+        const objectArgs = args.find(arg => typeof arg === 'object' && arg !== null) || {};
+
+        // 3. Log locally using Pino (Structured)
+        //    We merge context first, then object args, then the readable message
+        (logger as any)[ level ]({ ...context, ...objectArgs }, message);
+
+        // 4. Determine if we should publish to the Pipeline
+        //    DEFAULT: Publish UNLESS explicitly disabled in context OR marked internal
+        const shouldPublishLog =
+            context &&
+            context.projectId &&
+            (context.shouldPublishLog !== false || !isInternalLog(args)) &&
+            publishPipelineEvent;
+
+        if (shouldPublishLog) {
+            publishPipelineEvent({
+                type: "LOG",
+                projectId: context.projectId,
+                correlationId: context.correlationId,
+                timestamp: new Date().toISOString(),
+                payload: {
+                    level,
+                    message, // The clean, formatted string
+                    job_id: context.jobId,
+                    worker_id: context.workerId,
+                    hostname: os.hostname(),
+                    process_id: process.pid,
+                    // If you really want raw args dump, put it in a specific field
+                    // raw_args: args 
+                },
+            }).catch(err => {
+                // Use a string flag to prevent infinite recursion
+                logger.error({ err, internal: true }, "LOG_INTERNAL_ONLY: Failed to publish pipeline event");
+            });
+        }
+    };
+
+    // Monkey-patch console methods
+    console.log = (...args) => handleIntercept('info', args);
+    console.warn = (...args) => handleIntercept('warn', args);
+    console.error = (...args) => handleIntercept('error', args);
+}
\ No newline at end of file
diff --git a/src/shared/logger.ts b/src/shared/logger.ts
new file mode 100644
index 0000000..48990e8
--- /dev/null
+++ b/src/shared/logger.ts
@@ -0,0 +1,43 @@
+import pino from 'pino';
+import os from 'os';
+
+
+
+export interface LogContext {
+    commandId?: string;
+    jobId?: string;
+    projectId?: string;
+    workerId: string;
+    correlationId: string;
+    shouldPublishLog: boolean;
+    [ key: string ]: any;
+}
+
+const isDev = process.env.NODE_ENV !== 'production';
+
+export const logger = pino({
+    level: process.env.LOG_LEVEL || 'info',
+    // Mix in global worker context to every log
+    mixin() {
+        return { worker_id: `${os.hostname()}-${process.pid}` };
+    },
+    formatters: {
+        level: (label) => ({ level: label.toUpperCase() }),
+    },
+    // Add human-readable timestamps for machine logs too
+    base: undefined, // Removes pid/hostname from default to use our mixin format
+    timestamp: () => `,"timestamp_iso":"${new Date().toISOString()}","timestamp_human":"${new Date().toLocaleString()}"`,
+    transport: isDev ? {
+        target: 'pino-pretty',
+        options: { colorize: true, translateTime: 'SYS:standard' }
+    } : undefined,
+});
+
+/**
+ * Creates a scoped logger for a specific job or project.
+ * This ensures every log line within a job execution automatically 
+ * includes the IDs without re-typing them.
+ */
+export function createJobLogger(context: LogContext) {
+    return logger.child(context);
+}
\ No newline at end of file
diff --git a/src/shared/schema.ts b/src/shared/schema.ts
index 614f259..0a27d62 100644
--- a/src/shared/schema.ts
+++ b/src/shared/schema.ts
@@ -10,18 +10,20 @@ import {
   InitialStoryboard,
   UserSchema,
   createDefaultMetrics
-} from "./types/pipeline.types";
+} from "./types/workflow.types";
 import { z } from "zod";
-import { createTableFromZod } from "zod-to-drizzle";
 import { v7 as uuidv7 } from "uuid"; 
 
 // --- ENUMS ---
 export const assetStatusEnum = pgEnum("asset_status", [ "pending", "generating", "evaluating", "complete", "error" ]);
 export const jobStateEnum = pgEnum("job_state", [ "CREATED", "RUNNING", "COMPLETED", "FAILED", "CANCELLED" ]);
 
-export const users = createTableFromZod("users", UserSchema, {
-  dialect: "pg",
-  primaryKey: "id"
+export const users = pgTable("users", {
+  id: uuid("id").notNull().primaryKey().$defaultFn(() => uuidv7()),
+  createdAt: timestamp("created_at").defaultNow().notNull(),
+  updatedAt: timestamp("updated_at").defaultNow().notNull(),
+  name: text("name").notNull(),
+  email: text("email").notNull(),
 });
 
 export type InsertUser = typeof users.$inferInsert;
diff --git a/src/shared/types/job-types.ts b/src/shared/types/job.types.ts
similarity index 97%
rename from src/shared/types/job-types.ts
rename to src/shared/types/job.types.ts
index c7c6b41..6bd7b9a 100644
--- a/src/shared/types/job-types.ts
+++ b/src/shared/types/job.types.ts
@@ -1,5 +1,5 @@
-//shared/job-types.ts
-import { AudioAnalysis, Character, GeneratedScene, Location, Project, QualityEvaluationResult, Scene, Storyboard } from "./pipeline.types";
+//shared/job.types.ts
+import { AudioAnalysis, Character, GeneratedScene, Location, Project, QualityEvaluationResult, Scene, Storyboard } from "./workflow.types";
 
 // export type JobCommand =
 //     | CreateJobCommand
diff --git a/src/shared/types/pipeline.types.ts b/src/shared/types/pipeline.types.ts
index 34c7f8f..95331a7 100644
--- a/src/shared/types/pipeline.types.ts
+++ b/src/shared/types/pipeline.types.ts
@@ -1,721 +1,214 @@
 //shared/types/pipeline.types.ts
-import { z } from "zod";
-import { CinematographySchema, LightingSchema, TransitionTypesSchema } from "./cinematography.types";
-import { WorkflowMetricsSchema } from "./workflow-metrics.types";
-import { QualityEvaluationResult, QualityEvaluationResultSchema } from "./quality.types";
-
-
-
-export const getJsonSchema = (schema: z.ZodType) => z.toJSONSchema(schema, { target: "openapi-3.0" });
-
-// ============================================================================
-// CONSTANTS
-// ============================================================================
-
-export const VALID_DURATIONS = [ 5, 6, 7, 8 ] as const;
-export type ValidDuration = typeof VALID_DURATIONS[ number ];
-
-
-export const GcsObjectTypeSchema = z.union([
-  z.literal('final_output'),
-  z.literal('character_image'),
-  z.literal('location_image'),
-  z.literal('scene_video'),
-  z.literal('scene_start_frame'),
-  z.literal('scene_end_frame'),
-  z.literal('render_video'),
-  z.literal('composite_frame'),
-]);
-export type GcsObjectType = z.infer<typeof GcsObjectTypeSchema>;
-
-
-// ============================================================================
-// AUDIO ANALYSIS SCHEMAS (Director: Musical Structure)
-// ============================================================================
-
-export const AudioSegmentSchema = z.object({
-  startTime: z.number().describe("start time in seconds"),
-  endTime: z.number().describe("end time in seconds"),
-  duration: z.union([ z.literal(4), z.literal(6), z.literal(8) ]).describe("Duration in seconds (4, 6, or 8)"),
-  type: z.enum([ "lyrical", "instrumental", "transition", "breakdown", "solo", "climax" ]),
-  lyrics: z.string().describe("Transcribed lyrics if lyrical, empty otherwise"),
-  musicalDescription: z.string().describe("Detailed description of the sound, instruments, tempo, mood"),
-  musicChange: z.string().describe("Notable changes: key signature, tempo shift, instrumentation changes, dynamic shifts"),
-  intensity: z.enum([ "low", "medium", "high", "extreme" ]).describe("Energy level of this segment"),
-  mood: z.string().describe("Emotional tone (e.g., aggressive, melancholic, triumphant, mysterious)"),
-  tempo: z.enum([ "slow", "moderate", "fast", "very_fast" ]).describe("Pace of the music"),
-  transitionType: TransitionTypesSchema.describe("cinematic transition type"),
-  // --- NEW: GROUNDING FIELDS ---
-  audioEvidence: z.string().describe(
-    "Verifiable sonic proof from this segment (e.g., 'Heavy kick drum starts at 4.2s', 'Reverb-heavy female vocal enters', 'High-pass filter sweep')."
-  ),
-  transientImpact: z.enum([ "soft", "sharp", "explosive", "none" ]).describe(
-    "The physical nature of the audio onset at the start of this segment."
-  ),
-});
-export type AudioSegment = z.infer<typeof AudioSegmentSchema>;
-
-
-export const AudioAnalysisSchema = z.object({
-  bpm: z.number().describe("The detected beats per minute of the track."),
-  keySignature: z.string().describe("The estimated musical key (e.g., C Minor, G Major)."),
-  totalDuration: z.number().describe("Total authoritative duration in seconds."),
-  segments: z.array(AudioSegmentSchema).describe("List of segments covering 0.0 to totalDuration without gaps."),
-}).optional();
-export type AudioAnalysis = z.infer<typeof AudioAnalysisSchema> & {
-  audioGcsUri: string;
-  audioPublicUri?: string;
-};
-
-
-export const TagSchema = z.object({
-  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
-  projectId: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
-  createdAt: z.date().default(new Date()),
-  updatedAt: z.date().default(new Date()),
-});
-export type Tag = z.infer<typeof TagSchema>;
-
-
-// ============================================================================
-// ASSET VERSIONING SCHEMA
-// ============================================================================
-
-// TODO REPLACE SCENE.BESTATTEMPT AND SCENE.REJECTEDATTEMPTS
-// REMOVE STORAGEMANAGER ATTEMPT ALOGIC
-// FINISH GRAPH.TS FULL IMPL
-// MAKE A PENULTIMATE COMMIT WITH COMMENTS AND OLD CODE
-// REMOVE COMMENTS
-
-export const AssetKeySchema = z.union([
-  GcsObjectTypeSchema,
-  z.literal('enhanced_prompt'),
-  z.literal('storyboard'),
-  z.literal('scenes'),
-  z.literal('character_description'),
-  z.literal('character_prompt'),
-  z.literal('location_description'),
-  z.literal('location_prompt'),
-  z.literal('scene_description'),
-  z.literal('scene_prompt'),
-  z.literal('start_frame_prompt'),
-  z.literal('end_frame_prompt'),
-  z.literal('scene_quality_evaluation'),
-  z.literal('frame_quality_evaluation'),
-]);
-export type AssetKey = z.infer<typeof AssetKeySchema>;
-
-
-export const AssetTypeSchema = z.enum([ 'video', 'image', 'audio', 'text', 'json' ]);
-export type AssetType = z.infer<typeof AssetTypeSchema>;
-
-
-export const AssetVersionSchema = z.object({
-  version: z.number(),
-  data: z.string().describe("The content (text) or URI (file)"),
-  type: AssetTypeSchema,
-  createdAt: z.string(),
-  metadata: z.object({
-    evaluation: QualityEvaluationResultSchema.optional().describe("Quality evaluation result").nullable(),
-    model: z.string().nonoptional().describe("AI model used for asset generation")
-  }).catchall(z.any()).describe("Flexible metadata for evaluations, models, etc."),
-});
-export type AssetVersion = z.infer<typeof AssetVersionSchema>;
-
-
-export const AssetHistorySchema = z.object({
-  head: z.number().default(0).describe("The highest version number created"),
-  best: z.number().default(0).describe("The version currently selected as active/best"),
-  versions: z.array(AssetVersionSchema).default([]),
-});
-export type AssetHistory = z.infer<typeof AssetHistorySchema>;
-
-
-export const AssetRegistrySchema = z.partialRecord(AssetKeySchema, AssetHistorySchema).describe("The core registry map to be used in Projects, Scenes, Locations, and Characters").default({});
-export type AssetRegistry = z.infer<typeof AssetRegistrySchema>;
-
-
-// ============================================================================
-// SCENE SCHEMAS
-// ============================================================================
-
-export const DirectorSceneSchema = z.object({
-  description: z.string().describe("Detailed description of scene's narrative elements"),
-  mood: z.string().describe("overall emotional tone combining music and narrative"),
-  audioSync: z.string().optional().describe("how visuals sync with audio (Lip Sync, Mood Sync, Beat Sync)"),
-}).describe("Director specifications for scene");
-export type DirectorScene = z.infer<typeof DirectorSceneSchema>;
-
-
-export const ScriptSupervisorSceneSchema = z.object({
-  continuityNotes: z.array(z.string()).optional().describe("continuity requirements").default([]),
-  characters: z.array(z.string()).describe("list of character IDs present in scene").default([]),
-  locationId: z.string().describe("ID of the location where scene takes place"),
-}).describe("Script Supervisor specifications for scene");
-export type ScriptSupervisorScene = z.infer<typeof ScriptSupervisorSceneSchema>;
-
-
-export const AssetStatusSchema = z.enum([ "pending", "generating", "evaluating", "complete", "error" ]);
-export type AssetStatus = z.infer<typeof AssetStatusSchema>;
-
-
-export const SceneStatusSchema = z.object({
-  status: AssetStatusSchema,
-  progressMessage: z.string().optional().describe("Real-time progress message during generation"),
-});
-export type SceneStatus = z.infer<typeof SceneStatusSchema>;
-
-
-export const SceneSchema = z.object({
-  ...TagSchema.shape,
-  ...AudioSegmentSchema.shape,
-  ...DirectorSceneSchema.shape,
-  ...CinematographySchema.shape,
-  ...ScriptSupervisorSceneSchema.shape,
-  ...SceneStatusSchema.shape,
-  lighting: LightingSchema,
-  sceneIndex: z.number().describe("Index of the scene in the storyboard"),
-  assets: AssetRegistrySchema,
-}).describe("Composition of all department specs + audio timing + generation outputs");
-export type Scene = z.infer<typeof SceneSchema>;
-
-
-export interface SceneGenerationInput {
-  scene: Scene;
-  enhancedPrompt: string;
-}
-
-
-export type GeneratedScene = Scene & {
-  enhancedPrompt: string;
-};
-
-
-export interface SceneGenerationResult {
-  scene: GeneratedScene;
-  videoUrl?: string;
-  attempts: number;
-  finalScore: number;
-  evaluation: QualityEvaluationResult | null;
-  warning?: string;
-  acceptedAttempt: number;
-}
-
-
-export interface FrameGenerationResult {
-  frame: string;
-  attempts: number;
-  finalScore: number;
-  evaluation: QualityEvaluationResult | null;
-  warning?: string;
-}
-
-
-export interface VideoGenerationConfig {
-  resolution: "480p" | "720p" | "1080p";
-  durationSeconds: 4 | 6 | 8;
-  numberOfVideos: number;
-  personGeneration: "ALLOW_ALL" | "DONT_ALLOW";
-  generateAudio: boolean;
-  negativePrompt?: string;
-}
-
-
-// ============================================================================
-// METADATA SCHEMAS
-// ============================================================================
-
-/**
- * InitialProjectMetadataSchema: Loose schema for project creation/insertion.
- * Only `projectId` and `initialPrompt` are strictly required.
- * Other fields have defaults or are optional - populated during workflow.
- */
-export const InitialProjectMetadataSchema = z.object({
-  projectId: z.uuid({ version: "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
-  title: z.string().default("").describe("title of the video"),
-  duration: z.number().default(0).describe("total duration in seconds"),
-  totalScenes: z.number().default(0).describe("total number of scenes"),
-  style: z.string().default("").describe("inferred cinematic style"),
-  mood: z.string().default("").describe("overall emotional arc"),
-  colorPalette: z.array(z.string()).default([]).describe("dominant colors"),
-  tags: z.array(z.string()).default([]).describe("descriptive tags"),
-
-  models: z.object({
-    videoModel: z.string().optional().describe("AI model used for video generation"),
-    imageModel: z.string().optional().describe("AI model used for image generation"),
-    textModel: z.string().optional().describe("AI model used for text generation"),
-    qaModel: z.string().optional().describe("AI model used for quality evaluation"),
-  }).default({}),
-
-  initialPrompt: z.string().describe("original creative prompt"),
-  enhancedPrompt: z.string().optional().describe("enhanced user prompt with narrative, characters, settings"),
-  audioGcsUri: z.string().optional().describe("GCS URI of uploaded audio file"),
-  audioPublicUri: z.string().optional().describe("audio file public url"),
-  hasAudio: z.boolean().default(false).describe("whether this workflow has user-provided audio"),
-});
-export type InitialProjectMetadata = z.infer<typeof InitialProjectMetadataSchema>;
-
-
-/**
- * ProjectMetadataSchema: Strict schema for runtime application logic.
- * All fields are required (no optionals except audio-related fields).
- * Used after storyboard generation when metadata is fully populated.
- */
-export const ProjectMetadataSchema = z.object({
-  projectId: z.uuid({ version: "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
-  title: z.string().describe("title of the video"),
-  duration: z.number().describe("total duration in seconds"),
-  totalScenes: z.number().describe("total number of scenes"),
-  style: z.string().describe("inferred cinematic style"),
-  mood: z.string().describe("overall emotional arc"),
-  colorPalette: z.array(z.string()).describe("dominant colors"),
-  tags: z.array(z.string()).describe("descriptive tags"),
-
-  models: z.object({
-    videoModel: z.string().optional().describe("AI model used for video generation"),
-    imageModel: z.string().optional().describe("AI model used for image generation"),
-    textModel: z.string().optional().describe("AI model used for text generation"),
-    qaModel: z.string().optional().describe("AI model used for quality evaluation"),
-  }),
-
-  initialPrompt: z.string().describe("original creative prompt"),
-  enhancedPrompt: z.string().describe("enhanced user prompt with narrative, characters, settings"),
-  audioGcsUri: z.string().optional().describe("GCS URI of uploaded audio file"),
-  audioPublicUri: z.string().optional().describe("audio file public url"),
-  hasAudio: z.boolean().describe("whether this workflow has user-provided audio"),
-});
-export type ProjectMetadata = z.infer<typeof ProjectMetadataSchema>;
-
-
-// ============================================================================
-// CHARACTER SCHEMAS (Costume & Makeup Dept)
-// ============================================================================
-
-export const PhysicalTraitsSchema = z.object({
-  hair: z.string().describe("specific hairstyle, color, length, texture"),
-  clothing: z.union([
-    z.string(),
-    z.array(z.string())
-  ]).describe("specific outfit description (string or array of garments)"),
-  accessories: z.array(z.string()).describe("list of accessories").default([]),
-  distinctiveFeatures: z.array(z.string()).describe("list of distinctive features").default([]),
-  build: z.string().optional().describe("physical build description"),
-  ethnicity: z.string().optional().describe("ethnicity description (generic, non-specific)"),
-});
-export type PhysicalTraits = z.infer<typeof PhysicalTraitsSchema>;
-
-
-// Enhanced: Temporal state tracking for Script Supervisor with progressive changes
-export const CharacterStateSchema = z.object({
-  lastSeen: z.string().optional().describe("scene ID where character was last seen"),
-
-  // Spatial continuity
-  position: z.string().optional().describe("character's spatial position: left/center/right, foreground/background"),
-  lastExitDirection: z.enum([ "left", "right", "up", "down", "none" ]).optional().describe("direction character exited frame in previous scene"),
-
-  // Emotional progression
-  emotionalState: z.string().optional().describe("character's current emotional state"),
-  emotionalHistory: z.array(z.object({
-    sceneId: z.string(),
-    emotion: z.string(),
-  })).optional().default([]).describe("emotional state timeline across scenes"),
-
-  // Physical condition progression
-  physicalCondition: z.string().optional().describe("accumulated damage, dirt, exhaustion"),
-  injuries: z.array(z.object({
-    type: z.string(),
-    location: z.string(),
-    severity: z.enum([ "minor", "moderate", "severe" ]),
-    acquiredInScene: z.number(), // Using sceneIndex for temporal logic
-  })).optional().default([]).describe("injuries that persist across scenes"),
-
-  // Appearance changes
-  dirtLevel: z.enum([ "clean", "slightly_dirty", "dirty", "very_dirty", "covered" ]).optional().default("clean").describe("accumulation of dirt, mud, dust"),
-  exhaustionLevel: z.enum([ "fresh", "slightly_tired", "tired", "exhausted", "collapsing" ]).optional().default("fresh").describe("progressive fatigue"),
-  sweatLevel: z.enum([ "dry", "slight", "moderate", "heavy", "drenched" ]).optional().default("dry").describe("perspiration level"),
-
-  // Costume state progression
-  costumeCondition: z.object({
-    tears: z.array(z.string()).optional().default([]).describe("torn areas (e.g., 'sleeve torn', 'pants ripped at knee')"),
-    stains: z.array(z.string()).optional().default([]).describe("stains (e.g., 'blood on shirt', 'mud on pants')"),
-    wetness: z.enum([ "dry", "damp", "wet", "soaked" ]).optional().default("dry").describe("moisture level of clothing"),
-    damage: z.array(z.string()).optional().default([]).describe("other damage (e.g., 'burned collar', 'missing button')"),
-  }).optional().describe("progressive costume degradation"),
-
-  // Makeup/hair changes
-  hairCondition: z.object({
-    style: z.string().optional().describe("current style (should match baseline unless narrative justification)"),
-    messiness: z.enum([ "pristine", "slightly_messy", "messy", "disheveled", "wild" ]).optional().default("pristine"),
-    wetness: z.enum([ "dry", "damp", "wet", "soaked" ]).optional().default("dry"),
-  }).optional().describe("progressive hair state changes"),
-});
-export type CharacterState = z.infer<typeof CharacterStateSchema>;
-
-
-export const CharacterSchema = z.object({
-  ...TagSchema.shape,
-
-  referenceId: z.string().describe("unique identifier for the character (e.g. char_1)"),
-  name: z.string().describe("character name"),
-  aliases: z.array(z.string()).describe("list of aliases for the character").default([]),
-  age: z.string().describe("age or age range"),
-
-  // Costume & Makeup specifications
-  physicalTraits: PhysicalTraitsSchema,
-  appearanceNotes: z.array(z.string()).describe("additional notes on appearance").default([]),
-
-  assets: AssetRegistrySchema,
-
-  // Script Supervisor state tracking (mutable)
-  state: CharacterStateSchema.optional(),
-});
-export type Character = z.infer<typeof CharacterSchema>;
-
-
-// ============================================================================
-// LOCATION SCHEMAS (Production Designer)
-// ============================================================================
-
-
-// Enhanced: Temporal state tracking for locations with progressive changes
-export const LocationStateSchema = z.object({
-  lastUsed: z.string().optional().describe("scene ID where location was last used"),
-
-  // Temporal progression
-  timeOfDay: z.string().optional().describe("current time of day (evolves across scenes)"),
-  timeHistory: z.array(z.object({
-    sceneId: z.string(),
-    timeOfDay: z.string(),
-  })).optional().default([]).describe("time progression timeline"),
-
-  // Weather progression
-  weather: z.string().optional().describe("current weather conditions"),
-  weatherHistory: z.array(z.object({
-    sceneId: z.string(),
-    weather: z.string(),
-    intensity: z.enum([ "light", "moderate", "heavy", "extreme" ]).optional(),
-  })).optional().default([]).describe("weather evolution across scenes"),
-  precipitation: z.enum([ "none", "light", "moderate", "heavy" ]).optional().default("none").describe("current precipitation level"),
-  visibility: z.enum([ "clear", "slight_haze", "hazy", "foggy", "obscured" ]).optional().default("clear").describe("atmospheric visibility"),
-
-  // Lighting progression
-  lighting: LightingSchema,
-  lightingHistory: z.array(z.object({
-    sceneId: z.string(),
-    lighting: LightingSchema,
-  })).optional().default([]).describe("lighting changes timeline"),
-
-  // Environmental state changes
-  groundCondition: z.object({
-    wetness: z.enum([ "dry", "damp", "wet", "soaked", "flooded" ]).optional().default("dry"),
-    debris: z.array(z.string()).optional().default([]).describe("accumulated debris (e.g., 'broken glass', 'fallen leaves')"),
-    damage: z.array(z.string()).optional().default([]).describe("environmental damage (e.g., 'crater', 'burn marks')"),
-  }).optional().describe("progressive ground surface changes"),
-
-  // Object/prop persistence
-  brokenObjects: z.array(z.object({
-    object: z.string(),
-    description: z.string(),
-    brokenInScene: z.number(), // Using sceneIndex for temporal logic
-  })).optional().default([]).describe("objects that remain broken across scenes"),
-
-  // Atmospheric effects
-  atmosphericEffects: z.array(z.object({
-    type: z.string().describe("smoke, fog, dust, steam, etc."),
-    intensity: z.enum([ "light", "moderate", "heavy" ]),
-    addedInScene: z.number(), // Using sceneIndex for temporal logic
-    dissipating: z.boolean().optional().default(false),
-  })).optional().default([]).describe("lingering atmospheric effects"),
-
-  // Temperature/season indicators (for consistency)
-  season: z.enum([ "spring", "summer", "fall", "winter", "unspecified" ]).optional().describe("seasonal context for consistency"),
-  temperatureIndicators: z.array(z.string()).optional().default([]).describe("visual temperature cues (e.g., 'frost on windows', 'heat shimmer')"),
-});
-export type LocationState = z.infer<typeof LocationStateSchema>;
-
-
-export const LocationSchema = z.object({
-  ...TagSchema.shape,
-
-  referenceId: z.string().describe("narrative-scoped identifier for the location (e.g., loc_1)"),
-  name: z.string().describe("location name"),
-  type: z.string().optional().describe("location type (beach, urban, warehouse, etc.)"),
-
-  // Production Designer specifications (baseline/initial state)
-  lightingConditions: LightingSchema,
-  timeOfDay: z.string().describe("initial time of day"),
-  weather: z.string().describe("initial weather conditions").default("Clear"),
-  colorPalette: z.array(z.string()).describe("dominant colors").default([]),
-  mood: z.string().describe("atmospheric mood"),
-
-  // Environmental elements (baseline)
-  architecture: z.string().describe("architectural features"),
-  naturalElements: z.array(z.string()).describe("natural elements in scene").default([]),
-  manMadeObjects: z.array(z.string()).describe("man-made objects in scene").default([]),
-  groundSurface: z.string().describe("ground surface description"),
-  skyOrCeiling: z.string().describe("sky or ceiling description"),
-
-  assets: AssetRegistrySchema,
-
-  // Script Supervisor state tracking (mutable, evolves across scenes)
-  state: LocationStateSchema.optional(),
-});
-export type Location = z.infer<typeof LocationSchema>;
-
-
-// ============================================================================
-// STORYBOARD ENRICHMENT SCHEMA
-// ============================================================================
-
-/**
- * InitialStoryboardSchema: Loose schema for project creation.
- * Uses InitialProjectMetadataSchema and allows empty arrays.
- */
-export const InitialStoryboardSchema = z.object({
-  metadata: InitialProjectMetadataSchema,
-  characters: z.array(CharacterSchema).default([]),
-  locations: z.array(LocationSchema).default([]),
-  scenes: z.array(SceneSchema).default([]),
-});
-export type InitialStoryboard = z.infer<typeof InitialStoryboardSchema>;
-
-
-/**
- * StoryboardSchema: Strict schema for immutable storyboard snapshot.
- * Uses ProjectMetadataSchema and requires populated arrays.
- */
-export const StoryboardSchema = z.object({
-  metadata: ProjectMetadataSchema,
-  characters: z.array(CharacterSchema),
-  locations: z.array(LocationSchema),
-  scenes: z.array(SceneSchema),
-}).readonly();
-export type Storyboard = z.infer<typeof StoryboardSchema>;
-
-
-export const InitialContextSchema = z.object({
-  metadata: InitialProjectMetadataSchema,
-  characters: z.array(CharacterSchema),
-  locations: z.array(LocationSchema),
-});
-
-
-export const SceneBatchSchema = z.object({
-  scenes: z.array(SceneSchema)
-});
-
-
-/**
- * Default WorkflowMetrics factory for project creation.
- */
-export const createDefaultMetrics = (): z.infer<typeof WorkflowMetricsSchema> => ({
-  sceneMetrics: [],
-  attemptMetrics: [],
-  trendHistory: [],
-  regression: {
-    count: 0,
-    sumX: 0,
-    sumY_a: 0,
-    sumY_q: 0,
-    sumXY_a: 0,
-    sumXY_q: 0,
-    sumX2: 0,
-  },
-});
-
-
-/**
- * InitialProjectSchema: Minimal schema for DB insertion.
- * Uses loose metadata and storyboard schemas with defaults.
- * This is the type used before storyboard generation completes.
- */
-export const InitialProjectSchema = z.object({
-  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
-  createdAt: z.date().default(new Date()),
-  updatedAt: z.date().default(new Date()),
-
-  // Loose storyboard and metadata
-  storyboard: InitialStoryboardSchema.describe("The initial storyboard plan (empty at creation)"),
-  metadata: InitialProjectMetadataSchema.describe("Production metadata (partial at creation)"),
-
-  // Workflow control with defaults
-  status: AssetStatusSchema.default("pending"),
-  currentSceneIndex: z.number().default(0).describe("Index of scene currently being processed"),
-  forceRegenerateSceneIds: z.array(z.string()).default([]).describe("List of scene IDs to force video regenerate"),
-
-  assets: AssetRegistrySchema.default({}),
-  generationRules: z.array(z.string()).default([]).describe("generation rule guidelines"),
-  generationRulesHistory: z.array(
-    z.array(z.string()).default([])
-  ).default([]).describe("history of generation rule guidelines"),
-
-  // Optional at creation - populated during workflow
-  characters: z.array(CharacterSchema).optional(),
-  locations: z.array(LocationSchema).optional(),
-  scenes: z.array(SceneSchema).optional(),
-  metrics: WorkflowMetricsSchema.optional(),
-});
-export type InitialProject = z.infer<typeof InitialProjectSchema>;
-
-
-/**
- * ProjectSchema: Strict schema for runtime application logic.
- * All fields required. Used after storyboard generation completes.
- * NOT an extension of InitialProjectSchema - standalone strict definition.
- */
-export const ProjectSchema = z.object({
-  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
-  createdAt: z.date().default(new Date()),
-  updatedAt: z.date().default(new Date()),
-
-  // Strict storyboard and metadata
-  storyboard: StoryboardSchema.describe("The immutable storyboard snapshot"),
-  metadata: ProjectMetadataSchema.describe("Fully populated production metadata"),
-
-  // Workflow control
-  status: AssetStatusSchema,
-  currentSceneIndex: z.number().describe("Index of scene currently being processed"),
-  forceRegenerateSceneIds: z.array(z.string()).describe("List of scene IDs to force video regenerate"),
-
-  assets: AssetRegistrySchema,
-  generationRules: z.array(z.string()).describe("generation rule guidelines"),
-  generationRulesHistory: z.array(
-    z.array(z.string())
-  ).describe("history of generation rule guidelines"),
-
-  // Required at runtime - hydrated from DB
-  characters: z.array(CharacterSchema),
-  locations: z.array(LocationSchema),
-  scenes: z.array(SceneSchema),
-  metrics: WorkflowMetricsSchema,
-});
-export type Project = z.infer<typeof ProjectSchema>;
-
-
-export type ErrorRecord = {
-  node: string;
-  error: string;
-  skipped: boolean;
-  timestamp: string;
+import { Project, InitialProject, Scene, AssetStatus, AssetKey, AttemptMetric } from "./workflow.types.ts";
+
+export type PubSubMessage<T extends string, P = undefined> = P extends undefined ? {
+    type: T;
+    projectId: string;
+    commandId?: string;
+    timestamp: string;
+} : {
+    type: T;
+    projectId: string;
+    commandId?: string;
+    timestamp: string;
+    payload: P;
 };
 
-
-// ============================================================================
-// USER SCHEMA
-// ============================================================================
-
-export const UserSchema = z.object({
-  id: z.uuid({ "version": "v7" }),
-  name: z.string(),
-  email: z.email().optional(),
-  createdAt: z.string().default(new Date().toISOString()),
-  updatedAt: z.string().default(new Date().toISOString()),
-});
-
-
-// ============================================================================
-// WORKFLOW STATE
-// ============================================================================
-
-export const WorkflowStateSchema = z.object({
-  ...TagSchema.shape,
-
-  initialProject: z.union([InitialProjectSchema, z.null()]),
-  project: z.union([ProjectSchema, z.null()]),
-    
-  localAudioPath: z.string().optional().describe("user-provided audio filepath"),
-  hasAudio: z.boolean().default(false).describe("whether this workflow uses audio"),
-
-  // Transient execution data
-  jobIds: z.record(z.string(), z.string()).describe("Active generative worker jobs"),
-  currentSceneIndex: z.number().describe("index of scene currently being processed").default(0),
-  nodeAttempts: z.record(z.string(), z.number()).describe("Count of node executions inthe current workflow"),
-
-  errors: z.array(z.object({
-    node: z.string(),
-    message: z.string(),
-    value: z.record(z.string(), z.any()),
-    shouldRetry: z.boolean(),
-    timestamp: z.string(),
-  })).describe("errors encountered during workflow").default([]),
-});
-export type WorkflowState = Omit<z.infer<typeof WorkflowStateSchema>, "createdAt" | "updatedAt"> & {
-  __interrupt__?: { value: LlmRetryInterruptValue; }[];
-  __interrupt_resolved__?: boolean;
+// ===== COMMANDS (Client -> Server -> Pipeline) =====
+
+export type PipelineCommand =
+    | StartPipelineCommand
+    | RequestFullStateCommand
+    | ResumePipelineCommand
+    | StopPipelineCommand
+    | RegenerateSceneCommand
+    | RegenerateFrameCommand
+    | ResolveInterventionCommand
+    | UpdateSceneAssetCommand;
+
+export type StartPipelineCommand = {
+    type: "START_PIPELINE";
+    projectId?: string;
+    commandId?: string;
+    timestamp: string;
+    payload: {
+        audioGcsUri?: string;
+        audioPublicUri?: string;
+        initialPrompt: string;
+        title?: string;
+    };
 };
 
-
-// ============================================================================
-// UTILITY TYPES
-// ============================================================================
-
-export interface ContinuityCheck {
-  characterConsistency: boolean;
-  locationConsistency: boolean;
-  timingConsistency: boolean;
-  issues: string[];
-}
-
-// ============================================================================
-// TYPE GUARDS
-// ============================================================================
-
-export function isValidDuration(duration: number): duration is 4 | 6 | 8 {
-  return duration === 4 || duration === 6 || duration === 8;
-}
-
-
-export function isLyricalScene(scene: Scene): boolean {
-  return (
-    scene.audioSync === "Lip Sync" ||
-    (scene.lyrics && scene.lyrics.length > 0) ||
-    false
-  );
-}
-
-
-export function isInstrumentalScene(scene: Scene): boolean {
-  return (
-    scene.audioSync === "Mood Sync" ||
-    scene.description?.includes("[Instrumental") ||
-    false
-  );
-}
-
-
-export function requiresTransition(scene: Scene): boolean {
-  return scene.transitionType !== "Cut" && scene.transitionType !== "none";
-}
-
-
-export type PipelineStatus = "ready" | "analyzing" | "generating" | "evaluating" | "complete" | "error" | "paused";
+export type RequestFullStateCommand = PubSubMessage<
+    "REQUEST_FULL_STATE",
+    (Record<string, never> | undefined)
+>;
+
+export type ResumePipelineCommand = PubSubMessage<
+    "RESUME_PIPELINE",
+    {
+        fromSceneIndex?: number;
+    } | undefined
+>;
+
+export type StopPipelineCommand = PubSubMessage<
+    "STOP_PIPELINE"
+>;
+
+export type RegenerateSceneCommand = PubSubMessage<
+    "REGENERATE_SCENE",
+    {
+        sceneId: string;
+        forceRegenerate: boolean;
+        promptModification: string;
+    }
+>;
+
+export type RegenerateFrameCommand = PubSubMessage<
+    "REGENERATE_FRAME",
+    {
+        sceneId: string;
+        frameType: "start" | "end";
+        promptModification: string;
+    }
+>;
+
+export type UpdateSceneAssetCommand = PubSubMessage<
+    "UPDATE_SCENE_ASSET",
+    {
+        scene: Scene;
+        assetKey: AssetKey;
+        version: number | null; // null means delete/reject
+    }
+>;
+
+export type ResolveInterventionCommand = PubSubMessage<
+    "RESOLVE_INTERVENTION",
+    {
+        action: "retry" | "skip" | "abort";
+        revisedParams?: Record<string, any>;
+    }
+>;
+
+
+// ===== EVENTS (Pipeline -> Server -> Client) =====
+
+export type PipelineEvent =
+    | WorkflowStartedEvent
+    | FullStateEvent
+    | SceneStartedEvent
+    | SceneProgressEvent
+    | SceneCompletedEvent
+    | SceneSkippedEvent
+    | WorkflowCompletedEvent
+    | WorkflowFailedEvent
+    | LlmInterventionNeededEvent
+    | InterventionResolvedEvent
+    | LogEvent;
+
+export type LogEvent = PubSubMessage<
+    "LOG",
+    {
+        level: "info" | "warning" | "error" | "success";
+        message: string;
+        sceneId?: string;
+    }
+>;
+
+export type WorkflowStartedEvent = PubSubMessage<
+    "WORKFLOW_STARTED",
+    {
+        project: InitialProject;
+    }
+>;
+
+export type FullStateEvent = PubSubMessage<
+    "FULL_STATE",
+    {
+        project: Project | InitialProject;
+    }
+>;
+
+export type SceneStartedEvent = PubSubMessage<
+    "SCENE_STARTED",
+    {
+        scene: Scene;
+        totalScenes: number;
+    }
+>;
+
+export type SceneProgressEvent = PubSubMessage<
+    "SCENE_PROGRESS",
+    {
+        scene: Scene;
+        progress?: number;
+    }
+>;
+
+export type SceneCompletedEvent = PubSubMessage<
+    "SCENE_COMPLETED",
+    {
+        scene: Scene;
+    }
+    >;
+
+export type SceneSkippedEvent = PubSubMessage<
+    "SCENE_SKIPPED",
+    {
+        sceneId: string;
+        reason: string;
+        videoUrl?: string;
+    }
+    >;
+
+export type WorkflowCompletedEvent = PubSubMessage<
+    "WORKFLOW_COMPLETED",
+    {
+        project: Project;
+        videoUrl: string;
+    }
+    >;
+
+export type WorkflowFailedEvent = PubSubMessage<
+    "WORKFLOW_FAILED",
+    {
+        error: string;
+        nodeName?: string;
+    }
+    >;
+
+export type LlmInterventionNeededEvent = PubSubMessage<
+    "LLM_INTERVENTION_NEEDED",
+    {
+        error: string;
+        params?: Record<string, any>;
+        functionName: string;
+        nodeName: string;
+        attemptCount?: number;
+    }
+    >;
+
+export type InterventionResolvedEvent = PubSubMessage<
+    "INTERVENTION_RESOLVED",
+    {
+        action: "retry" | "skip" | "abort";
+        nodeName: string;
+    }
+    >;
 
 
 export interface PipelineMessage {
-  id: string;
-  type: "info" | "warning" | "error" | "success";
-  message: string;
-  timestamp: Date;
-  sceneId?: string;
-}
-
-
-export interface LlmRetryInterruptValue {
-  type: "llm_retry_exhausted" | "llm_intervention" | "waiting_for_job" | "waiting_for_batch";
-  error: string;
-  errorDetails?: Record<string, any>;
-  stackTrace?: string;
-  functionName: string;
-  nodeName: string;
-  params?: Record<string, any>;
-  attempt?: number;
-  maxRetries?: number;
-  lastAttemptTimestamp: string;
+    id: string;
+    type: "info" | "warning" | "error" | "success";
+    message: string;
+    timestamp: Date;
+    sceneId?: string;
 }
+export type PipelineStatus = "ready" | "analyzing" | "generating" | "evaluating" | "complete" | "error" | "paused";
+export type StatusType = PipelineStatus | AssetStatus | "PASS" | "MINOR_ISSUES" | "MAJOR_ISSUES" | "FAIL" | "ACCEPT" | "ACCEPT_WITH_NOTES" | "REGENERATE_MINOR" | "REGENERATE_MAJOR";
 
 
-export type StatusType = PipelineStatus | AssetStatus | "PASS" | "MINOR_ISSUES" | "MAJOR_ISSUES" | "FAIL" | "ACCEPT" | "ACCEPT_WITH_NOTES" | "REGENERATE_MINOR" | "REGENERATE_MAJOR";
+export type OnProgressCallback<T> = (artifact: T) => void;
+export type OnCompleteCallback<T> = (artifact: T, attemptMetric?: Omit<AttemptMetric, 'sceneId'>) => void;
 
-export * from "./cinematography.types";
-export * from "./workflow-metrics.types";
-export * from "./quality.types";
+export * from './workflow.types.ts';
\ No newline at end of file
diff --git a/src/shared/types/pubsub.types.ts b/src/shared/types/pubsub.types.ts
deleted file mode 100644
index bcbf980..0000000
--- a/src/shared/types/pubsub.types.ts
+++ /dev/null
@@ -1,197 +0,0 @@
-//shared/types/pubsub.types.ts
-import { Project, InitialProject, Scene, AssetStatus, AssetKey } from "./pipeline.types.ts";
-
-export type PubSubMessage<T extends string, P = undefined> = P extends undefined ? {
-    type: T;
-    projectId: string;
-    commandId?: string;
-    timestamp: string;
-} : {
-    type: T;
-    projectId: string;
-    commandId?: string;
-    timestamp: string;
-    payload: P;
-};
-
-// ===== COMMANDS (Client -> Server -> Pipeline) =====
-
-export type PipelineCommand =
-    | StartPipelineCommand
-    | RequestFullStateCommand
-    | ResumePipelineCommand
-    | StopPipelineCommand
-    | RegenerateSceneCommand
-    | RegenerateFrameCommand
-    | ResolveInterventionCommand
-    | UpdateSceneAssetCommand;
-
-export type StartPipelineCommand = {
-    type: "START_PIPELINE";
-    projectId?: string;
-    commandId?: string;
-    timestamp: string;
-    payload: {
-        audioGcsUri?: string;
-        audioPublicUri?: string;
-        initialPrompt: string;
-        title?: string;
-    };
-};
-
-export type RequestFullStateCommand = PubSubMessage<
-    "REQUEST_FULL_STATE",
-    (Record<string, never> | undefined)
->;
-
-export type ResumePipelineCommand = PubSubMessage<
-    "RESUME_PIPELINE",
-    {
-        fromSceneIndex?: number;
-    } | undefined
->;
-
-export type StopPipelineCommand = PubSubMessage<
-    "STOP_PIPELINE"
->;
-
-export type RegenerateSceneCommand = PubSubMessage<
-    "REGENERATE_SCENE",
-    {
-        sceneId: string;
-        forceRegenerate: boolean;
-        promptModification: string;
-    }
->;
-
-export type RegenerateFrameCommand = PubSubMessage<
-    "REGENERATE_FRAME",
-    {
-        sceneId: string;
-        frameType: "start" | "end";
-        promptModification: string;
-    }
->;
-
-export type UpdateSceneAssetCommand = PubSubMessage<
-    "UPDATE_SCENE_ASSET",
-    {
-        scene: Scene;
-        assetKey: AssetKey;
-        version: number | null; // null means delete/reject
-    }
->;
-
-export type ResolveInterventionCommand = PubSubMessage<
-    "RESOLVE_INTERVENTION",
-    {
-        action: "retry" | "skip" | "abort";
-        revisedParams?: Record<string, any>;
-    }
->;
-
-
-// ===== EVENTS (Pipeline -> Server -> Client) =====
-
-export type PipelineEvent =
-    | WorkflowStartedEvent
-    | FullStateEvent
-    | SceneStartedEvent
-    | SceneProgressEvent
-    | SceneCompletedEvent
-    | SceneSkippedEvent
-    | WorkflowCompletedEvent
-    | WorkflowFailedEvent
-    | LlmInterventionNeededEvent
-    | InterventionResolvedEvent
-    | LogEvent;
-
-export type LogEvent = PubSubMessage<
-    "LOG",
-    {
-        level: "info" | "warning" | "error" | "success";
-        message: string;
-        sceneId?: string;
-    }
->;
-
-export type WorkflowStartedEvent = PubSubMessage<
-    "WORKFLOW_STARTED",
-    {
-        project: InitialProject;
-    }
->;
-
-export type FullStateEvent = PubSubMessage<
-    "FULL_STATE",
-    {
-        project: Project | InitialProject;
-    }
->;
-
-export type SceneStartedEvent = PubSubMessage<
-    "SCENE_STARTED",
-    {
-        scene: Scene;
-        totalScenes: number;
-    }
->;
-
-export type SceneProgressEvent = PubSubMessage<
-    "SCENE_PROGRESS",
-    {
-        scene: Scene;
-        progress?: number;
-    }
->;
-
-export type SceneCompletedEvent = PubSubMessage<
-    "SCENE_COMPLETED",
-    {
-        scene: Scene;
-    }
->;
-
-export type SceneSkippedEvent = PubSubMessage<
-    "SCENE_SKIPPED",
-    {
-        sceneId: string;
-        reason: string;
-        videoUrl?: string;
-    }
->;
-
-export type WorkflowCompletedEvent = PubSubMessage<
-    "WORKFLOW_COMPLETED",
-    {
-        project: Project;
-        videoUrl: string;
-    }
->;
-
-export type WorkflowFailedEvent = PubSubMessage<
-    "WORKFLOW_FAILED",
-    {
-        error: string;
-        nodeName?: string;
-    }
->;
-
-export type LlmInterventionNeededEvent = PubSubMessage<
-    "LLM_INTERVENTION_NEEDED",
-    {
-        error: string;
-        params?: Record<string, any>;
-        functionName: string;
-        nodeName: string;
-        attemptCount?: number;
-    }
->;
-
-export type InterventionResolvedEvent = PubSubMessage<
-    "INTERVENTION_RESOLVED",
-    {
-        action: "retry" | "skip" | "abort";
-        nodeName: string;
-    }
->;
\ No newline at end of file
diff --git a/src/shared/types/workflow.types.ts b/src/shared/types/workflow.types.ts
new file mode 100644
index 0000000..3ab4375
--- /dev/null
+++ b/src/shared/types/workflow.types.ts
@@ -0,0 +1,709 @@
+//shared/types/pipeline.types.ts
+import { z } from "zod";
+import { CinematographySchema, LightingSchema, TransitionTypesSchema } from "./cinematography.types";
+import { WorkflowMetricsSchema } from "./workflow-metrics.types";
+import { QualityEvaluationResult, QualityEvaluationResultSchema } from "./quality.types";
+
+
+
+export const getJsonSchema = (schema: z.ZodType) => z.toJSONSchema(schema, { target: "openapi-3.0" });
+
+// ============================================================================
+// CONSTANTS
+// ============================================================================
+
+export const VALID_DURATIONS = [ 5, 6, 7, 8 ] as const;
+export type ValidDuration = typeof VALID_DURATIONS[ number ];
+
+
+export const GcsObjectTypeSchema = z.union([
+  z.literal('final_output'),
+  z.literal('character_image'),
+  z.literal('location_image'),
+  z.literal('scene_video'),
+  z.literal('scene_start_frame'),
+  z.literal('scene_end_frame'),
+  z.literal('render_video'),
+  z.literal('composite_frame'),
+]);
+export type GcsObjectType = z.infer<typeof GcsObjectTypeSchema>;
+
+
+// ============================================================================
+// AUDIO ANALYSIS SCHEMAS (Director: Musical Structure)
+// ============================================================================
+
+export const AudioSegmentSchema = z.object({
+  startTime: z.number().describe("start time in seconds"),
+  endTime: z.number().describe("end time in seconds"),
+  duration: z.union([ z.literal(4), z.literal(6), z.literal(8) ]).describe("Duration in seconds (4, 6, or 8)"),
+  type: z.enum([ "lyrical", "instrumental", "transition", "breakdown", "solo", "climax" ]),
+  lyrics: z.string().describe("Transcribed lyrics if lyrical, empty otherwise"),
+  musicalDescription: z.string().describe("Detailed description of the sound, instruments, tempo, mood"),
+  musicChange: z.string().describe("Notable changes: key signature, tempo shift, instrumentation changes, dynamic shifts"),
+  intensity: z.enum([ "low", "medium", "high", "extreme" ]).describe("Energy level of this segment"),
+  mood: z.string().describe("Emotional tone (e.g., aggressive, melancholic, triumphant, mysterious)"),
+  tempo: z.enum([ "slow", "moderate", "fast", "very_fast" ]).describe("Pace of the music"),
+  transitionType: TransitionTypesSchema.describe("cinematic transition type"),
+  // --- NEW: GROUNDING FIELDS ---
+  audioEvidence: z.string().describe(
+    "Verifiable sonic proof from this segment (e.g., 'Heavy kick drum starts at 4.2s', 'Reverb-heavy female vocal enters', 'High-pass filter sweep')."
+  ),
+  transientImpact: z.enum([ "soft", "sharp", "explosive", "none" ]).describe(
+    "The physical nature of the audio onset at the start of this segment."
+  ),
+});
+export type AudioSegment = z.infer<typeof AudioSegmentSchema>;
+
+
+export const AudioAnalysisSchema = z.object({
+  bpm: z.number().describe("The detected beats per minute of the track."),
+  keySignature: z.string().describe("The estimated musical key (e.g., C Minor, G Major)."),
+  totalDuration: z.number().describe("Total authoritative duration in seconds."),
+  segments: z.array(AudioSegmentSchema).describe("List of segments covering 0.0 to totalDuration without gaps."),
+}).optional();
+export type AudioAnalysis = z.infer<typeof AudioAnalysisSchema> & {
+  audioGcsUri: string;
+  audioPublicUri?: string;
+};
+
+
+export const TagSchema = z.object({
+  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
+  projectId: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
+  createdAt: z.date().default(new Date()),
+  updatedAt: z.date().default(new Date()),
+});
+export type Tag = z.infer<typeof TagSchema>;
+
+
+// ============================================================================
+// ASSET VERSIONING SCHEMA
+// ============================================================================
+
+// TODO REPLACE SCENE.BESTATTEMPT AND SCENE.REJECTEDATTEMPTS
+// REMOVE STORAGEMANAGER ATTEMPT ALOGIC
+// FINISH GRAPH.TS FULL IMPL
+// MAKE A PENULTIMATE COMMIT WITH COMMENTS AND OLD CODE
+// REMOVE COMMENTS
+
+export const AssetKeySchema = z.union([
+  GcsObjectTypeSchema,
+  z.literal('enhanced_prompt'),
+  z.literal('storyboard'),
+  z.literal('scenes'),
+  z.literal('character_description'),
+  z.literal('character_prompt'),
+  z.literal('location_description'),
+  z.literal('location_prompt'),
+  z.literal('scene_description'),
+  z.literal('scene_prompt'),
+  z.literal('start_frame_prompt'),
+  z.literal('end_frame_prompt'),
+  z.literal('scene_quality_evaluation'),
+  z.literal('frame_quality_evaluation'),
+]);
+export type AssetKey = z.infer<typeof AssetKeySchema>;
+
+
+export const AssetTypeSchema = z.enum([ 'video', 'image', 'audio', 'text', 'json' ]);
+export type AssetType = z.infer<typeof AssetTypeSchema>;
+
+
+export const AssetVersionSchema = z.object({
+  version: z.number(),
+  data: z.string().describe("The content (text) or URI (file)"),
+  type: AssetTypeSchema,
+  createdAt: z.string(),
+  metadata: z.object({
+    evaluation: QualityEvaluationResultSchema.optional().describe("Quality evaluation result").nullable(),
+    model: z.string().nonoptional().describe("AI model used for asset generation")
+  }).catchall(z.any()).describe("Flexible metadata for evaluations, models, etc."),
+});
+export type AssetVersion = z.infer<typeof AssetVersionSchema>;
+
+
+export const AssetHistorySchema = z.object({
+  head: z.number().default(0).describe("The highest version number created"),
+  best: z.number().default(0).describe("The version currently selected as active/best"),
+  versions: z.array(AssetVersionSchema).default([]),
+});
+export type AssetHistory = z.infer<typeof AssetHistorySchema>;
+
+
+export const AssetRegistrySchema = z.partialRecord(AssetKeySchema, AssetHistorySchema).describe("The core registry map to be used in Projects, Scenes, Locations, and Characters").default({});
+export type AssetRegistry = z.infer<typeof AssetRegistrySchema>;
+
+
+// ============================================================================
+// SCENE SCHEMAS
+// ============================================================================
+
+export const DirectorSceneSchema = z.object({
+  description: z.string().describe("Detailed description of scene's narrative elements"),
+  mood: z.string().describe("overall emotional tone combining music and narrative"),
+  audioSync: z.string().optional().describe("how visuals sync with audio (Lip Sync, Mood Sync, Beat Sync)"),
+}).describe("Director specifications for scene");
+export type DirectorScene = z.infer<typeof DirectorSceneSchema>;
+
+
+export const ScriptSupervisorSceneSchema = z.object({
+  continuityNotes: z.array(z.string()).optional().describe("continuity requirements").default([]),
+  characters: z.array(z.string()).describe("list of character IDs present in scene").default([]),
+  locationId: z.string().describe("ID of the location where scene takes place"),
+}).describe("Script Supervisor specifications for scene");
+export type ScriptSupervisorScene = z.infer<typeof ScriptSupervisorSceneSchema>;
+
+
+export const AssetStatusSchema = z.enum([ "pending", "generating", "evaluating", "complete", "error" ]);
+export type AssetStatus = z.infer<typeof AssetStatusSchema>;
+
+
+export const SceneStatusSchema = z.object({
+  status: AssetStatusSchema,
+  progressMessage: z.string().optional().describe("Real-time progress message during generation"),
+});
+export type SceneStatus = z.infer<typeof SceneStatusSchema>;
+
+
+export const SceneSchema = z.object({
+  ...TagSchema.shape,
+  ...AudioSegmentSchema.shape,
+  ...DirectorSceneSchema.shape,
+  ...CinematographySchema.shape,
+  ...ScriptSupervisorSceneSchema.shape,
+  ...SceneStatusSchema.shape,
+  lighting: LightingSchema,
+  sceneIndex: z.number().describe("Index of the scene in the storyboard"),
+  assets: AssetRegistrySchema,
+}).describe("Composition of all department specs + audio timing + generation outputs");
+export type Scene = z.infer<typeof SceneSchema>;
+
+
+export interface SceneGenerationInput {
+  scene: Scene;
+  enhancedPrompt: string;
+}
+
+
+export type GeneratedScene = Scene & {
+  enhancedPrompt: string;
+};
+
+
+export interface SceneGenerationResult {
+  scene: GeneratedScene;
+  videoUrl?: string;
+  attempts: number;
+  finalScore: number;
+  evaluation: QualityEvaluationResult | null;
+  warning?: string;
+  acceptedAttempt: number;
+}
+
+
+export interface FrameGenerationResult {
+  frame: string;
+  attempts: number;
+  finalScore: number;
+  evaluation: QualityEvaluationResult | null;
+  warning?: string;
+}
+
+
+export interface VideoGenerationConfig {
+  resolution: "480p" | "720p" | "1080p";
+  durationSeconds: 4 | 6 | 8;
+  numberOfVideos: number;
+  personGeneration: "ALLOW_ALL" | "DONT_ALLOW";
+  generateAudio: boolean;
+  negativePrompt?: string;
+}
+
+
+// ============================================================================
+// METADATA SCHEMAS
+// ============================================================================
+
+/**
+ * InitialProjectMetadataSchema: Loose schema for project creation/insertion.
+ * Only `projectId` and `initialPrompt` are strictly required.
+ * Other fields have defaults or are optional - populated during workflow.
+ */
+export const InitialProjectMetadataSchema = z.object({
+  projectId: z.uuid({ version: "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
+  title: z.string().default("").describe("title of the video"),
+  duration: z.number().default(0).describe("total duration in seconds"),
+  totalScenes: z.number().default(0).describe("total number of scenes"),
+  style: z.string().default("").describe("inferred cinematic style"),
+  mood: z.string().default("").describe("overall emotional arc"),
+  colorPalette: z.array(z.string()).default([]).describe("dominant colors"),
+  tags: z.array(z.string()).default([]).describe("descriptive tags"),
+
+  models: z.object({
+    videoModel: z.string().optional().describe("AI model used for video generation"),
+    imageModel: z.string().optional().describe("AI model used for image generation"),
+    textModel: z.string().optional().describe("AI model used for text generation"),
+    qaModel: z.string().optional().describe("AI model used for quality evaluation"),
+  }).default({}),
+
+  initialPrompt: z.string().describe("original creative prompt"),
+  enhancedPrompt: z.string().optional().describe("enhanced user prompt with narrative, characters, settings"),
+  audioGcsUri: z.string().optional().describe("GCS URI of uploaded audio file"),
+  audioPublicUri: z.string().optional().describe("audio file public url"),
+  hasAudio: z.boolean().default(false).describe("whether this workflow has user-provided audio"),
+});
+export type InitialProjectMetadata = z.infer<typeof InitialProjectMetadataSchema>;
+
+
+/**
+ * ProjectMetadataSchema: Strict schema for runtime application logic.
+ * All fields are required (no optionals except audio-related fields).
+ * Used after storyboard generation when metadata is fully populated.
+ */
+export const ProjectMetadataSchema = z.object({
+  projectId: z.uuid({ version: "v7" }).nonempty().nonoptional().describe("Pipeline project id"),
+  title: z.string().describe("title of the video"),
+  duration: z.number().describe("total duration in seconds"),
+  totalScenes: z.number().describe("total number of scenes"),
+  style: z.string().describe("inferred cinematic style"),
+  mood: z.string().describe("overall emotional arc"),
+  colorPalette: z.array(z.string()).describe("dominant colors"),
+  tags: z.array(z.string()).describe("descriptive tags"),
+
+  models: z.object({
+    videoModel: z.string().optional().describe("AI model used for video generation"),
+    imageModel: z.string().optional().describe("AI model used for image generation"),
+    textModel: z.string().optional().describe("AI model used for text generation"),
+    qaModel: z.string().optional().describe("AI model used for quality evaluation"),
+  }),
+
+  initialPrompt: z.string().describe("original creative prompt"),
+  enhancedPrompt: z.string().describe("enhanced user prompt with narrative, characters, settings"),
+  audioGcsUri: z.string().optional().describe("GCS URI of uploaded audio file"),
+  audioPublicUri: z.string().optional().describe("audio file public url"),
+  hasAudio: z.boolean().describe("whether this workflow has user-provided audio"),
+});
+export type ProjectMetadata = z.infer<typeof ProjectMetadataSchema>;
+
+
+// ============================================================================
+// CHARACTER SCHEMAS (Costume & Makeup Dept)
+// ============================================================================
+
+export const PhysicalTraitsSchema = z.object({
+  hair: z.string().describe("specific hairstyle, color, length, texture"),
+  clothing: z.union([
+    z.string(),
+    z.array(z.string())
+  ]).describe("specific outfit description (string or array of garments)"),
+  accessories: z.array(z.string()).describe("list of accessories").default([]),
+  distinctiveFeatures: z.array(z.string()).describe("list of distinctive features").default([]),
+  build: z.string().optional().describe("physical build description"),
+  ethnicity: z.string().optional().describe("ethnicity description (generic, non-specific)"),
+});
+export type PhysicalTraits = z.infer<typeof PhysicalTraitsSchema>;
+
+
+// Enhanced: Temporal state tracking for Script Supervisor with progressive changes
+export const CharacterStateSchema = z.object({
+  lastSeen: z.string().optional().describe("scene ID where character was last seen"),
+
+  // Spatial continuity
+  position: z.string().optional().describe("character's spatial position: left/center/right, foreground/background"),
+  lastExitDirection: z.enum([ "left", "right", "up", "down", "none" ]).optional().describe("direction character exited frame in previous scene"),
+
+  // Emotional progression
+  emotionalState: z.string().optional().describe("character's current emotional state"),
+  emotionalHistory: z.array(z.object({
+    sceneId: z.string(),
+    emotion: z.string(),
+  })).optional().default([]).describe("emotional state timeline across scenes"),
+
+  // Physical condition progression
+  physicalCondition: z.string().optional().describe("accumulated damage, dirt, exhaustion"),
+  injuries: z.array(z.object({
+    type: z.string(),
+    location: z.string(),
+    severity: z.enum([ "minor", "moderate", "severe" ]),
+    acquiredInScene: z.number(), // Using sceneIndex for temporal logic
+  })).optional().default([]).describe("injuries that persist across scenes"),
+
+  // Appearance changes
+  dirtLevel: z.enum([ "clean", "slightly_dirty", "dirty", "very_dirty", "covered" ]).optional().default("clean").describe("accumulation of dirt, mud, dust"),
+  exhaustionLevel: z.enum([ "fresh", "slightly_tired", "tired", "exhausted", "collapsing" ]).optional().default("fresh").describe("progressive fatigue"),
+  sweatLevel: z.enum([ "dry", "slight", "moderate", "heavy", "drenched" ]).optional().default("dry").describe("perspiration level"),
+
+  // Costume state progression
+  costumeCondition: z.object({
+    tears: z.array(z.string()).optional().default([]).describe("torn areas (e.g., 'sleeve torn', 'pants ripped at knee')"),
+    stains: z.array(z.string()).optional().default([]).describe("stains (e.g., 'blood on shirt', 'mud on pants')"),
+    wetness: z.enum([ "dry", "damp", "wet", "soaked" ]).optional().default("dry").describe("moisture level of clothing"),
+    damage: z.array(z.string()).optional().default([]).describe("other damage (e.g., 'burned collar', 'missing button')"),
+  }).optional().describe("progressive costume degradation"),
+
+  // Makeup/hair changes
+  hairCondition: z.object({
+    style: z.string().optional().describe("current style (should match baseline unless narrative justification)"),
+    messiness: z.enum([ "pristine", "slightly_messy", "messy", "disheveled", "wild" ]).optional().default("pristine"),
+    wetness: z.enum([ "dry", "damp", "wet", "soaked" ]).optional().default("dry"),
+  }).optional().describe("progressive hair state changes"),
+});
+export type CharacterState = z.infer<typeof CharacterStateSchema>;
+
+
+export const CharacterSchema = z.object({
+  ...TagSchema.shape,
+
+  referenceId: z.string().describe("unique identifier for the character (e.g. char_1)"),
+  name: z.string().describe("character name"),
+  aliases: z.array(z.string()).describe("list of aliases for the character").default([]),
+  age: z.string().describe("age or age range"),
+
+  // Costume & Makeup specifications
+  physicalTraits: PhysicalTraitsSchema,
+  appearanceNotes: z.array(z.string()).describe("additional notes on appearance").default([]),
+
+  assets: AssetRegistrySchema,
+
+  // Script Supervisor state tracking (mutable)
+  state: CharacterStateSchema.optional(),
+});
+export type Character = z.infer<typeof CharacterSchema>;
+
+
+// ============================================================================
+// LOCATION SCHEMAS (Production Designer)
+// ============================================================================
+
+
+// Enhanced: Temporal state tracking for locations with progressive changes
+export const LocationStateSchema = z.object({
+  lastUsed: z.string().optional().describe("scene ID where location was last used"),
+
+  // Temporal progression
+  timeOfDay: z.string().optional().describe("current time of day (evolves across scenes)"),
+  timeHistory: z.array(z.object({
+    sceneId: z.string(),
+    timeOfDay: z.string(),
+  })).optional().default([]).describe("time progression timeline"),
+
+  // Weather progression
+  weather: z.string().optional().describe("current weather conditions"),
+  weatherHistory: z.array(z.object({
+    sceneId: z.string(),
+    weather: z.string(),
+    intensity: z.enum([ "light", "moderate", "heavy", "extreme" ]).optional(),
+  })).optional().default([]).describe("weather evolution across scenes"),
+  precipitation: z.enum([ "none", "light", "moderate", "heavy" ]).optional().default("none").describe("current precipitation level"),
+  visibility: z.enum([ "clear", "slight_haze", "hazy", "foggy", "obscured" ]).optional().default("clear").describe("atmospheric visibility"),
+
+  // Lighting progression
+  lighting: LightingSchema,
+  lightingHistory: z.array(z.object({
+    sceneId: z.string(),
+    lighting: LightingSchema,
+  })).optional().default([]).describe("lighting changes timeline"),
+
+  // Environmental state changes
+  groundCondition: z.object({
+    wetness: z.enum([ "dry", "damp", "wet", "soaked", "flooded" ]).optional().default("dry"),
+    debris: z.array(z.string()).optional().default([]).describe("accumulated debris (e.g., 'broken glass', 'fallen leaves')"),
+    damage: z.array(z.string()).optional().default([]).describe("environmental damage (e.g., 'crater', 'burn marks')"),
+  }).optional().describe("progressive ground surface changes"),
+
+  // Object/prop persistence
+  brokenObjects: z.array(z.object({
+    object: z.string(),
+    description: z.string(),
+    brokenInScene: z.number(), // Using sceneIndex for temporal logic
+  })).optional().default([]).describe("objects that remain broken across scenes"),
+
+  // Atmospheric effects
+  atmosphericEffects: z.array(z.object({
+    type: z.string().describe("smoke, fog, dust, steam, etc."),
+    intensity: z.enum([ "light", "moderate", "heavy" ]),
+    addedInScene: z.number(), // Using sceneIndex for temporal logic
+    dissipating: z.boolean().optional().default(false),
+  })).optional().default([]).describe("lingering atmospheric effects"),
+
+  // Temperature/season indicators (for consistency)
+  season: z.enum([ "spring", "summer", "fall", "winter", "unspecified" ]).optional().describe("seasonal context for consistency"),
+  temperatureIndicators: z.array(z.string()).optional().default([]).describe("visual temperature cues (e.g., 'frost on windows', 'heat shimmer')"),
+});
+export type LocationState = z.infer<typeof LocationStateSchema>;
+
+
+export const LocationSchema = z.object({
+  ...TagSchema.shape,
+
+  referenceId: z.string().describe("narrative-scoped identifier for the location (e.g., loc_1)"),
+  name: z.string().describe("location name"),
+  type: z.string().optional().describe("location type (beach, urban, warehouse, etc.)"),
+
+  // Production Designer specifications (baseline/initial state)
+  lightingConditions: LightingSchema,
+  timeOfDay: z.string().describe("initial time of day"),
+  weather: z.string().describe("initial weather conditions").default("Clear"),
+  colorPalette: z.array(z.string()).describe("dominant colors").default([]),
+  mood: z.string().describe("atmospheric mood"),
+
+  // Environmental elements (baseline)
+  architecture: z.string().describe("architectural features"),
+  naturalElements: z.array(z.string()).describe("natural elements in scene").default([]),
+  manMadeObjects: z.array(z.string()).describe("man-made objects in scene").default([]),
+  groundSurface: z.string().describe("ground surface description"),
+  skyOrCeiling: z.string().describe("sky or ceiling description"),
+
+  assets: AssetRegistrySchema,
+
+  // Script Supervisor state tracking (mutable, evolves across scenes)
+  state: LocationStateSchema.optional(),
+});
+export type Location = z.infer<typeof LocationSchema>;
+
+
+// ============================================================================
+// STORYBOARD ENRICHMENT SCHEMA
+// ============================================================================
+
+/**
+ * InitialStoryboardSchema: Loose schema for project creation.
+ * Uses InitialProjectMetadataSchema and allows empty arrays.
+ */
+export const InitialStoryboardSchema = z.object({
+  metadata: InitialProjectMetadataSchema,
+  characters: z.array(CharacterSchema).default([]),
+  locations: z.array(LocationSchema).default([]),
+  scenes: z.array(SceneSchema).default([]),
+});
+export type InitialStoryboard = z.infer<typeof InitialStoryboardSchema>;
+
+
+/**
+ * StoryboardSchema: Strict schema for immutable storyboard snapshot.
+ * Uses ProjectMetadataSchema and requires populated arrays.
+ */
+export const StoryboardSchema = z.object({
+  metadata: ProjectMetadataSchema,
+  characters: z.array(CharacterSchema),
+  locations: z.array(LocationSchema),
+  scenes: z.array(SceneSchema),
+}).readonly();
+export type Storyboard = z.infer<typeof StoryboardSchema>;
+
+
+export const InitialContextSchema = z.object({
+  metadata: InitialProjectMetadataSchema,
+  characters: z.array(CharacterSchema),
+  locations: z.array(LocationSchema),
+});
+
+
+export const SceneBatchSchema = z.object({
+  scenes: z.array(SceneSchema)
+});
+
+
+/**
+ * Default WorkflowMetrics factory for project creation.
+ */
+export const createDefaultMetrics = (): z.infer<typeof WorkflowMetricsSchema> => ({
+  sceneMetrics: [],
+  attemptMetrics: [],
+  trendHistory: [],
+  regression: {
+    count: 0,
+    sumX: 0,
+    sumY_a: 0,
+    sumY_q: 0,
+    sumXY_a: 0,
+    sumXY_q: 0,
+    sumX2: 0,
+  },
+});
+
+
+/**
+ * InitialProjectSchema: Minimal schema for DB insertion.
+ * Uses loose metadata and storyboard schemas with defaults.
+ * This is the type used before storyboard generation completes.
+ */
+export const InitialProjectSchema = z.object({
+  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
+  createdAt: z.date().default(new Date()),
+  updatedAt: z.date().default(new Date()),
+
+  // Loose storyboard and metadata
+  storyboard: InitialStoryboardSchema.describe("The initial storyboard plan (empty at creation)"),
+  metadata: InitialProjectMetadataSchema.describe("Production metadata (partial at creation)"),
+
+  // Workflow control with defaults
+  status: AssetStatusSchema.default("pending"),
+  currentSceneIndex: z.number().default(0).describe("Index of scene currently being processed"),
+  forceRegenerateSceneIds: z.array(z.string()).default([]).describe("List of scene IDs to force video regenerate"),
+
+  assets: AssetRegistrySchema.default({}),
+  generationRules: z.array(z.string()).default([]).describe("generation rule guidelines"),
+  generationRulesHistory: z.array(
+    z.array(z.string()).default([])
+  ).default([]).describe("history of generation rule guidelines"),
+
+  // Optional at creation - populated during workflow
+  characters: z.array(CharacterSchema).optional(),
+  locations: z.array(LocationSchema).optional(),
+  scenes: z.array(SceneSchema).optional(),
+  metrics: WorkflowMetricsSchema.optional(),
+});
+export type InitialProject = z.infer<typeof InitialProjectSchema>;
+
+
+/**
+ * ProjectSchema: Strict schema for runtime application logic.
+ * All fields required. Used after storyboard generation completes.
+ * NOT an extension of InitialProjectSchema - standalone strict definition.
+ */
+export const ProjectSchema = z.object({
+  id: z.uuid({ "version": "v7" }).nonempty().nonoptional().describe("unique identifier (uuid)"),
+  createdAt: z.date().default(new Date()),
+  updatedAt: z.date().default(new Date()),
+
+  // Strict storyboard and metadata
+  storyboard: StoryboardSchema.describe("The immutable storyboard snapshot"),
+  metadata: ProjectMetadataSchema.describe("Fully populated production metadata"),
+
+  // Workflow control
+  status: AssetStatusSchema,
+  currentSceneIndex: z.number().describe("Index of scene currently being processed"),
+  forceRegenerateSceneIds: z.array(z.string()).describe("List of scene IDs to force video regenerate"),
+
+  assets: AssetRegistrySchema,
+  generationRules: z.array(z.string()).describe("generation rule guidelines"),
+  generationRulesHistory: z.array(
+    z.array(z.string())
+  ).describe("history of generation rule guidelines"),
+
+  // Required at runtime - hydrated from DB
+  characters: z.array(CharacterSchema),
+  locations: z.array(LocationSchema),
+  scenes: z.array(SceneSchema),
+  metrics: WorkflowMetricsSchema,
+});
+export type Project = z.infer<typeof ProjectSchema>;
+
+
+export type ErrorRecord = {
+  node: string;
+  error: string;
+  skipped: boolean;
+  timestamp: string;
+};
+
+
+// ============================================================================
+// USER SCHEMA
+// ============================================================================
+
+export const UserSchema = z.object({
+  id: z.uuid({ "version": "v7" }),
+  name: z.string(),
+  email: z.email().optional(),
+  createdAt: z.string().default(new Date().toISOString()),
+  updatedAt: z.string().default(new Date().toISOString()),
+});
+
+
+// ============================================================================
+// WORKFLOW STATE
+// ============================================================================
+
+export const WorkflowStateSchema = z.object({
+  ...TagSchema.shape,
+
+  initialProject: z.union([ InitialProjectSchema, z.null() ]),
+  project: z.union([ ProjectSchema, z.null() ]),
+
+  localAudioPath: z.string().optional().describe("user-provided audio filepath"),
+  hasAudio: z.boolean().default(false).describe("whether this workflow uses audio"),
+
+  // Transient execution data
+  jobIds: z.record(z.string(), z.string()).describe("Active generative worker jobs"),
+  currentSceneIndex: z.number().describe("index of scene currently being processed").default(0),
+  nodeAttempts: z.record(z.string(), z.number()).describe("Count of node executions inthe current workflow"),
+
+  errors: z.array(z.object({
+    projectId: z.string(),
+    node: z.string(),
+    message: z.string(),
+    value: z.record(z.string(), z.any()),
+    shouldRetry: z.boolean(),
+    timestamp: z.string(),
+  })).describe("errors encountered during workflow").default([]),
+});
+export type WorkflowState = Omit<z.infer<typeof WorkflowStateSchema>, "createdAt" | "updatedAt"> & {
+  __interrupt__?: { value: LlmRetryInterruptValue; }[];
+  __interrupt_resolved__?: boolean;
+};
+
+
+// ============================================================================
+// UTILITY TYPES
+// ============================================================================
+
+export interface ContinuityCheck {
+  characterConsistency: boolean;
+  locationConsistency: boolean;
+  timingConsistency: boolean;
+  issues: string[];
+}
+
+// ============================================================================
+// TYPE GUARDS
+// ============================================================================
+
+export function isValidDuration(duration: number): duration is 4 | 6 | 8 {
+  return duration === 4 || duration === 6 || duration === 8;
+}
+
+
+export function isLyricalScene(scene: Scene): boolean {
+  return (
+    scene.audioSync === "Lip Sync" ||
+    (scene.lyrics && scene.lyrics.length > 0) ||
+    false
+  );
+}
+
+
+export function isInstrumentalScene(scene: Scene): boolean {
+  return (
+    scene.audioSync === "Mood Sync" ||
+    scene.description?.includes("[Instrumental") ||
+    false
+  );
+}
+
+
+export function requiresTransition(scene: Scene): boolean {
+  return scene.transitionType !== "Cut" && scene.transitionType !== "none";
+}
+
+
+export interface LlmRetryInterruptValue {
+  type: "llm_retry_exhausted" | "llm_intervention" | "waiting_for_job" | "waiting_for_batch";
+  error: string;
+  errorDetails?: Record<string, any>;
+  stackTrace?: string;
+  functionName: string;
+  nodeName: string;
+  projectId: string;
+  params?: Record<string, any>;
+  attempt?: number;
+  maxRetries?: number;
+  lastAttemptTimestamp: string;
+}
+
+
+export * from "./cinematography.types";
+export * from "./workflow-metrics.types";
+export * from "./quality.types";
diff --git a/src/shared/utils/errors.ts b/src/shared/utils/errors.ts
index fd13e9e..0f19f25 100644
--- a/src/shared/utils/errors.ts
+++ b/src/shared/utils/errors.ts
@@ -1,6 +1,6 @@
 import { ApiError as GenAIApiError } from "@google/genai";
 import { NodeInterrupt } from "@langchain/langgraph";
-import { LlmRetryInterruptValue } from "@shared/types/pipeline.types";
+import { LlmRetryInterruptValue } from "@shared/types/workflow.types";
 
 export class RAIError extends Error {
     constructor(message: string) {
@@ -122,6 +122,7 @@ export function extractRelevantParams(state: any): Record<string, any> {
 export function interceptNodeInterruptAndThrow(
     error: any,
     nodeName: string,
+    projectId: string,
     context: Partial<LlmRetryInterruptValue> = {}
 ) {
 
@@ -132,14 +133,14 @@ export function interceptNodeInterruptAndThrow(
 
     const errorMessage = extractErrorMessage(error);
     const errorDetails = extractErrorDetails(error);
-    const defaults = {
+    const defaults: Omit<LlmRetryInterruptValue, "projectId"> = {
         error: errorMessage,
         errorDetails: errorDetails,
         attempt: context?.attempt ?? 1,
         maxRetries: context?.maxRetries ?? 3,
         functionName: nodeName,
         lastAttemptTimestamp: new Date().toISOString(),
-        // type: context?.attempt >= context?.maxRetries && 'llm_retry_exhausted' || 'llm_intervention',
+        type: 'llm_intervention',
         nodeName: nodeName,
         stackTrace: error instanceof Error ? error.stack : undefined,
     };
@@ -151,12 +152,18 @@ export function interceptNodeInterruptAndThrow(
             type: "llm_intervention", // can be defined as a different type
             functionName: nodeName,
             nodeName,
+            projectId: projectId,
             attempt: defaults.attempt,
             maxRetries: defaults.maxRetries,
             lastAttemptTimestamp: defaults.lastAttemptTimestamp,
         }
     } else {
-        interruptValue = { ...defaults, ...interruptValue, ...context };
+        interruptValue = {
+            ...defaults,
+            ...interruptValue,
+            ...context,
+            projectId: projectId
+        };
     }
 
     throw new NodeInterrupt(interruptValue);
diff --git a/src/shared/utils/llm-retry.ts b/src/shared/utils/llm-retry.ts
index 40d042c..927dcd6 100644
--- a/src/shared/utils/llm-retry.ts
+++ b/src/shared/utils/llm-retry.ts
@@ -1,6 +1,6 @@
 //pipeline/lib/llm-retry.ts
 import { interrupt } from "@langchain/langgraph";
-import { LlmRetryInterruptValue } from "../types/pipeline.types";
+import { LlmRetryInterruptValue } from "../types/workflow.types";
 
 
 
@@ -16,6 +16,7 @@ export type RetryConfig = {
     maxRetries: number;
     initialDelay?: number;
     backoffFactor?: number;
+    projectId: string;
 };
 
 const defaultRetryConfig = { initialDelay: 1000, backoffFactor: 2, };
@@ -57,6 +58,7 @@ export async function retryLlmCall<T, U>(
                 attempt: attempt,
                 functionName: llmCall.name || "Unknown Function",
                 lastAttemptTimestamp: new Date().toISOString(),
+                projectId: retryConfig.projectId,
             };
 
             const resolution = interrupt(interruptValue);
diff --git a/src/shared/utils/quality-retry-handler.ts b/src/shared/utils/quality-retry-handler.ts
index 1101350..e4816f6 100644
--- a/src/shared/utils/quality-retry-handler.ts
+++ b/src/shared/utils/quality-retry-handler.ts
@@ -4,7 +4,8 @@
  * Eliminates code duplication between frame and scene generation
  */
 
-import { QualityEvaluationResult, QualityConfig } from "../types/pipeline.types";
+import { OnCompleteCallback, OnProgressCallback } from "@shared/types/pipeline.types";
+import { QualityEvaluationResult, QualityConfig, Scene } from "../types/workflow.types";
 import { RetryLogger, RetryContext } from "./retry-logger";
 
 export interface QualityRetryConfig {
@@ -26,15 +27,29 @@ export interface QualityRetryResult<T> {
   warning?: string;
 }
 
+export type GenerateCallbackProps<T> = [
+  prompt: string,
+  attempt: number,
+  onProgress?: OnProgressCallback<T>,
+];
+export type EvaluateCallbackProps<T> = [
+  output: T, attempt: number, onProgress?: OnProgressCallback<T>
+];
+export type ApplyCorrectionsCallbackProps<T> = [
+  prompt: string,
+  evaluation: QualityEvaluationResult,
+  attempt: number,
+  onProgress?: OnProgressCallback<T>,
+];
+export type CalculateScoreProps = [ evaluation: QualityEvaluationResult ];
+
 export interface GenerationCallbacks<T> {
-  generate: (prompt: string, attempt: number) => Promise<T>;
-  evaluate: (output: T, attempt: number) => Promise<QualityEvaluationResult>;
-  applyCorrections: (
-    prompt: string,
-    evaluation: QualityEvaluationResult,
-    attempt: number
-  ) => Promise<string>;
-  calculateScore: (evaluation: QualityEvaluationResult) => number;
+  generate: (...args: GenerateCallbackProps<T>) => Promise<T>;
+  evaluate: (...args: EvaluateCallbackProps<T>) => Promise<QualityEvaluationResult>;
+  applyCorrections: (...args: ApplyCorrectionsCallbackProps<T>) => Promise<string>;
+  calculateScore: (...args: CalculateScoreProps) => number;
+  onComplete?: OnCompleteCallback<T>;
+  onProgress?: OnProgressCallback<T>;
 }
 
 /**
@@ -53,10 +68,9 @@ export class QualityRetryHandler {
   ): Promise<QualityRetryResult<T>> {
 
     const { qualityConfig, context } = config;
-
     const acceptanceThreshold = qualityConfig.minorIssueThreshold;
 
-    const { generate, evaluate, applyCorrections, calculateScore } = callbacks;
+    const { generate, evaluate, applyCorrections, calculateScore, onComplete, onProgress } = callbacks;
 
     let bestOutput: T | null = null;
     let bestEvaluation: QualityEvaluationResult | null = null;
@@ -65,35 +79,35 @@ export class QualityRetryHandler {
     let totalAttempts = 0;
 
     for (let attempt = 1; attempt <= qualityConfig.maxRetries; attempt++) {
+
       totalAttempts = attempt;
       const attemptContext: RetryContext = { ...context, attempt };
-
       try {
-        // Log attempt start
+
         RetryLogger.logAttemptStart(attemptContext, currentPrompt.length);
 
-        // Generate
-        const output = await generate(currentPrompt, attempt);
+        const output = await generate(currentPrompt, attempt, onProgress);
 
-        // Evaluate
-        const evaluation = await evaluate(output, attempt);
+        const evaluation = await evaluate(output, attempt, onProgress);
         const score = calculateScore(evaluation);
-
-        // Log evaluation details
         RetryLogger.logEvaluationDetails(attemptContext, evaluation, score);
 
-        // Track best attempt
         if (score > bestScore) {
           bestScore = score;
           bestOutput = output;
           bestEvaluation = evaluation;
         }
 
-        // Check if quality is acceptable
         if (score >= acceptanceThreshold) {
           console.log(`   âœ… Quality acceptable (${(score * 100).toFixed(1)}%)`);
           RetryLogger.logFinalResult(attemptContext, score, acceptanceThreshold, totalAttempts);
 
+          if (onComplete) {
+            onComplete(output, {
+              attemptNumber: attempt,
+              finalScore: bestScore,
+            });
+          }
           return {
             output,
             evaluation,
@@ -102,7 +116,6 @@ export class QualityRetryHandler {
           };
         }
 
-        // If this was the last attempt, break without retrying
         if (attempt >= qualityConfig.maxRetries) {
           break;
         }
@@ -110,7 +123,7 @@ export class QualityRetryHandler {
         // Apply corrections for next attempt
         if (evaluation.promptCorrections && evaluation.promptCorrections.length > 0) {
           const originalLength = currentPrompt.length;
-          currentPrompt = await applyCorrections(currentPrompt, evaluation, attempt);
+          currentPrompt = await applyCorrections(currentPrompt, evaluation, attempt, onProgress);
           RetryLogger.logPromptCorrections(
             attemptContext,
             evaluation.promptCorrections,
@@ -123,16 +136,10 @@ export class QualityRetryHandler {
             'No prompt corrections provided by evaluation'
           );
         }
-
-        // Wait before retry
         await new Promise(resolve => setTimeout(resolve, 3000));
 
       } catch (error) {
         console.error(`   âœ— Attempt ${attempt} failed:`, error);
-
-        // If we have partial results, consider them for best-attempt tracking
-        // (This would require passing output/evaluation through the error, which we skip for now)
-
         if (attempt < qualityConfig.maxRetries) {
           console.log(`   Retrying generation...`);
           await new Promise(resolve => setTimeout(resolve, 3000));
@@ -140,7 +147,6 @@ export class QualityRetryHandler {
       }
     }
 
-    // All attempts exhausted - return best attempt
     if (bestOutput && bestScore > 0) {
       RetryLogger.logFinalResult(
         { ...context, attempt: totalAttempts },
@@ -163,6 +169,6 @@ export class QualityRetryHandler {
       };
     }
 
-    throw new Error(`Failed to generate acceptable ${context.type} after ${totalAttempts} attempts`);
+    throw new Error(`Failed to generate acceptable ${context.assetKey} after ${totalAttempts} attempts`);
   }
 }
diff --git a/src/shared/utils/retry-logger.ts b/src/shared/utils/retry-logger.ts
index 0ad5c24..dc34d18 100644
--- a/src/shared/utils/retry-logger.ts
+++ b/src/shared/utils/retry-logger.ts
@@ -3,14 +3,16 @@
  * Comprehensive retry logging utility for quality control processes
  */
 
-import { QualityEvaluationResult, PromptCorrection } from "../types/pipeline.types";
+import { QualityEvaluationResult, PromptCorrection, AssetKey } from "../types/workflow.types";
 
 export interface RetryContext {
-  type: 'frame' | 'scene';
-  sceneId: number;
+  assetKey: AssetKey;
+  sceneId: string;
+  sceneIndex: number;
   attempt: number;
   maxAttempts: number;
   framePosition?: 'start' | 'end';
+  projectId: string;
 }
 
 export class RetryLogger {
@@ -19,11 +21,11 @@ export class RetryLogger {
    * Log the start of a generation attempt
    */
   static logAttemptStart(context: RetryContext, promptLength: number): void {
-    const { type, sceneId, attempt, maxAttempts, framePosition } = context;
+    const { assetKey, sceneId, attempt, maxAttempts, framePosition } = context;
     const frameLabel = framePosition ? ` (${framePosition})` : '';
 
     console.log(`\n${'='.repeat(70)}`);
-    console.log(`ðŸŽ¯ ${type.toUpperCase()}${frameLabel} GENERATION - Scene ${sceneId}`);
+    console.log(`ðŸŽ¯ ${assetKey}${frameLabel} GENERATION - Scene ${sceneId}`);
     console.log(`   Attempt: ${attempt}/${maxAttempts}`);
     console.log(`   Prompt length: ${promptLength} characters`);
     console.log(`${'='.repeat(70)}`);
diff --git a/src/shared/utils/utils.ts b/src/shared/utils/utils.ts
index 1760ccc..e16826d 100644
--- a/src/shared/utils/utils.ts
+++ b/src/shared/utils/utils.ts
@@ -1,4 +1,4 @@
-import { Character, Location, WorkflowMetrics, AttemptMetric, Trend, RegressionState, ValidDuration, VALID_DURATIONS, Storyboard, Project, WorkflowState, AssetRegistry, AssetKey, AssetType, AssetHistory, AssetVersion } from "../types/pipeline.types";
+import { Character, Location, WorkflowMetrics, AttemptMetric, Trend, RegressionState, ValidDuration, VALID_DURATIONS, Storyboard, Project, WorkflowState, AssetRegistry, AssetKey, AssetType, AssetHistory, AssetVersion } from "../types/workflow.types";
 
 /**
  * Sanitizes the storyboard by removing any potentially hallucinated asset URLs.
diff --git a/src/shared/zod-db.ts b/src/shared/zod-db.ts
index f28e8c8..5d485f9 100644
--- a/src/shared/zod-db.ts
+++ b/src/shared/zod-db.ts
@@ -14,7 +14,7 @@ import {
   LocationStateSchema,
   InitialProjectSchema,
   LocationSchema
-} from "./types/pipeline.types";
+} from "./types/workflow.types";
 
 // --- PROJECT HELPERS ---
 export const DbProjectSchema = createSelectSchema(dbSchema.projects);
diff --git a/src/worker/index.ts b/src/worker/index.ts
index ab996aa..2ce5f57 100644
--- a/src/worker/index.ts
+++ b/src/worker/index.ts
@@ -1,21 +1,25 @@
 // src/worker/index.ts
 import { PubSub } from "@google-cloud/pubsub";
-import { PipelineEvent } from "../shared/types/pubsub.types";
+import { PipelineEvent } from "../shared/types/pipeline.types";
 import {
     JOB_EVENTS_TOPIC_NAME,
     PIPELINE_EVENTS_TOPIC_NAME,
     WORKER_JOB_EVENTS_SUBSCRIPTION,
     PIPELINE_JOB_EVENTS_SUBSCRIPTION
 } from "../shared/constants";
-import { JobEvent } from "../shared/types/job-types";
+import { JobEvent } from "../shared/types/job.types";
 import { PoolManager } from "../pipeline/services/pool-manager";
 import { JobControlPlane } from "../pipeline/services/job-control-plane";
+import { AsyncLocalStorage } from "async_hooks";
 import { v7 as uuidv7 } from 'uuid';
-import * as dotenv from "dotenv";
 import { WorkerService } from "./worker-service";
-
+import { LogContext } from "../shared/logger";
+import * as dotenv from "dotenv";
+import { formatLoggers } from "../shared/format-loggers";
 dotenv.config();
 
+const logContextStore = new AsyncLocalStorage<LogContext>();
+
 const workerId = uuidv7();
 
 const gcpProjectId = process.env.GCP_PROJECT_ID;
@@ -56,64 +60,76 @@ const jobControlPlane = new JobControlPlane(poolManager, publishJobEvent);
 
 const workerService = new WorkerService(workerId, bucketName, jobControlPlane, publishJobEvent, publishPipelineEvent);
 
+const logContext: LogContext = {
+    workerId,
+    correlationId: uuidv7(),
+    shouldPublishLog: false,
+};
+
 async function main() {
     console.log(`Starting generative worker service ${workerId}...`);
-
-    try {
-        const [ topic ] = await pubsub.topic(JOB_EVENTS_TOPIC_NAME).get({ autoCreate: true });
-
-        const ensureSubscription = async (topic: any, subscriptionName: string) => {
-            console.log(`[Worker ${workerId}] Ensuring subscription ${subscriptionName} exists on ${topic.name}...`);
-            const isDev = process.env.NODE_ENV !== 'production';
-            try {
-                await topic.createSubscription(subscriptionName, {
-                    ackDeadlineSeconds: isDev ? 600 : 10
-                });
-            } catch (e: any) {
-                if (e.code !== 6) throw e;
-            }
-        };
-
-        await ensureSubscription(topic, WORKER_JOB_EVENTS_SUBSCRIPTION);
-        await ensureSubscription(topic, PIPELINE_JOB_EVENTS_SUBSCRIPTION);
-
-        const subscription = pubsub.subscription(WORKER_JOB_EVENTS_SUBSCRIPTION);
-        console.log(`[Worker ${workerId}] Listening on ${WORKER_JOB_EVENTS_SUBSCRIPTION}`);
-
-        subscription.on("message", async (message) => {
-            try {
-                const event = JSON.parse(message.data.toString()) as JobEvent;
-
-                if (event.type === "JOB_DISPATCHED") {
-                    console.log(`[Worker ${workerId}] Received JOB_DISPATCHED for ${event.jobId}`);
-                    // Await processing. 
-                    // If processing throws (DB connection error in claim), we catch and nack.
-                    // If processing logic fails, inside processJob it catches and updates DB, so it returns safely here -> ack.
-                    // If claim returns false (already taken), it returns safely here -> ack.
-                    await workerService.processJob(event.jobId);
-                    message.ack();
-                } else {
-                    // Ack unknown events so they don't clog
+    formatLoggers(
+        { getStore: logContextStore.getStore.bind(logContextStore) },
+        publishPipelineEvent
+    );
+    await logContextStore.run(logContext, async () => {
+        try {
+
+            const [ topic ] = await pubsub.topic(JOB_EVENTS_TOPIC_NAME).get({ autoCreate: true });
+            const ensureSubscription = async (topic: any, subscriptionName: string) => {
+                console.log(`[Worker ${workerId}] Ensuring subscription ${subscriptionName} exists on ${topic.name}...`);
+                const isDev = process.env.NODE_ENV !== 'production';
+                try {
+                    await topic.createSubscription(subscriptionName, {
+                        ackDeadlineSeconds: isDev ? 600 : 10
+                    });
+                } catch (e: any) {
+                    if (e.code !== 6) throw e;
+                }
+            };
+            await ensureSubscription(topic, WORKER_JOB_EVENTS_SUBSCRIPTION);
+            await ensureSubscription(topic, PIPELINE_JOB_EVENTS_SUBSCRIPTION);
+
+            const subscription = pubsub.subscription(WORKER_JOB_EVENTS_SUBSCRIPTION);
+            console.log(`[Worker ${workerId}] Listening on ${WORKER_JOB_EVENTS_SUBSCRIPTION}`);
+
+            subscription.on("message", async (message) => {
+                try {
+                    let event: JobEvent | undefined;
+                    try {
+                        event = JSON.parse(message.data.toString());
+                    } catch (error) {
+                        console.error("[Job Listener]: Error parsing message:", error);
+                        message.ack();
+                        return;
+                    }
+
+                    if (event && event.type === "JOB_DISPATCHED") {
+                        await logContextStore.run({ ...logContext, jobId: event.jobId, shouldPublishLog: false }, async () => {
+
+                            console.log(`[Worker ${workerId}] Received JOB_DISPATCHED for ${event.jobId}`);
+                            workerService.processJob(event.jobId);
+                        });
+                    }
                     message.ack();
+                } catch (error) {
+                    console.error(`[Worker ${workerId}] Error processing message:`, error);
                 }
-            } catch (error) {
-                console.error(`[Worker ${workerId}] Error processing message:`, error);
-                message.nack();
-            }
-        });
-
-        // Handle shutdown
-        process.on("SIGINT", async () => {
-            console.log("Shutting down worker...");
-            subscription.close();
-            await poolManager.close();
-            process.exit(0);
-        });
-    } catch (error) {
-        console.error(`[Worker ${workerId}] FATAL: PubSub initialization failed:`, error);
-        console.error(`[Worker ${workerId}] Service cannot start without PubSub. Shutting down...`);
-        process.exit(1);
-    }
+            });
+
+            // Handle shutdown
+            process.on("SIGINT", async () => {
+                console.log("Shutting down worker...");
+                subscription.close();
+                await poolManager.close();
+                process.exit(0);
+            });
+        } catch (error) {
+            console.error(`[Worker ${workerId}] FATAL: PubSub initialization failed:`, error);
+            console.error(`[Worker ${workerId}] Service cannot start without PubSub. Shutting down...`);
+            process.exit(1);
+        }
+    });
 }
 
 main().catch(console.error);
\ No newline at end of file
diff --git a/src/worker/worker-service.ts b/src/worker/worker-service.ts
index 3137e17..15cf4aa 100644
--- a/src/worker/worker-service.ts
+++ b/src/worker/worker-service.ts
@@ -1,5 +1,5 @@
 import { JobControlPlane } from "../pipeline/services/job-control-plane";
-import { JobEvent } from "../shared/types/job-types";
+import { JobEvent } from "../shared/types/job.types";
 import { GCPStorageManager } from "../workflow/storage-manager";
 import { TextModelController } from "../workflow/llm/text-model-controller";
 import { VideoModelController } from "../workflow/llm/video-model-controller";
@@ -10,9 +10,9 @@ import { SemanticExpertAgent } from "../workflow/agents/semantic-expert-agent";
 import { FrameCompositionAgent } from "../workflow/agents/frame-composition-agent";
 import { SceneGeneratorAgent } from "../workflow/agents/scene-generator";
 import { ContinuityManagerAgent } from "../workflow/agents/continuity-manager";
-import { AttemptMetric, Project, Scene } from "../shared/types/pipeline.types";
+import { AttemptMetric, Project, Scene } from "../shared/types/workflow.types";
 import { deleteBogusUrlsStoryboard } from "../shared/utils/utils";
-import { PipelineEvent } from "../shared/types/pubsub.types";
+import { PipelineEvent } from "../shared/types/pipeline.types";
 import { ProjectRepository } from "../pipeline/project-repository";
 import { MediaController } from "../workflow/media-controller";
 import { AssetVersionManager } from "../workflow/asset-version-manager";
@@ -94,22 +94,16 @@ export class WorkerService {
     async processJob(jobId: string) {
         console.log(`[Worker ${this.workerId}] Attempting to claim job ${jobId}`);
 
-        // Phase 1: Claim Job
-        // If this throws, it bubbles up to be Nacked (transient DB error)
-        // If it returns false, we return immediately (duplicate message, Ack)
         const claimed = await this.jobControlPlane.claimJob(jobId, this.workerId);
         if (!claimed) {
             console.log(`[Worker ${this.workerId}] Failed to claim job ${jobId} (already taken or not in CREATED state).`);
             return;
         }
 
-        // Phase 2: Processing
-        // Errors here are "Job Failed", catch them, update DB state, and return (Ack)
         try {
             const job = await this.jobControlPlane.getJob(jobId);
             if (!job) {
                 console.error(`[Worker ${this.workerId}] Job ${jobId} not found after claim`);
-                // This is weird state, but we claimed it. Treating as failed processing.
                 return;
             }
 
@@ -136,7 +130,8 @@ export class WorkerService {
                     payload = job.payload;
                     const expanded = await agents.compositionalAgent.expandCreativePrompt(
                         payload.title,
-                        payload.initialPrompt
+                        payload.initialPrompt,
+                        { maxRetries: 3, attempt: 1, initialDelay: 1000, projectId: job.projectId }
                     );
                     result = { expandedPrompt: expanded };
                     break;
@@ -146,7 +141,7 @@ export class WorkerService {
                     let storyboard = await agents.compositionalAgent.generateStoryboardFromPrompt(
                         payload.title,
                         payload.enhancedPrompt,
-                        { attempt: job.retryCount, maxRetries: job.maxRetries }
+                        { attempt: job.retryCount, maxRetries: job.maxRetries, projectId: job.projectId }
                     );
                     result = { storyboard: deleteBogusUrlsStoryboard(storyboard) };
                     break;
@@ -165,7 +160,7 @@ export class WorkerService {
                     const storyboard = await agents.compositionalAgent.generateFullStoryboard(
                         payload.storyboard,
                         payload.enhancedPrompt,
-                        { initialDelay: 30000, attempt: job.retryCount, maxRetries: job.maxRetries }
+                        { initialDelay: 30000, attempt: job.retryCount, maxRetries: job.maxRetries, projectId: job.projectId }
                     );
                     result = { storyboard };
                     break;
@@ -226,8 +221,12 @@ export class WorkerService {
                         generationRules,
                     } = await agents.continuityAgent.prepareAndRefineSceneInputs(scene, project, false);
 
-                    const onAttemptComplete = (_scene: Scene, attemptMetric: AttemptMetric) => {
-                        console.log(`[Job ${jobId}] Attempt complete:`, attemptMetric);
+                    const onComplete = (_scene: Scene, _attemptMetric: Omit<AttemptMetric, 'sceneId'>) => {
+                        const attemptMetric: AttemptMetric = {
+                            ..._attemptMetric,
+                            sceneId: _scene.id,
+                        };
+                        console.log(`[Job ${jobId}] complete:`, attemptMetric);
                         this.projectRepository.updateScenes([_scene]);
                     };
 
@@ -246,7 +245,7 @@ export class WorkerService {
                         characterReferenceImages,
                         locationReferenceImages,
                         generateAudio,
-                        onAttemptComplete,
+                        onComplete,
                         onProgress,
                         generationRules
                     });
@@ -287,7 +286,6 @@ export class WorkerService {
             await this.jobControlPlane.updateJobState(jobId, "COMPLETED", result);
             await this.publishJobEvent({ type: "JOB_COMPLETED", jobId });
             console.log(`[Worker ${this.workerId}] Job ${jobId} completed`);
-
         } catch (error: any) {
 
             console.error(`[Worker ${this.workerId}] Error processing job ${jobId}:`, {error});
diff --git a/src/workflow/agents/audio-processing-agent.ts b/src/workflow/agents/audio-processing-agent.ts
index 994650e..b3c4949 100644
--- a/src/workflow/agents/audio-processing-agent.ts
+++ b/src/workflow/agents/audio-processing-agent.ts
@@ -3,7 +3,7 @@
 // ============================================================================
 
 import { GCPStorageManager } from "../storage-manager";
-import { AudioAnalysis, AudioAnalysisSchema, AudioSegment, Scene, TransitionType, VALID_DURATIONS, getJsonSchema } from "../../shared/types/pipeline.types";
+import { AudioAnalysis, AudioAnalysisSchema, AudioSegment, Scene, TransitionType, VALID_DURATIONS, getJsonSchema } from "../../shared/types/workflow.types";
 import { FileData, GenerateContentResponse, GoogleGenAI, PartMediaResolution, PartMediaResolutionLevel, ThinkingLevel } from "@google/genai";
 import { cleanJsonOutput, formatTime, roundToValidDuration } from "../../shared/utils/utils";
 import { buildAudioProcessingInstruction } from "../prompts/audio-processing-instruction";
diff --git a/src/workflow/agents/compositional-agent.ts b/src/workflow/agents/compositional-agent.ts
index ce1cdec..b870c07 100644
--- a/src/workflow/agents/compositional-agent.ts
+++ b/src/workflow/agents/compositional-agent.ts
@@ -12,7 +12,7 @@ import {
   Character,
   Location,
   Project
-} from "../../shared/types/pipeline.types";
+} from "../../shared/types/workflow.types";
 import { cleanJsonOutput } from "../../shared/utils/utils";
 import { GCPStorageManager } from "../storage-manager";
 import { composeFrameGenerationPromptMeta, composeStoryboardEnrichmentPrompt } from "../prompts/prompt-composer";
@@ -204,6 +204,7 @@ export class CompositionalAgent {
   async expandCreativePrompt(
     title: string,
     userPrompt: string,
+    retryConfig: RetryConfig,
   ): Promise<string> {
 
     const systemPrompt = buildDirectorVisionPrompt(title, userPrompt);
@@ -235,7 +236,7 @@ export class CompositionalAgent {
       return expandedPrompt;
     };
 
-    return await retryLlmCall(llmCall, undefined, { maxRetries: 3, attempt: 1, initialDelay: 1000 });
+    return await retryLlmCall(llmCall, undefined, retryConfig);
   }
 
   /**
diff --git a/src/workflow/agents/continuity-manager.ts b/src/workflow/agents/continuity-manager.ts
index a2e74fb..cffcf8d 100644
--- a/src/workflow/agents/continuity-manager.ts
+++ b/src/workflow/agents/continuity-manager.ts
@@ -8,7 +8,7 @@ import {
     Storyboard,
     Project,
     AssetStatus,
-} from "../../shared/types/pipeline.types";
+} from "../../shared/types/workflow.types";
 import { GCPStorageManager } from "../storage-manager";
 import { Modality } from "@google/genai";
 import { FrameCompositionAgent } from "./frame-composition-agent";
@@ -230,6 +230,7 @@ export class ContinuityManagerAgent {
                                 attempt,
                                 maxRetries,
                                 initialDelay: this.ASSET_GEN_COOLDOWN_MS,
+                                projectId: character.projectId
                             },
                             async (error, attempt, params) => {
                                 attempt = await onRetry?.(attempt) || attempt;
@@ -575,6 +576,7 @@ export class ContinuityManagerAgent {
                                 attempt,
                                 maxRetries,
                                 initialDelay: this.ASSET_GEN_COOLDOWN_MS,
+                                projectId: location.projectId
                             },
                             async (error, attempt, params) => {
                                 attempt = onRetry ? await onRetry(attempt) : attempt;
diff --git a/src/workflow/agents/frame-composition-agent.ts b/src/workflow/agents/frame-composition-agent.ts
index fe61409..e294fed 100644
--- a/src/workflow/agents/frame-composition-agent.ts
+++ b/src/workflow/agents/frame-composition-agent.ts
@@ -4,13 +4,14 @@ import { TextModelController } from "../llm/text-model-controller";
 import { buildllmParams } from "../llm/google/google-llm-params";
 import { imageModelName } from "../llm/google/models";
 import { QualityCheckAgent } from "./quality-check-agent";
-import { AssetStatus, Character, FrameGenerationResult, Location, QualityEvaluationResult, Scene } from "../../shared/types/pipeline.types";
+import { AssetStatus, Character, FrameGenerationResult, Location, QualityEvaluationResult, Scene } from "../../shared/types/workflow.types";
 import { retryLlmCall } from "../../shared/utils/llm-retry";
 import { RAIError } from "../../shared/utils/errors";
 import { GraphInterrupt } from "@langchain/langgraph";
 import { composeFrameGenerationPromptMeta, composeGenerationRules } from "../prompts/prompt-composer";
 import { cleanJsonOutput } from "../../shared/utils/utils";
 import { AssetVersionManager } from "../asset-version-manager";
+import { QualityRetryHandler } from "@shared/utils/quality-retry-handler";
 
 type FrameImageObjectParams = Extract<GcsObjectPathParams, ({ type: "scene_start_frame"; } | { type: "scene_end_frame"; })>;
 
@@ -242,7 +243,61 @@ export class FrameCompositionAgent {
             };
         }
 
+        // const evaluateFn = async () => await this.qualityAgent.evaluateFrameQuality(
+        //     frame,
+        //     scene,
+        //     framePosition,
+        //     characters,
+        //     locations,
+        // );
+
+        // const applyCorrectionsFn = async () => await this.qualityAgent.applyQualityCorrections(
+        //     prompt,
+        //     evaluation,
+        //     scene,
+        //     characters,
+        //     numAttempts
+        // );
+
+        // const calculateScoreFn = async () => this.qualityAgent[ "calculateOverallScore" ](evaluation.scores);
+
+
+        // await QualityRetryHandler.executeWithRetry(
+        //     prompt,
+        //     {
+        //         qualityConfig: this.qualityAgent.qualityConfig,
+        //         context: {
+        //             assetKey: framePosition === "start" ? "scene_start_frame" : "scene_end_frame",
+        //             sceneId: scene.id,
+        //             sceneIndex: scene.sceneIndex,
+        //             attempt: 1,
+        //             maxAttempts: this.qualityAgent.qualityConfig.maxRetries,
+        //             framePosition,
+        //             projectId: scene.projectId
+        //         }
+        //     },
+        //     {
+        //         generate: async (prompt, currentAttemptNumber) => await this.generateImageWithSafetyRetry(
+        //             scene,
+        //             prompt,
+        //             framePosition,
+        //             objectParams,
+        //             currentAttemptNumber,
+        //             previousFrame,
+        //             referenceImages,
+        //             onProgress
+        //         ),
+        //         evaluate: evaluateFn,
+        //         applyCorrections:,
+        //         calculateScore: ,
+        //         onComplete:,
+        //         onProgress:,
+        //     }
+        // )
+
         throw new Error(`Failed to generate acceptable frame image after ${totalAttempts} attempts`);
+
+
     }
 
     /**
@@ -276,7 +331,8 @@ export class FrameCompositionAgent {
                 maxRetries: this.qualityAgent.qualityConfig.safetyRetries,
                 initialDelay: 3000,
                 backoffFactor: 2,
-                attempt
+                attempt,
+                projectId: scene.projectId
             },
             async (error: any, attempt: number, params) => {
                 if (error instanceof RAIError) {
diff --git a/src/workflow/agents/quality-check-agent.ts b/src/workflow/agents/quality-check-agent.ts
index fb99af6..3598244 100644
--- a/src/workflow/agents/quality-check-agent.ts
+++ b/src/workflow/agents/quality-check-agent.ts
@@ -1,5 +1,5 @@
 
-import { Scene, Character, Location, QualityEvaluationResult, QualityConfig, QualityEvaluationSchema, getJsonSchema, AssetStatus } from "../../shared/types/pipeline.types";
+import { Scene, Character, Location, QualityEvaluationResult, QualityConfig, QualityEvaluationSchema, getJsonSchema, AssetStatus } from "../../shared/types/workflow.types";
 import { GCPStorageManager, GcsObjectPathParams } from "../storage-manager";
 import { buildFrameEvaluationPrompt, buildSceneVideoEvaluationPrompt } from "../prompts/evaluation-instruction";
 import { buildllmParams } from "../llm/google/google-llm-params";
@@ -10,6 +10,7 @@ import { FileData } from "@google/genai";
 import { buildSafetyGuidelinesPrompt } from "../prompts/safety-instructions";
 import { detectRelevantDomainRules, getProactiveRules } from "../prompts/generation-rules-presets";
 import { qualityCheckModelName } from "../llm/google/models";
+import { OnProgressCallback } from "@shared/types/pipeline.types";
 
 
 
@@ -21,7 +22,6 @@ Do not include the markdown characters that denote a a code block.
 ${malformedJson}
 `;
 
-type OnProgressCallback = (scene: Scene, progress?: number) => void;
 
 export class QualityCheckAgent {
   private llm: TextModelController;
@@ -190,7 +190,7 @@ export class QualityCheckAgent {
     location: Location,
     attempt: number,
     previousScene?: Scene,
-    onProgress?: OnProgressCallback,
+    onProgress?: OnProgressCallback<Scene>,
     activeRules?: string[]
   ): Promise<QualityEvaluationResult> {
     scene.progressMessage = "Evaluating scene quality...";
@@ -266,7 +266,7 @@ export class QualityCheckAgent {
     scene: Scene,
     characters: Character[],
     attempt: number,
-    onProgress?: OnProgressCallback,
+    onProgress?: OnProgressCallback<Scene>,
   ): Promise<string> {
 
     if (!evaluation.promptCorrections || evaluation.promptCorrections.length === 0) {
diff --git a/src/workflow/agents/scene-generator.ts b/src/workflow/agents/scene-generator.ts
index 418799b..26b818f 100644
--- a/src/workflow/agents/scene-generator.ts
+++ b/src/workflow/agents/scene-generator.ts
@@ -1,9 +1,9 @@
 import { PersonGeneration, Video, Image, VideoGenerationReferenceType, Operation, GenerateVideosResponse } from "@google/genai";
 import { GCPStorageManager } from "../storage-manager";
-import { Character, Location, GeneratedScene, QualityEvaluationResult, Scene, SceneGenerationResult, AttemptMetric, AssetStatus } from "../../shared/types/pipeline.types";
+import { Character, Location, GeneratedScene, QualityEvaluationResult, Scene, SceneGenerationResult, AttemptMetric, AssetStatus } from "../../shared/types/workflow.types";
 import { RAIError } from "../../shared/utils/errors";
 import ffmpeg from "fluent-ffmpeg";
-import { buildVideoGenerationParams, buildllmParams } from "../llm/google/google-llm-params";
+import { buildVideoGenerationParams } from "../llm/google/google-llm-params";
 import fs from "fs";
 import { formatTime, roundToValidDuration } from "../../shared/utils/utils";
 import { retryLlmCall } from "../../shared/utils/llm-retry";
@@ -12,11 +12,10 @@ import { QualityCheckAgent } from "./quality-check-agent";
 import { GraphInterrupt } from "@langchain/langgraph";
 import { AssetVersionManager } from "../asset-version-manager";
 import { videoModelName } from "../llm/google/models";
+import { OnCompleteCallback, OnProgressCallback } from "@shared/types/pipeline.types";
 
 
 
-type OnProgressCallback = (scene: Scene, progress?: number) => void;
-
 export class SceneGeneratorAgent {
     private videoModel: VideoModelController;
     private storageManager: GCPStorageManager;
@@ -55,7 +54,7 @@ export class SceneGeneratorAgent {
         characterReferenceImages,
         locationReferenceImages,
         generateAudio = false,
-        onAttemptComplete,
+        onComplete,
         onProgress,
         onRetry,
         generationRules,
@@ -71,8 +70,8 @@ export class SceneGeneratorAgent {
         characterReferenceImages?: string[],
         locationReferenceImages?: string[],
         generateAudio: boolean,
-        onAttemptComplete?: (scene: Scene, metric: AttemptMetric) => void,
-        onProgress?: OnProgressCallback,
+            onComplete?: OnCompleteCallback<Scene>,
+            onProgress?: OnProgressCallback<Scene>,
         onRetry?: (attempt: number) => Promise<number>,
         generationRules?: string[],
     }): Promise<SceneGenerationResult> {
@@ -105,9 +104,8 @@ export class SceneGeneratorAgent {
                 setBestVersion,
             );
 
-            if (onAttemptComplete) {
-                onAttemptComplete(generated.scene, {
-                    sceneId: generated.scene.id,
+            if (onComplete) {
+                onComplete(generated.scene, {
                     attemptNumber: version,
                     finalScore: 1.0,
                 });
@@ -135,7 +133,7 @@ export class SceneGeneratorAgent {
             characterReferenceImages,
             locationReferenceImages,
             generateAudio,
-            onAttemptComplete,
+            onComplete,
             onProgress,
             onRetry,
             generationRules,
@@ -171,8 +169,8 @@ export class SceneGeneratorAgent {
         characterReferenceImages?: string[],
         locationReferenceImages?: string[],
         generateAudio = false,
-        onAttemptComplete?: (scene: Scene, metric: AttemptMetric) => void,
-        onProgress?: OnProgressCallback,
+        onAttemptComplete?: OnCompleteCallback<Scene>,
+        onProgress?: OnProgressCallback<Scene>,
         onRetry?: (attempt: number) => Promise<number>,
         generationRules?: string[],
     ): Promise<SceneGenerationResult> {
@@ -237,7 +235,6 @@ export class SceneGeneratorAgent {
 
                     if (onAttemptComplete) {
                         onAttemptComplete(generated.scene, {
-                            sceneId: generated.scene.id,
                             attemptNumber: lastestAttempt,
                             finalScore: score,
                         });
@@ -297,7 +294,6 @@ export class SceneGeneratorAgent {
 
             if (onAttemptComplete) {
                 onAttemptComplete(bestScene, {
-                    sceneId: bestScene.id,
                     attemptNumber: bestAttemptNumber,
                     finalScore: bestScore,
                 });
@@ -331,7 +327,7 @@ export class SceneGeneratorAgent {
         previousScene?: Scene,
         generateAudio = false,
         generationRules?: string[],
-        onProgress?: OnProgressCallback,
+        onProgress?: OnProgressCallback<Scene>,
         onRetry?: (attempt: number) => Promise<number>,
     ): Promise<{ scene: GeneratedScene, videoUrl: string }> {
         console.log(`\nðŸŽ¬ Generating Scene ${scene.id}: ${formatTime(scene.duration)}`);
@@ -363,7 +359,8 @@ export class SceneGeneratorAgent {
                 attempt: version,
                 maxRetries,
                 initialDelay: 1000,
-                backoffFactor: 2
+                backoffFactor: 2,
+                projectId: scene.projectId
             },
             async (error, attempt, params): Promise<any> => {
                 if (error instanceof RAIError) {
@@ -402,7 +399,7 @@ export class SceneGeneratorAgent {
         locationReferenceUrls?: string[],
         previousScene?: Scene,
         generateAudio = false,
-        onProgress?: OnProgressCallback,
+        onProgress?: OnProgressCallback<Scene>,
     ): Promise<string> {
 
         console.log(`   Generating video with prompt: ${prompt.substring(0, 50)}...`);
diff --git a/src/workflow/agents/semantic-expert-agent.ts b/src/workflow/agents/semantic-expert-agent.ts
index 9a07c89..9f29857 100644
--- a/src/workflow/agents/semantic-expert-agent.ts
+++ b/src/workflow/agents/semantic-expert-agent.ts
@@ -1,5 +1,5 @@
 import { TextModelController } from "../llm/text-model-controller";
-import { Storyboard, getJsonSchema } from "../../shared/types/pipeline.types";
+import { Storyboard, getJsonSchema } from "../../shared/types/workflow.types";
 import { buildSemanticRulesPrompt } from "../prompts/semantic-rules-instruction";
 import { buildllmParams } from "../llm/google/google-llm-params";
 import { z } from "zod";
diff --git a/src/workflow/agents/state-evolution.ts b/src/workflow/agents/state-evolution.ts
index bd77812..e1985a7 100644
--- a/src/workflow/agents/state-evolution.ts
+++ b/src/workflow/agents/state-evolution.ts
@@ -1,4 +1,4 @@
-import { Character, Location, Scene, CharacterState, LocationState } from "../../shared/types/pipeline.types";
+import { Character, Location, Scene, CharacterState, LocationState } from "../../shared/types/workflow.types";
 
 /**
  * State Evolution Helper
diff --git a/src/workflow/asset-version-manager.ts b/src/workflow/asset-version-manager.ts
index cf7e57a..972b463 100644
--- a/src/workflow/asset-version-manager.ts
+++ b/src/workflow/asset-version-manager.ts
@@ -1,5 +1,5 @@
 import { ProjectRepository } from "../pipeline/project-repository";
-import { AssetHistory, AssetRegistry, AssetType, AssetVersion, Project, Scene, Character, Location, AssetKey } from "../shared/types/pipeline.types";
+import { AssetHistory, AssetRegistry, AssetType, AssetVersion, Project, Scene, Character, Location, AssetKey } from "../shared/types/workflow.types";
 import { mapDbProjectToDomain } from "../pipeline/helpers/domain/project-mappers";
 
 export type Scope = {
diff --git a/src/workflow/checkpointer-manager.ts b/src/workflow/checkpointer-manager.ts
index c45deb6..7b2d0fc 100644
--- a/src/workflow/checkpointer-manager.ts
+++ b/src/workflow/checkpointer-manager.ts
@@ -1,7 +1,7 @@
 import { RunnableConfig } from "@langchain/core/runnables";
 import { PostgresSaver } from "@langchain/langgraph-checkpoint-postgres";
 import { Checkpoint } from "@langchain/langgraph";
-import { WorkflowState } from "@shared/types/pipeline.types";
+import { WorkflowState } from "@shared/types/workflow.types";
 
 /**
  * Manages loading and saving graph states (checkpoints) to PostgreSQL using LangGraph's Postgres handler.
diff --git a/src/workflow/graph.ts b/src/workflow/graph.ts
index 75fa1a0..826af0a 100644
--- a/src/workflow/graph.ts
+++ b/src/workflow/graph.ts
@@ -4,7 +4,7 @@ dotenv.config();
 import { StateGraph, END, START, NodeInterrupt, Command, interrupt } from "@langchain/langgraph";
 import { JobControlPlane } from "../pipeline/services/job-control-plane";
 import { PoolManager } from "../pipeline/services/pool-manager";
-import { JobEvent, JobRecord, JobType } from "../shared/types/job-types";
+import { JobEvent, JobRecord, JobType } from "../shared/types/job.types";
 import {
   InitialProject,
   InitialProjectSchema,
@@ -12,8 +12,8 @@ import {
   Project,
   Scene,
   WorkflowState,
-} from "../shared/types/pipeline.types";
-import { PipelineEvent } from "../shared/types/pubsub.types";
+} from "../shared/types/workflow.types";
+import { PipelineEvent } from "../shared/types/pipeline.types";
 import { z } from "zod";
 import { GCPStorageManager } from "./storage-manager";
 import { TextModelController } from "./llm/text-model-controller";
@@ -35,7 +35,6 @@ import { SemanticExpertAgent } from "./agents/semantic-expert-agent";
 import { PubSub } from "@google-cloud/pubsub";
 import { JOB_EVENTS_TOPIC_NAME } from "@shared/constants";
 import { AssetVersionManager } from "./asset-version-manager";
-import { interceptNodeInterruptAndThrow } from "../shared/utils/errors";
 import { MediaController } from "./media-controller";
 import { extractGenerationRules } from "./prompts/prompt-composer";
 import { errorHandler } from "./nodes/error-handler";
@@ -174,9 +173,20 @@ export class CinematicVideoWorkflow {
     ...payloadArg: JobPayload<T>
   ): Promise<Extract<JobRecord, { type: T; }>[ 'result' ]> {
 
-    const [ payload ] = payloadArg;
     const jobId = this.jobControlPlane.jobId(this.projectId, nodeName, attempt);
     const job = await this.jobControlPlane.getJob(jobId);
+    const [ payload ] = payloadArg;
+
+    const interruptValue: LlmRetryInterruptValue = {
+      type: "waiting_for_job",
+      error: "waiting_for_job",
+      errorDetails: { jobId },
+      functionName: "ensureJob",
+      nodeName,
+      projectId: this.projectId,
+      attempt,
+      lastAttemptTimestamp: new Date().toISOString(),
+    };
 
     if (!job) {
       await this.jobControlPlane.createJob({
@@ -188,27 +198,26 @@ export class CinematicVideoWorkflow {
         maxRetries: this.MAX_RETRIES,
       });
       console.log(`[${nodeName}] Dispatched job ${jobId}`);
-    } else if (job.state === 'COMPLETED') {
-      const result = job.result;
-      if (!result) {
-        console.error(`Job ${job.id} complete but no result was returned.`, { job });
-        throw new Error(`Job ${job.id} complete but no result was returned.`);
+
+      throw new NodeInterrupt(interruptValue);
+    }
+
+    if (job) {
+      if (job.state === 'COMPLETED') {
+        const result = job.result;
+        if (!result) {
+          console.error(`Job ${job.id} complete but no result was returned.`, { job });
+          throw new Error(`Job ${job.id} complete but no result was returned.`);
+        }
+        return result as any;
+      }
+
+      if (job.state === 'FAILED') {
+        throw new Error(`Job ${jobId} failed: ${job.error}`);
       }
-      return result as any;
-    } else if (job.state === 'FAILED') {
-      throw new Error(`Job ${jobId} failed: ${job.error}`);
     }
 
-    const interruptValue: LlmRetryInterruptValue = {
-      type: "waiting_for_job",
-      error: "waiting_for_job",
-      errorDetails: { jobId },
-      functionName: "ensureJob",
-      nodeName,
-      attempt,
-      lastAttemptTimestamp: new Date().toISOString(),
-    };
-    interrupt(interruptValue);
+    throw new NodeInterrupt(interruptValue);
   }
 
   private async ensureBatchJobs<T extends JobType>(
@@ -250,6 +259,7 @@ export class CinematicVideoWorkflow {
         errorDetails: { failedJobs },
         functionName: "ensureBatchJobs",
         nodeName: nodeName,
+        projectId: this.projectId,
         params: {
           jobIds: failedJobs.map(f => f.id)
         },
@@ -257,7 +267,7 @@ export class CinematicVideoWorkflow {
         lastAttemptTimestamp: new Date().toISOString(),
       };
 
-      interrupt(interruptValue);
+      throw new NodeInterrupt(interruptValue);
     }
 
     // 3. Throttling & Creation
@@ -293,10 +303,11 @@ export class CinematicVideoWorkflow {
         errorDetails: { pendingJobs: notCompletedCount },
         functionName: "ensureBatchJobs",
         nodeName: nodeName,
+        projectId: this.projectId,
         attempt: jobs[ 0 ].attempt,
         lastAttemptTimestamp: new Date().toISOString(),
       };
-      interrupt(interruptValue);
+      throw new NodeInterrupt(interruptValue);
     }
 
     return results as any;
@@ -329,6 +340,71 @@ export class CinematicVideoWorkflow {
       },
     });
 
+    workflow.addConditionalEdges(START, async (state: WorkflowState) => {
+      const scenes = await this.projectRepository.getProjectScenes(state.projectId);
+      const project = await this.projectRepository.getProject(state.projectId);
+      if (scenes.some(s => {
+        const sceneVideoAssets = s.assets[ 'scene_video' ];
+        const hasVideo = !!sceneVideoAssets?.versions[ sceneVideoAssets.best ]?.data;
+        return hasVideo;
+      })) {
+        console.log(" [Cinematic-Canvas]: Resuming from 'process_scene'");
+        return "process_scene";
+      }
+      if (project.generationRules.length > 0) {
+        console.log("[Cinematic-Canvas]:  Proceeding to 'generate_character_assets'");
+        return "generate_character_assets";
+      }
+      if (project.metadata.enhancedPrompt) {
+        console.log("[Cinematic-Canvas]:  Proceeding to 'semantic_analysis'");
+        return "semantic_analysis";
+      }
+      console.log("[Cinematic-Canvas]: Proceeding to 'expand_creative_prompt'");
+      return "expand_creative_prompt";
+    });
+    // Non-audio workflow path
+    workflow.addEdge("expand_creative_prompt" as any, "generate_storyboard_exclusively_from_prompt" as any);
+    workflow.addEdge("generate_storyboard_exclusively_from_prompt" as any, "semantic_analysis" as any);
+    // Audio-based workflow path
+    workflow.addEdge("expand_creative_prompt" as any, "create_scenes_from_audio" as any);
+    workflow.addEdge("create_scenes_from_audio" as any, "enrich_storyboard_and_scenes" as any);
+    workflow.addEdge("enrich_storyboard_and_scenes" as any, "semantic_analysis" as any);
+    workflow.addEdge("semantic_analysis" as any, "generate_character_assets" as any);
+    workflow.addEdge("generate_character_assets" as any, "generate_location_assets" as any);
+    workflow.addEdge("generate_location_assets" as any, "generate_scene_assets" as any);
+    workflow.addEdge("generate_scene_assets" as any, "process_scene" as any);
+    workflow.addConditionalEdges("process_scene" as any, async (state: WorkflowState) => {
+      const scenes = await this.projectRepository.getProjectScenes(state.projectId);
+      const executionMode = process.env.EXECUTION_MODE || 'SEQUENTIAL';
+      if (executionMode === 'SEQUENTIAL') {
+        if (state.currentSceneIndex < (scenes.length || 0)) {
+          console.log("[process_scene edge]: Looping 'process_scene'");
+          return "process_scene";
+        }
+      } else {
+        const hasPending = scenes.some(s => s.status === 'pending');
+        if (hasPending) {
+          console.log("[process_scene edge]: Pending scenes found, looping 'process_scene'");
+          return "process_scene";
+        }
+      }
+      console.log("[process_scene edge]: Proceeding to 'render_video'");
+      return "render_video";
+    });
+    workflow.addEdge("render_video" as any, "finalize" as any);
+    workflow.addEdge("finalize" as any, END);
+
+    workflow.addEdge("expand_creative_prompt" as any, "error_handler" as any);
+    workflow.addEdge("generate_storyboard_exclusively_from_prompt" as any, "error_handler" as any);
+    workflow.addEdge("create_scenes_from_audio" as any, "error_handler" as any);
+    workflow.addEdge("enrich_storyboard_and_scenes" as any, "error_handler" as any);
+    workflow.addEdge("semantic_analysis" as any, "error_handler" as any);
+    workflow.addEdge("generate_character_assets" as any, "error_handler" as any);
+    workflow.addEdge("generate_location_assets" as any, "error_handler" as any);
+    workflow.addEdge("generate_scene_assets" as any, "error_handler" as any);
+    workflow.addEdge("process_scene" as any, "error_handler" as any);
+    workflow.addEdge("render_video" as any, "error_handler" as any);
+
     workflow.addNode("expand_creative_prompt", async (state: WorkflowState) => {
       const nodeName = "expand_creative_prompt";
       console.log(`[${nodeName}]: Started`);
@@ -355,13 +431,31 @@ export class CinematicVideoWorkflow {
         });
         await this.publishStateUpdate(updated, nodeName);
         console.log(`[${nodeName}]: Completed\n`);
-        return {
-          ...state,
-          initialProject: updated,
-          nodeAttempts: { [ nodeName ]: currentAttempt },
-          __interrupt__: undefined,
-          __interrupt_resolved__: false,
-        };
+
+        if (state.hasAudio) {
+          console.log("[expand_creative_prompt edge]: state.hasAudio: ", state.hasAudio);
+          console.log("[expand_creative_prompt edge]: Proceeding to 'create_scenes_from_audio'");
+          return new Command({
+            goto: "create_scenes_from_audio",
+            update: {
+              initialProject: updated,
+              nodeAttempts: { [ nodeName ]: currentAttempt },
+              __interrupt__: undefined,
+              __interrupt_resolved__: false,
+            }
+          });
+        } else {
+          console.log("[expand_creative_prompt edge]: Proceeding to 'generate_storyboard_exclusively_from_prompt'");
+          return new Command({
+            goto: "generate_storyboard_exclusively_from_prompt",
+            update: {
+              initialProject: updated,
+              nodeAttempts: { [ nodeName ]: currentAttempt },
+              __interrupt__: undefined,
+              __interrupt_resolved__: false,
+            }
+          });
+        }
       } catch (error: any) {
         console.error(`[${nodeName}] error`, { error });
         return new Command({
@@ -372,6 +466,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "generate_storyboard_exclusively_from_prompt", "create_scenes_from_audio", "error_handler" ]
     });
 
     workflow.addNode("generate_storyboard_exclusively_from_prompt", async (state: WorkflowState) => {
@@ -423,6 +519,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "semantic_analysis", "error_handler" ]
     });
 
     workflow.addNode("create_scenes_from_audio", async (state: WorkflowState) => {
@@ -491,6 +589,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "enrich_storyboard_and_scenes", "error_handler" ]
     });
 
     workflow.addNode("enrich_storyboard_and_scenes", async (state: WorkflowState) => {
@@ -558,6 +658,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "semantic_analysis", "error_handler" ]
     });
 
     workflow.addNode("semantic_analysis", async (state: WorkflowState) => {
@@ -605,6 +707,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "generate_character_assets", "error_handler" ]
     });
 
     workflow.addNode("generate_character_assets", async (state: WorkflowState) => {
@@ -716,6 +820,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "generate_location_assets", "error_handler" ]
     });
 
     workflow.addNode("generate_location_assets", async (state: WorkflowState) => {
@@ -823,6 +929,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "generate_scene_assets", "error_handler" ]
     });
 
     workflow.addNode("generate_scene_assets", async (state: WorkflowState) => {
@@ -893,6 +1001,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "process_scene", "error_handler" ]
     });
 
     workflow.addNode("process_scene", async (state: WorkflowState) => {
@@ -1105,6 +1215,8 @@ export class CinematicVideoWorkflow {
           // });
         }
       }
+    }, {
+      ends: [ "process_scene", "render_video", "error_handler" ]
     });
 
     workflow.addNode("render_video", async (state: WorkflowState) => {
@@ -1165,6 +1277,8 @@ export class CinematicVideoWorkflow {
           }
         });
       }
+    }, {
+      ends: [ "finalize", "error_handler" ]
     });
 
     workflow.addNode("finalize", async (state: WorkflowState) => {
@@ -1194,63 +1308,21 @@ export class CinematicVideoWorkflow {
       };
     });
 
-    workflow.addNode("error_handler", errorHandler);
-
-
-    workflow.addConditionalEdges(START, async (state: WorkflowState) => {
-      const scenes = await this.projectRepository.getProjectScenes(state.projectId);
-      const project = await this.projectRepository.getProject(state.projectId);
-      if (scenes.some(s => {
-        const sceneVideoAssets = s.assets[ 'scene_video' ];
-        return sceneVideoAssets?.versions[ sceneVideoAssets.best ].data;
-      })) {
-        console.log(" Resuming from 'process_scene'");
-        return "process_scene";
-      }
-      if (project.metadata.enhancedPrompt) {
-        console.log("[START edge]: Proceeding to 'generate_character_assets'");
-        return "generate_character_assets";
-      }
-      console.log("[START edge]: Proceeding to 'expand_creative_prompt'");
-      return "expand_creative_prompt";
-    });
-    workflow.addConditionalEdges("expand_creative_prompt" as any, (state: WorkflowState) => {
-      if (state.hasAudio) {
-        console.log("[expand_creative_prompt edge]: Proceeding to 'create_scenes_from_audio'");
-        return "create_scenes_from_audio";
-      }
-      console.log("[expand_creative_prompt edge]: Proceeding to 'generate_storyboard_exclusively_from_prompt'");
-      return "generate_storyboard_exclusively_from_prompt";
+    workflow.addNode("error_handler", errorHandler, {
+      ends: [
+        "expand_creative_prompt",
+        "generate_storyboard_exclusively_from_prompt",
+        "create_scenes_from_audio",
+        "enrich_storyboard_and_scenes",
+        "semantic_analysis",
+        "generate_character_assets",
+        "generate_location_assets",
+        "generate_scene_assets",
+        "process_scene",
+        "render_video",
+        "finalize"
+      ]
     });
-    // Non-audio workflow path
-    workflow.addEdge("generate_storyboard_exclusively_from_prompt" as any, "semantic_analysis" as any);
-    // Audio-based workflow path
-    workflow.addEdge("create_scenes_from_audio" as any, "enrich_storyboard_and_scenes" as any);
-    workflow.addEdge("enrich_storyboard_and_scenes" as any, "semantic_analysis" as any);
-    workflow.addEdge("semantic_analysis" as any, "generate_character_assets" as any);
-    workflow.addEdge("generate_character_assets" as any, "generate_location_assets" as any);
-    workflow.addEdge("generate_location_assets" as any, "generate_scene_assets" as any);
-    workflow.addEdge("generate_scene_assets" as any, "process_scene" as any);
-    workflow.addConditionalEdges("process_scene" as any, async (state: WorkflowState) => {
-      const scenes = await this.projectRepository.getProjectScenes(state.projectId);
-      const executionMode = process.env.EXECUTION_MODE || 'SEQUENTIAL';
-      if (executionMode === 'SEQUENTIAL') {
-        if (state.currentSceneIndex < (scenes.length || 0)) {
-          console.log("[process_scene edge]: Looping 'process_scene'");
-          return "process_scene";
-        }
-      } else {
-        const hasPending = scenes.some(s => s.status === 'pending');
-        if (hasPending) {
-          console.log("[process_scene edge]: Pending scenes found, looping 'process_scene'");
-          return "process_scene";
-        }
-      }
-      console.log("[process_scene edge]: Proceeding to 'render_video'");
-      return "render_video";
-    });
-    workflow.addEdge("render_video" as any, "finalize" as any);
-    workflow.addEdge("finalize" as any, END);
 
     return workflow;
   }
@@ -1367,6 +1439,7 @@ export class CinematicVideoWorkflow {
     }
 
     const compiled = this.graph.compile({ checkpointer });
+    // INTERRUPTS ARE NOT HANDLED WHEN USING CLI EXECUTION!!
     result = await compiled.invoke(initialState, {
       configurable: { thread_id: this.projectId },
       recursionLimit: 100,
@@ -1490,4 +1563,4 @@ async function main() {
 
 if (import.meta.main) {
   main().catch(console.error);
-}
\ No newline at end of file
+}
diff --git a/src/workflow/media-controller.ts b/src/workflow/media-controller.ts
index ae2ef0f..cee49f3 100644
--- a/src/workflow/media-controller.ts
+++ b/src/workflow/media-controller.ts
@@ -3,7 +3,7 @@ import fs from "fs";
 import path from "path";
 import ffmpegBin from "@ffmpeg-installer/ffmpeg";
 import ffprobeBin from "@ffprobe-installer/ffprobe";
-import { Scene } from "@shared/types/pipeline.types";
+import { Scene } from "@shared/types/workflow.types";
 import { GCPStorageManager } from "./storage-manager";
 ffmpeg.setFfmpegPath(ffmpegBin.path);
 ffmpeg.setFfprobePath(ffprobeBin.path);
diff --git a/src/workflow/nodes/error-handler.ts b/src/workflow/nodes/error-handler.ts
index 7a7b5fe..707b85c 100644
--- a/src/workflow/nodes/error-handler.ts
+++ b/src/workflow/nodes/error-handler.ts
@@ -1,10 +1,10 @@
 import { Command } from "@langchain/langgraph";
-import { WorkflowState } from "@shared/types/pipeline.types";
+import { WorkflowState } from "@shared/types/workflow.types";
 import { interceptNodeInterruptAndThrow } from "@shared/utils/errors";
 
 export const errorHandler = async (state: WorkflowState) => {
     const errorContext = state[ 'errors' ].at(-1);
-    if (state.__interrupt__ && !state.__interrupt_resolved__) {
+    if (state.__interrupt__?.length && !state.__interrupt_resolved__) {
         console.log(`[Error Handler Node]: Interrupt found. Retrying node: ${errorContext?.node}`);
         console.debug(`Error context: `, JSON.stringify({ errorContext }));
         return new Command({
@@ -28,5 +28,5 @@ export const errorHandler = async (state: WorkflowState) => {
     // }
     
     console.log(`[Error Handler Node]: Retrying node: ${errorContext?.node}`);
-    interceptNodeInterruptAndThrow(errorContext, errorContext?.node || "Error Handler Node");
+    interceptNodeInterruptAndThrow(errorContext, errorContext?.node || "Error Handler Node", state.projectId);
 };
\ No newline at end of file
diff --git a/src/workflow/prompts/character-image-instruction.ts b/src/workflow/prompts/character-image-instruction.ts
index 4ef708e..9b60aa9 100644
--- a/src/workflow/prompts/character-image-instruction.ts
+++ b/src/workflow/prompts/character-image-instruction.ts
@@ -1,4 +1,4 @@
-import { Character } from "../../shared/types/pipeline.types";
+import { Character } from "../../shared/types/workflow.types";
 import { composeGenerationRules } from "./prompt-composer";
 import { buildCostumeAndMakeupPrompt } from "./role-costume-makeup";
 
diff --git a/src/workflow/prompts/deprecated-continuity-instructions.ts b/src/workflow/prompts/deprecated-continuity-instructions.ts
index 5f1d534..1529eff 100644
--- a/src/workflow/prompts/deprecated-continuity-instructions.ts
+++ b/src/workflow/prompts/deprecated-continuity-instructions.ts
@@ -1,5 +1,5 @@
 // deprecated
-import { Scene } from "../../shared/types/pipeline.types";
+import { Scene } from "../../shared/types/workflow.types";
 import { composeGenerationRules } from "./prompt-composer";
 
 export const continuitySystemPrompt = `As the continuity supervisor for a high-budget cinematic production, the task is to ensure that every frame feels like it belongs to the same carefully crafted world.
diff --git a/src/workflow/prompts/deprecated-storyboard-composition-instruction.ts b/src/workflow/prompts/deprecated-storyboard-composition-instruction.ts
index ee80b12..471ef8c 100644
--- a/src/workflow/prompts/deprecated-storyboard-composition-instruction.ts
+++ b/src/workflow/prompts/deprecated-storyboard-composition-instruction.ts
@@ -2,7 +2,7 @@
 export const promptVersion = "3.0.0";
 
 import { z } from "zod";
-import { SceneSchema, StoryboardSchema } from "../../shared/types/pipeline.types";
+import { SceneSchema, StoryboardSchema } from "../../shared/types/workflow.types";
 import { buildDirectorSceneBeatPrompt } from "./role-director";
 import { buildCinematographerGuidelines } from "./role-cinematographer";
 import { buildGafferGuidelines } from "./role-gaffer";
diff --git a/src/workflow/prompts/evaluation-instruction.ts b/src/workflow/prompts/evaluation-instruction.ts
index 332f7ec..79fb46e 100644
--- a/src/workflow/prompts/evaluation-instruction.ts
+++ b/src/workflow/prompts/evaluation-instruction.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-quality-control";
 
-import { Character, Location, PromptCorrectionSchema, QualityIssueSchema, Scene, getJsonSchema } from "../../shared/types/pipeline.types";
+import { Character, Location, PromptCorrectionSchema, QualityIssueSchema, Scene, getJsonSchema } from "../../shared/types/workflow.types";
 import { formatCharacterSpecs, formatLocationSpecs, getAllBestFromAssets } from "../../shared/utils/utils";
 import { composeDepartmentSpecs } from "./prompt-composer";
 import { buildQualityControlVideoPrompt, buildQualityControlFramePrompt } from "./role-quality-control";
diff --git a/src/workflow/prompts/location-image-instruction.ts b/src/workflow/prompts/location-image-instruction.ts
index eef55d1..e955af1 100644
--- a/src/workflow/prompts/location-image-instruction.ts
+++ b/src/workflow/prompts/location-image-instruction.ts
@@ -1,4 +1,4 @@
-import { Location } from "../../shared/types/pipeline.types";
+import { Location } from "../../shared/types/workflow.types";
 import { composeGenerationRules } from "./prompt-composer";
 import { buildProductionDesignerPrompt } from "./role-production-designer";
 
diff --git a/src/workflow/prompts/prompt-composer.ts b/src/workflow/prompts/prompt-composer.ts
index 7115b5c..07827da 100644
--- a/src/workflow/prompts/prompt-composer.ts
+++ b/src/workflow/prompts/prompt-composer.ts
@@ -5,7 +5,7 @@
  * at various generation points in the workflow.
  */
 
-import { Scene, Character, Location, QualityEvaluationResult } from "../../shared/types/pipeline.types";
+import { Scene, Character, Location, QualityEvaluationResult } from "../../shared/types/workflow.types";
 import { buildDirectorSceneBeatPrompt } from "./role-director";
 import { buildCinematographerGuidelines, buildCinematographerFrameComposition, buildCinematographerNarrative } from "./role-cinematographer";
 import { buildGafferGuidelines, buildGafferLightingSpec } from "./role-gaffer";
diff --git a/src/workflow/prompts/prompt-correction-instruction.ts b/src/workflow/prompts/prompt-correction-instruction.ts
index 78373b4..3154472 100644
--- a/src/workflow/prompts/prompt-correction-instruction.ts
+++ b/src/workflow/prompts/prompt-correction-instruction.ts
@@ -1,4 +1,4 @@
-import { PromptCorrection, Scene } from "../../shared/types/pipeline.types";
+import { PromptCorrection, Scene } from "../../shared/types/workflow.types";
 import { buildSafetyGuidelinesPrompt } from "./safety-instructions";
 
 export const buildCorrectionPrompt = (originalPrompt: string, scene: Scene, corrections: PromptCorrection[]) => `As a prompt refinement specialist, apply the following corrections to improve this video generation prompt.
diff --git a/src/workflow/prompts/role-cinematographer.ts b/src/workflow/prompts/role-cinematographer.ts
index bf0a1cf..f038885 100644
--- a/src/workflow/prompts/role-cinematographer.ts
+++ b/src/workflow/prompts/role-cinematographer.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-cinematographer";
 
-import { cameraAnglesWithDescriptions, cameraMovementsWithDescriptions, CompositionSchema, getJsonSchema, Scene, shotTypesWithDescriptions, TransitionTypesSchema } from "../../shared/types/pipeline.types";
+import { cameraAnglesWithDescriptions, cameraMovementsWithDescriptions, CompositionSchema, getJsonSchema, Scene, shotTypesWithDescriptions, TransitionTypesSchema } from "../../shared/types/workflow.types";
 
 /**
  * CINEMATOGRAPHER - Shot Composition & Framing
diff --git a/src/workflow/prompts/role-costume-makeup.ts b/src/workflow/prompts/role-costume-makeup.ts
index f11727b..57083e2 100644
--- a/src/workflow/prompts/role-costume-makeup.ts
+++ b/src/workflow/prompts/role-costume-makeup.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-costume-makeup";
 
-import { Character } from "../../shared/types/pipeline.types";
+import { Character } from "../../shared/types/workflow.types";
 import { buildSafetyGuidelinesPrompt } from "./safety-instructions";
 
 /**
diff --git a/src/workflow/prompts/role-director.ts b/src/workflow/prompts/role-director.ts
index 12fd0ed..8cad126 100644
--- a/src/workflow/prompts/role-director.ts
+++ b/src/workflow/prompts/role-director.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-director";
 
-import { AudioSegment } from "../../shared/types/pipeline.types";
+import { AudioSegment } from "../../shared/types/workflow.types";
 import { buildSafetyGuidelinesPrompt } from "./safety-instructions";
 
 /**
diff --git a/src/workflow/prompts/role-gaffer.ts b/src/workflow/prompts/role-gaffer.ts
index 5922db7..ca4802d 100644
--- a/src/workflow/prompts/role-gaffer.ts
+++ b/src/workflow/prompts/role-gaffer.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-gaffer";
 
-import { Scene, Location, getJsonSchema, LightingSchema } from "../../shared/types/pipeline.types";
+import { Scene, Location, getJsonSchema, LightingSchema } from "../../shared/types/workflow.types";
 
 export const buildGafferPrompt = (scene: Scene, location: Location, timeOfDay: string) => `
 As the GAFFER, design lighting for Scene ${scene.id}.
diff --git a/src/workflow/prompts/role-production-designer.ts b/src/workflow/prompts/role-production-designer.ts
index dd262ad..6074acd 100644
--- a/src/workflow/prompts/role-production-designer.ts
+++ b/src/workflow/prompts/role-production-designer.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-production-designer";
 
-import { Location } from "../../shared/types/pipeline.types";
+import { Location } from "../../shared/types/workflow.types";
 import { getAllBestFromAssets } from "../../shared/utils/utils";
 
 /**
diff --git a/src/workflow/prompts/role-quality-control.ts b/src/workflow/prompts/role-quality-control.ts
index 796bd07..40f8996 100644
--- a/src/workflow/prompts/role-quality-control.ts
+++ b/src/workflow/prompts/role-quality-control.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.1.0-quality-control-enhanced";
 
-import { Scene } from "../../shared/types/pipeline.types";
+import { Scene } from "../../shared/types/workflow.types";
 import { ISSUE_CATEGORIZATION_GUIDE, EVALUATION_CALIBRATION_GUIDE } from "./evaluation-guidelines";
 import { composeGenerationRules } from "./prompt-composer";
 import { getAllBestFromAssets } from "../../shared/utils/utils";
diff --git a/src/workflow/prompts/role-script-supervisor.ts b/src/workflow/prompts/role-script-supervisor.ts
index 2103d6e..f59541e 100644
--- a/src/workflow/prompts/role-script-supervisor.ts
+++ b/src/workflow/prompts/role-script-supervisor.ts
@@ -1,6 +1,6 @@
 export const promptVersion = "3.0.0-script-supervisor";
 
-import { Scene, Character, Location } from "../../shared/types/pipeline.types";
+import { Scene, Character, Location } from "../../shared/types/workflow.types";
 
 /**
  * SCRIPT SUPERVISOR - Continuity Tracking
diff --git a/src/workflow/storage-manager.ts b/src/workflow/storage-manager.ts
index aabc2de..61a977a 100644
--- a/src/workflow/storage-manager.ts
+++ b/src/workflow/storage-manager.ts
@@ -1,6 +1,6 @@
 import { Storage } from "@google-cloud/storage";
 import path from "path";
-import { GcsObjectType } from "../shared/types/pipeline.types";
+import { GcsObjectType } from "../shared/types/workflow.types";
 
 
 
diff --git a/src/workflow/tests/compositional-agent.test.ts b/src/workflow/tests/compositional-agent.test.ts
index 0d90b43..eb37914 100644
--- a/src/workflow/tests/compositional-agent.test.ts
+++ b/src/workflow/tests/compositional-agent.test.ts
@@ -253,29 +253,35 @@ describe('CompositionalAgent', () => {
     }, 15000);
 
     it('should expand creative prompt', async () => {
+        const title = 'Test Storyboard';
         const prompt = 'A short prompt';
         const expandedPrompt = 'A longer, more detailed prompt';
+        const projectId = 'test-project-id';
 
         mockGenerateContent.mockResolvedValueOnce({
             text: expandedPrompt,
         } as any);
 
-        const result = await compositionalAgent.expandCreativePrompt(prompt);
+        const result = await compositionalAgent.expandCreativePrompt(title, prompt, { maxRetries: 3, attempt: 1, initialDelay: 1000, projectId: projectId });
         expect(result).toBe(expandedPrompt);
         expect(mockGenerateContent).toHaveBeenCalled();
     }, 150000);
 
     it('should return original prompt if expansion fails', async () => {
+        const title = 'Test Storyboard';
         const prompt = 'A short prompt';
+        const projectId = 'test-project-id';
 
-        mockGenerateContent.mockRejectedValueOnce(new Error('Failed'));
+        mockGenerateContent.mockRejectedValueOnce(new Error('Failed')); 
 
-        const result = await compositionalAgent.expandCreativePrompt(prompt);
+        const result = await compositionalAgent.expandCreativePrompt(title, prompt, { maxRetries: 3, attempt: 1, initialDelay: 1000, projectId: projectId });
         expect(result).toBe(prompt);
     });
 
     it('should generate storyboard from prompt', async () => {
+        const initialPrompt = 'A short prompt';
         const enhancedPrompt = 'A creative prompt';
+        const projectId = 'test-project-id';
         const mockStoryboard: Storyboard = {
             metadata: {
                 title: 'Test Storyboard',
@@ -286,9 +292,15 @@ describe('CompositionalAgent', () => {
                 colorPalette: [ '#ffffff' ],
                 tags: [ 'test' ],
                 enhancedPrompt: enhancedPrompt,
-                videoModel: 'veo-2.0-generate-exp',
-                imageModel: 'imagen-3',
-                textModel: 'gemini-2.5-flash',
+                projectId,
+                models: {
+                    videoModel: 'veo-2.0-generate-exp',
+                    imageModel: 'imagen-3',
+                    textModel: 'gemini-2.5-flash',
+                    qualityCheckModel: 'gemini-2.5-flash',
+                },
+                initialPrompt,
+                hasAudio: true,
             } as Storyboard[ 'metadata' ],
             characters: [],
             locations: [],
diff --git a/src/workflow/tests/continuity-manager.test.ts b/src/workflow/tests/continuity-manager.test.ts
index 08c979d..3a2dd79 100644
--- a/src/workflow/tests/continuity-manager.test.ts
+++ b/src/workflow/tests/continuity-manager.test.ts
@@ -4,7 +4,7 @@ import { GCPStorageManager } from '../storage-manager';
 import { FrameCompositionAgent } from '../agents/frame-composition-agent';
 import { QualityCheckAgent } from '../agents/quality-check-agent';
 import { TextModelController } from '../llm/text-model-controller';
-import { Scene, Storyboard } from '../../shared/types/pipeline.types';
+import { Scene, Storyboard } from '../../shared/types/workflow.types';
 
 // Mock dependencies
 const mockGenerateContent = vi.fn();
diff --git a/vite.config.node.ts b/vite.config.node.ts
index 6d526d2..a6927a3 100644
--- a/vite.config.node.ts
+++ b/vite.config.node.ts
@@ -12,5 +12,11 @@ export default defineConfig({
   build: {
     target: 'node22',
     sourcemap: 'inline',
+    minify: false,
   },
+  server: {
+    hmr: {
+      overlay: false
+    }
+  }
 });
